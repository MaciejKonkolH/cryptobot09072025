"""
Konfiguracja dla modu≈Çu treningowego (`trainer`) z u≈ºyciem XGBoost.
"""
import os
import logging
from training.utils import find_project_root

# ==============================================================================
# üéØ G≈Å√ìWNE PARAMETRY KONFIGURACYJNE (DO ZMIANY PRZEZ U≈ªYTKOWNIKA)
# ==============================================================================

# --- ≈öcie≈ºki ---
PROJECT_ROOT = find_project_root()
MODULE_DIR = os.path.join(PROJECT_ROOT, 'training')

# Dane wej≈õciowe pochodzƒÖ teraz z modu≈Çu `labeler`
INPUT_DIR = os.path.join(PROJECT_ROOT, 'labeler', 'output')
INPUT_FILENAME = "BTCUSDT-1m-futures_features_and_labels_FW-120_SL-040_TP-080.feather" 
INPUT_FILE_PATH = os.path.join(INPUT_DIR, INPUT_FILENAME)

# ≈öcie≈ºki wyj≈õciowe
OUTPUT_DIR = os.path.join(MODULE_DIR, 'output')
MODEL_DIR = os.path.join(OUTPUT_DIR, 'models')
REPORT_DIR = os.path.join(OUTPUT_DIR, 'reports')
LOG_DIR = os.path.join(OUTPUT_DIR, 'logs')
SCALER_FILENAME = "scaler.pkl"

# --- Lista Cech do Treningu ---
# Wszystkie cechy obliczone przez feature_calculator.py
FEATURES = [
    'bb_width', 
    # 'bb_position', # Usuniƒôta z powodu bardzo niskiej wa≈ºno≈õci
    # 'rsi_14', # Usuniƒôta z powodu bardzo niskiej wa≈ºno≈õci
    'macd_hist', 
    'adx_14', 
    'choppiness_index',
    'price_to_ma_60',
    'price_to_ma_240',
    'ma_60_to_ma_240',
    # 'volume_change_norm', # Usuniƒôta z powodu bardzo niskiej wa≈ºno≈õci
    'price_to_ma_1440',
    'price_to_ma_43200',
    'volume_to_ma_1440',
    'volume_to_ma_43200',
    # --- Nowe cechy dedykowane (v2) ---
    'whipsaw_range_15m',   # Rozpiƒôto≈õƒá ceny w kr√≥tkim oknie (chaos vs nuda)
    'upper_wick_ratio_5m', # Stosunek g√≥rnego cienia (pu≈Çapki na byki)
    'lower_wick_ratio_5m', # Stosunek dolnego cienia (pu≈Çapki na nied≈∫wiedzie)
]

# Opcjonalne filtrowanie po dacie
ENABLE_DATE_FILTER = False
START_DATE = "2022-01-01"
END_DATE = "2023-01-01"

# --- Parametry Podzia≈Çu Danych ---
VALIDATION_SPLIT = 0.15
TEST_SPLIT = 0.15

# --- Parametry Modelu XGBoost ---
XGB_N_ESTIMATORS = 500          # Maksymalna liczba drzew
XGB_LEARNING_RATE = 0.05        # Wsp√≥≈Çczynnik uczenia
XGB_MAX_DEPTH = 5               # Maksymalna g≈Çƒôboko≈õƒá drzewa
XGB_SUBSAMPLE = 0.8             # Procent pr√≥bek u≈ºytych do budowy ka≈ºdego drzewa
XGB_COLSAMPLE_BYTREE = 0.8      # Procent cech u≈ºytych do budowy ka≈ºdego drzewa
XGB_GAMMA = 0.1                 # Minimalna redukcja straty wymagana do podzia≈Çu
XGB_EARLY_STOPPING_ROUNDS = 15  # Zatrzymaj trening, je≈õli metryka na zbiorze walidacyjnym nie poprawi siƒô przez 15 rund

# --- Strategiczne Wagi Klas ---
# Ustaw na True, aby aktywowaƒá poni≈ºsze wagi. Ustaw na False, aby wszystkie
# klasy by≈Çy traktowane jednakowo (bez wa≈ºenia).
ENABLE_CLASS_WEIGHTING = True

# Ustawiamy w≈Çasne wagi, aby nadaƒá priorytet najwa≈ºniejszym lekcjom dla modelu.
# NajwiƒôkszƒÖ wagƒô dajemy b≈Çƒôdom na klasach stratnych (LOSS_*), aby model
# nauczy≈Ç siƒô ich unikaƒá za wszelkƒÖ cenƒô.
CLASS_WEIGHTS = {
    0: 5.0,   # PROFIT_SHORT
    1: 1.0,   # TIMEOUT_HOLD
    2: 5.0,   # PROFIT_LONG
    3: 15.0,  # LOSS_SHORT (kluczowa lekcja!)
    4: 15.0,  # LOSS_LONG (kluczowa lekcja!)
    5: 2.0    # CHAOS_HOLD
}


# --- Parametry Logowania ---
LOG_LEVEL = logging.INFO
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_FILENAME = 'trainer_xgboost.log' 

# Zapisz tak≈ºe wykresy
SAVE_PLOTS = True


# -----------------------------------------------------------------------------
# USTAWIENIA FUNKCJI STRATY (LOSS FUNCTION)
# -----------------------------------------------------------------------------
# Wybierz funkcjƒô straty: 'categorical_crossentropy' lub 'focal_loss'
# 'focal_loss' jest zalecana przy problemach z niezbalansowanymi klasami.
LOSS_FUNCTION = 'categorical_crossentropy'  # Domy≈õlnie standardowa funkcja

# Parametry dla Focal Loss (ignorowane, je≈õli LOSS_FUNCTION != 'focal_loss')
# ---
# Gamma (Œ≥): Kontroluje tempo, w jakim ≈Çatwe przyk≈Çady sƒÖ "wyciszane".
# Wy≈ºsza gamma bardziej skupia model na trudnych, b≈Çƒôdnie klasyfikowanych przyk≈Çadach.
# Warto≈õƒá 2.0 jest standardowym i dobrym punktem wyj≈õcia.
FOCAL_LOSS_GAMMA = 2.0

# Alpha (Œ±): Kontroluje wagƒô ka≈ºdej z klas. Dzia≈Ça podobnie do `class_weights`.
# Ustaw wy≈ºsze warto≈õci dla klas, kt√≥re model ma problemy poprawnie przewidzieƒá.
# Kolejno≈õƒá: [SHORT, HOLD, LONG]
FOCAL_LOSS_ALPHA = [0.45, 0.1, 0.45]


# -----------------------------------------------------------------------------
# USTAWIENIA BALANSOWANIA DANYCH
# ----------------------------------------------------------------------------- 