"""
Konfiguracja dla nowego, czystego moduu treningowego (`trainer`).
"""
import os
import logging
from training.utils import find_project_root

# ==============================================================================
#  GWNE PARAMETRY KONFIGURACYJNE (DO ZMIANY PRZEZ U呕YTKOWNIKA)
# ==============================================================================

# --- Parametry Danych Wejciowych ---
# Lista par, na kt贸rych model bdzie trenowany.
PAIRS = ["BTCUSDT", "ETHUSDT"] 

# Parametry, na podstawie kt贸rych zostan znalezione odpowiednie pliki cech.
TAKE_PROFIT_PCT = 2.0
STOP_LOSS_PCT = 1.0
FUTURE_WINDOW = 60
TIMEFRAME = "1m"

# --- Nazewnictwo Plik贸w Wejciowych ---
def get_input_filenames() -> list[str]:
    """Dynamicznie generuje list nazw plik贸w wejciowych dla wszystkich par."""
    def format_pct(value):
        return str(value).replace('.', '')

    tp_str = format_pct(TAKE_PROFIT_PCT)
    sl_str = format_pct(STOP_LOSS_PCT)
    
    filenames = []
    for pair in PAIRS:
        # Przykad: BTCUSDT_TP20_SL10_FW60_features.feather
        filename = f"{pair}_TP{tp_str}_SL{sl_str}_FW{FUTURE_WINDOW}_features.feather"
        filenames.append(filename)
    return filenames

# --- cie偶ki ---
# Automatyczne wykrywanie g贸wnego katalogu projektu
# Zakadamy, 偶e ten skrypt jest w podkatalogu 'multi_training'
PROJECT_ROOT = find_project_root()
MODULE_DIR = os.path.join(PROJECT_ROOT, 'multi_training')

# cie偶ka do danych wejciowych (z feature_calculator)
INPUT_DIR = os.path.join(PROJECT_ROOT, 'feature_calculator', 'output')
# Generujemy list penych cie偶ek do plik贸w wejciowych
INPUT_FILENAMES = get_input_filenames()
INPUT_FILE_PATHS = [os.path.join(INPUT_DIR, fname) for fname in INPUT_FILENAMES]


# cie偶ki wyjciowe
OUTPUT_DIR = os.path.join(MODULE_DIR, 'output')
MODEL_DIR = os.path.join(OUTPUT_DIR, 'models')
REPORT_DIR = os.path.join(OUTPUT_DIR, 'reports')
LOG_DIR = os.path.join(OUTPUT_DIR, 'logs')
SCALER_FILENAME = "scaler.pkl"
MODEL_FILENAME = "model.h5"
METADATA_FILENAME = "metadata.json"
PREDICTIONS_FILENAME = "test_predictions.csv"

# --- Parametry Danych ---
SEQUENCE_LENGTH = 120
FEATURES = [
    'high_change', 'low_change', 'close_change', 'volume_change',
    'price_to_ma1440', 'price_to_ma43200', 
    'volume_to_ma1440', 'volume_to_ma43200'
]

# Opcjonalne filtrowanie po dacie
ENABLE_DATE_FILTER = False
START_DATE = "2022-01-01"  # Format: YYYY-MM-DD
END_DATE = "2023-01-01"    # Format: YYYY-MM-DD

# --- Parametry Podziau Danych ---
VALIDATION_SPLIT = 0.15  # 15% na walidacj
TEST_SPLIT = 0.15        # 15% na test
# Reszta (70%) p贸jdzie na trening

# --- Parametry Skalowania ---
SCALER_TYPE = 'robust'  # 'robust', 'standard', 'minmax'

# --- Parametry Treningu ---
EPOCHS = 50
BATCH_SIZE = 2048

# --- Parametry Architektury Modelu LSTM ---
LSTM_UNITS = [128, 64, 32]
DENSE_UNITS = [64, 32]
DROPOUT_RATE = 0.3
LEARNING_RATE = 0.0001

# --- Parametry Callback贸w ---
# EarlyStopping: zatrzymaj, jeli metryka 'val_loss' nie poprawi si przez X epok
EARLY_STOPPING_PATIENCE = 10
# ReduceLROnPlateau: zmniejsz LR, jeli 'val_loss' nie poprawi si przez X epok
REDUCE_LR_PATIENCE = 5
REDUCE_LR_FACTOR = 0.5  # Wsp贸czynnik zmniejszenia LR (new_lr = lr * factor)

# === Parametry Progu Pewnoci (Confidence Thresholding) ===
# Aktywuje filtrowanie predykcji na podstawie ich "pewnoci".
# Predykcje z prawdopodobiestwem ni偶szym ni偶 pr贸g dla danej klasy zostan odrzucone.
ENABLE_CONFIDENCE_THRESHOLDING = True
CONFIDENCE_THRESHOLDS = {
    0: 0.47,  # Pr贸g dla klasy SHORT
    1: 0.30,  # Pr贸g dla klasy HOLD
    2: 0.47   # Pr贸g dla klasy LONG
}

# --- Parametry Balansowania Klas ---
ENABLE_CLASS_BALANCING = True

# --- Parametry Logowania ---
LOG_LEVEL = logging.INFO
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_FILENAME = 'multi_trainer.log' 