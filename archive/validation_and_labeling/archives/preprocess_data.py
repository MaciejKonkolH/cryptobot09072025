#!/usr/bin/env python3
"""
SKRYPT PREPROCESSING DANYCH - BATCH PROCESSING

Zgodnie z planem modyfikacji - MODU≈Å 3: WORKFLOW PRODUKCYJNY
Wykorzystuje istniejƒÖcy DataContinuityChecker do jednorazowego 
przetworzenia i zapisu czystych danych.

U≈ªYCIE:
    python scripts/preprocess_data.py --pair BTCUSDT
    python scripts/preprocess_data.py --input data/raw/ETHUSDT_1m.feather --output data/processed/ETHUSDT_1m_clean.feather

KORZY≈öCI:
- Jednorazowe przetwarzanie zamiast przy ka≈ºdym treningu
- Sp√≥jne dane dla wszystkich eksperyment√≥w
- Szybsze uruchamianie trening√≥w
- Backup czystych danych
"""

import argparse
import sys
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import os
import numpy as np  # Dodajƒô import numpy
import re  # Dodajƒô import re dla regex

# Dodaj ≈õcie≈ºkƒô do modu≈Ç√≥w projektu
sys.path.append(str(Path(__file__).parent.parent))

try:
    from core.utils.data_quality_validator import DataQualityValidator
except ImportError as e:
    print(f"‚ùå B≈ÅƒÑD: Nie mo≈ºna zaimportowaƒá DataQualityValidator: {e}")
    print("   Sprawd≈∫ czy plik core/utils/data_quality_validator.py istnieje")
    sys.exit(1)


class NumpyEncoder(json.JSONEncoder):
    """Custom JSON encoder dla warto≈õci numpy."""
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)


def detect_timeframe_from_filename(filename: str) -> str:
    """
    Wykrywa timeframe z nazwy pliku.
    
    Args:
        filename: Nazwa pliku (np. "BTC_USDT-1m-futures.feather", "BTCUSDT_5m.feather")
        
    Returns:
        str: Wykryty timeframe (np. "1m", "5m", "1h", "1d")
    """
    # Wzorce timeframe w nazwach plik√≥w
    timeframe_patterns = [
        r'[-_](\d+m)[-_.]',     # 1m, 5m, 15m, 30m
        r'[-_](\d+h)[-_.]',     # 1h, 4h, 12h
        r'[-_](\d+d)[-_.]',     # 1d, 7d
        r'[-_](\d+w)[-_.]',     # 1w
        r'[-_](\d+M)[-_.]',     # 1M (miesiƒôczne)
    ]
    
    filename_lower = filename.lower()
    
    for pattern in timeframe_patterns:
        match = re.search(pattern, filename_lower)
        if match:
            return match.group(1)
    
    # Je≈õli nie znaleziono, sprawd≈∫ czy jest na ko≈Ñcu przed rozszerzeniem
    stem = Path(filename).stem.lower()
    
    # Wzorce na ko≈Ñcu nazwy
    end_patterns = [
        r'_(\d+[mhd])$',        # _1m, _5m, _1h, _1d
        r'-(\d+[mhd])$',        # -1m, -5m, -1h, -1d
    ]
    
    for pattern in end_patterns:
        match = re.search(pattern, stem)
        if match:
            return match.group(1)
    
    # Domy≈õlny timeframe je≈õli nie wykryto
    return "1m"


def extract_pair_from_filename(filename: str) -> str:
    """
    WyciƒÖga parƒô walutowƒÖ z nazwy pliku.
    
    Args:
        filename: Nazwa pliku
        
    Returns:
        str: Para walutowa (np. "BTC_USDT", "BTCUSDT")
    """
    stem = Path(filename).stem
    
    # Usu≈Ñ timeframe z nazwy
    timeframe = detect_timeframe_from_filename(filename)
    
    # Usu≈Ñ timeframe i inne sufiksy
    clean_name = stem
    clean_name = re.sub(rf'[-_]{timeframe}[-_.].*$', '', clean_name)
    clean_name = re.sub(rf'[-_]{timeframe}$', '', clean_name)
    clean_name = re.sub(r'[-_]futures$', '', clean_name)
    clean_name = re.sub(r'[-_]spot$', '', clean_name)
    clean_name = re.sub(r'[-_]clean$', '', clean_name)
    clean_name = re.sub(r'[-_]validated$', '', clean_name)
    clean_name = re.sub(r'[-_]fixed$', '', clean_name)
    clean_name = re.sub(r'[-_]test$', '', clean_name)
    
    return clean_name.upper()


def generate_organized_paths(input_path: str, pair: str = None, timeframe: str = None) -> tuple:
    """
    Generuje zorganizowane ≈õcie≈ºki wed≈Çug wzorca {PARA}_{TIMEFRAME}.
    
    Args:
        input_path: ≈öcie≈ºka do pliku wej≈õciowego
        pair: Para walutowa (opcjonalne, wykryje automatycznie)
        timeframe: Timeframe (opcjonalne, wykryje automatycznie)
        
    Returns:
        tuple: (output_path, report_path, folder_name)
    """
    if not pair:
        pair = extract_pair_from_filename(input_path)
    
    if not timeframe:
        timeframe = detect_timeframe_from_filename(input_path)
    
    # Nazwa folderu wed≈Çug wzorca {PARA}_{TIMEFRAME}
    folder_name = f"{pair}_{timeframe}"
    
    # ≈öcie≈ºki wyj≈õciowe
    base_dir = Path("data/validated")
    folder_path = base_dir / folder_name
    
    # Nazwy plik√≥w
    input_filename = Path(input_path).stem
    output_filename = f"{pair}_{timeframe}_validated.feather"
    report_filename = f"{pair}_{timeframe}_quality_report.json"
    
    output_path = folder_path / output_filename
    report_path = folder_path / report_filename
    
    return str(output_path), str(report_path), folder_name


def preprocess_and_save_data(
    input_path: str,
    output_path: str,
    report_path: str,
    min_quality: float = 80.0,
    # NOWE PARAMETRY WALIDACJI JAKO≈öCI:
    enable_quality_validation: bool = True,  # Domy≈õlnie w≈ÇƒÖczone - pe≈Çna walidacja
    quality_checks: list = None,
    anomaly_thresholds: dict = None,
    statistical_thresholds: dict = None,
    # NOWE PARAMETRY COMPETITIVE LABELING:
    enable_competitive_labeling: bool = False,  # Competitive labeling
    competitive_config: dict = None
) -> dict:
    """
    Jednorazowe przetwarzanie i zapis danych z domy≈õlnie w≈ÇƒÖczonƒÖ walidacjƒÖ jako≈õci 
    i opcjonalnym competitive labeling.
    
    Args:
        input_path: ≈öcie≈ºka do surowych danych
        output_path: ≈öcie≈ºka zapisu czystych danych  
        report_path: ≈öcie≈ºka zapisu raportu JSON
        min_quality: Minimalny pr√≥g jako≈õci (%)
        enable_quality_validation: W≈ÇƒÖcz walidacjƒô jako≈õci danych (domy≈õlnie: True)
        quality_checks: Lista sprawdze≈Ñ jako≈õci do wykonania
        anomaly_thresholds: Progi dla wykrywania anomalii cenowych
        statistical_thresholds: Progi dla analizy statystycznej
        enable_competitive_labeling: W≈ÇƒÖcz labeling konkurencyjne (domy≈õlnie: False)
        competitive_config: Konfiguracja labeling konkurencyjnego (TP/SL/WINDOW)
        
    Returns:
        dict: Statystyki preprocessing
    """
    print(f"üîÑ PREPROCESSING DANYCH")
    print(f"   Wej≈õcie: {input_path}")
    print(f"   Wyj≈õcie: {output_path}")
    print(f"   Raport: {report_path}")
    print(f"   Min. jako≈õƒá: {min_quality}%")
    if enable_quality_validation:
        print(f"   Walidacja jako≈õci: W≈ÅƒÑCZONA")
        print(f"   Sprawdzenia: {', '.join(quality_checks) if quality_checks else 'wszystkie'}")
    else:
        print(f"   Walidacja jako≈õci: wy≈ÇƒÖczona (tylko ciƒÖg≈Ço≈õƒá)")
    
    if enable_competitive_labeling:
        print(f"   Competitive labeling: W≈ÅƒÑCZONY")
        if competitive_config:
            print(f"   Parametry TP/SL: LONG {competitive_config.get('LONG_TP_PCT', 0.01)*100:.1f}%/{competitive_config.get('LONG_SL_PCT', 0.005)*100:.1f}%, SHORT {competitive_config.get('SHORT_TP_PCT', 0.01)*100:.1f}%/{competitive_config.get('SHORT_SL_PCT', 0.005)*100:.1f}%")
            print(f"   Future window: {competitive_config.get('FUTURE_WINDOW', 120)} minut")
        else:
            print(f"   Parametry: domy≈õlne (TP 1.0%, SL 0.5%, okno 120min)")
    else:
        print(f"   Competitive labeling: wy≈ÇƒÖczony")
    print("-" * 50)
    
    # 1. Sprawd≈∫ czy plik wej≈õciowy istnieje
    if not Path(input_path).exists():
        raise FileNotFoundError(f"Plik wej≈õciowy nie istnieje: {input_path}")
    
    # 2. Utw√≥rz katalogi wyj≈õciowe je≈õli nie istniejƒÖ
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    Path(report_path).parent.mkdir(parents=True, exist_ok=True)
    
    # 3. Za≈Çaduj surowe dane
    print("üìÇ ≈Åadowanie surowych danych...")
    try:
        if input_path.endswith('.feather'):
            df_raw = pd.read_feather(input_path)
            # Sprawd≈∫ czy jest kolumna timestamp i ustaw jako index
            if 'timestamp' in df_raw.columns:
                df_raw = df_raw.set_index('timestamp')
                # Sprawd≈∫ czy to Unix timestamp w milisekundach
                if df_raw.index.dtype in ['int64', 'float64']:
                    # Unix timestamp w milisekundach - konwertuj poprawnie
                    df_raw.index = pd.to_datetime(df_raw.index, unit='ms')
                else:
                    df_raw.index = pd.to_datetime(df_raw.index)
            elif 'index' in df_raw.columns:
                # Kolumna 'index' zawiera timestamp
                df_raw = df_raw.set_index('index')
                # Sprawd≈∫ czy to Unix timestamp w milisekundach
                if df_raw.index.dtype in ['int64', 'float64']:
                    df_raw.index = pd.to_datetime(df_raw.index, unit='ms')
                else:
                    df_raw.index = pd.to_datetime(df_raw.index)
            elif df_raw.index.name == 'timestamp' or isinstance(df_raw.index, pd.DatetimeIndex):
                # Index ju≈º jest ustawiony poprawnie
                pass
            else:
                # Sprawd≈∫ czy pierwsza kolumna to timestamp
                if df_raw.columns[0] in ['timestamp', 'date', 'datetime', 'index']:
                    df_raw = df_raw.set_index(df_raw.columns[0])
                    # Sprawd≈∫ czy to Unix timestamp w milisekundach
                    if df_raw.index.dtype in ['int64', 'float64']:
                        df_raw.index = pd.to_datetime(df_raw.index, unit='ms')
                    else:
                        df_raw.index = pd.to_datetime(df_raw.index)
                else:
                    raise ValueError("Nie mo≈ºna znale≈∫ƒá kolumny timestamp w danych feather")
        elif input_path.endswith('.csv'):
            df_raw = pd.read_csv(input_path, index_col=0, parse_dates=True)
        elif input_path.endswith('.parquet'):
            df_raw = pd.read_parquet(input_path)
        else:
            raise ValueError(f"Nieobs≈Çugiwany format pliku: {input_path}")
            
        print(f"   ‚úÖ Za≈Çadowano {len(df_raw)} ≈õwiec")
        print(f"   üìÖ Zakres: {df_raw.index[0]} ‚Üí {df_raw.index[-1]}")
        
    except Exception as e:
        raise RuntimeError(f"B≈ÇƒÖd ≈Çadowania danych: {e}")
    
    # 4. Sprawd≈∫ i uzupe≈Çnij luki u≈ºywajƒÖc DataContinuityChecker
    print("üîç Sprawdzanie ciƒÖg≈Ço≈õci danych...")
    
    # Wykryj timeframe z nazwy pliku
    timeframe = detect_timeframe_from_filename(input_path)
    print(f"   Wykryto timeframe: {timeframe}")
    
    # Utw√≥rz validator z wszystkimi parametrami
    validator = DataQualityValidator(
        timeframe=timeframe,
        tolerance_seconds=60,
        enable_quality_validation=enable_quality_validation,
        quality_checks=quality_checks,
        anomaly_thresholds=anomaly_thresholds,
        statistical_thresholds=statistical_thresholds,
        enable_competitive_labeling=enable_competitive_labeling,
        competitive_config=competitive_config
    )
    
    # Sprawd≈∫ i napraw dane
    df_clean, report = validator.check_and_fill_gaps(df_raw)
    
    # 5. Oce≈Ñ jako≈õƒá danych
    quality_score = report['quality_score']
    comprehensive_score = report.get('comprehensive_quality_score')
    
    print(f"üìä WYNIKI ANALIZY:")
    print(f"   Oryginalne ≈õwiece: {report['original_candles']}")
    print(f"   Wykryte luki: {report['gaps_detected']}")
    print(f"   Dodane ≈õwiece: {report['candles_added']}")
    print(f"   Finalne ≈õwiece: {len(df_clean)}")
    print(f"   Jako≈õƒá danych (ciƒÖg≈Ço≈õƒá): {quality_score:.1f}%")
    
    if enable_quality_validation and comprehensive_score is not None:
        print(f"   Kompleksowa jako≈õƒá: {comprehensive_score:.1f}%")
        print(f"   Status jako≈õci: {report.get('comprehensive_quality_status', 'N/A')}")
        
        # Poka≈º breakdown je≈õli dostƒôpny
        if 'quality_breakdown' in report:
            breakdown = report['quality_breakdown']
            print(f"   Breakdown jako≈õci:")
            print(f"     - CiƒÖg≈Ço≈õƒá: {breakdown['continuity_score']:.1f}%")
            if breakdown.get('ohlcv_logic_score') is not None:
                print(f"     - OHLCV Logic: {breakdown['ohlcv_logic_score']:.1f}%")
            if breakdown.get('anomaly_score') is not None:
                print(f"     - Anomalie: {breakdown['anomaly_score']:.1f}%")
            if breakdown.get('statistical_score') is not None:
                print(f"     - Statystyki: {breakdown['statistical_score']:.1f}%")
        
        # Poka≈º podsumowanie problem√≥w
        if 'validation_summary' in report:
            summary = report['validation_summary']
            if summary['total_issues'] > 0:
                print(f"   Problemy z jako≈õciƒÖ:")
                print(f"     - ≈ÅƒÖcznie: {summary['total_issues']}")
                print(f"     - Krytyczne: {summary['critical_issues']}")
                print(f"     - Ostrze≈ºenia: {summary['warnings']}")
        
        # U≈ºyj comprehensive score do oceny progu
        final_score = comprehensive_score
    else:
        final_score = quality_score
    
    # 6. Sprawd≈∫ pr√≥g jako≈õci
    if final_score < min_quality:
        print(f"‚ö†Ô∏è  OSTRZE≈ªENIE: Jako≈õƒá danych ({final_score:.1f}%) poni≈ºej progu ({min_quality}%)")
        print("   Dane zostanƒÖ zapisane, ale mogƒÖ wymagaƒá uwagi")
    else:
        print(f"‚úÖ Jako≈õƒá danych powy≈ºej progu - dane gotowe do u≈ºycia")
    
    # 7. Zapisz czyste dane
    print("üíæ Zapisywanie czystych danych...")
    try:
        if output_path.endswith('.feather'):
            df_clean.reset_index().to_feather(output_path)
        elif output_path.endswith('.csv'):
            df_clean.to_csv(output_path)
        elif output_path.endswith('.parquet'):
            df_clean.to_parquet(output_path)
        else:
            # Domy≈õlnie feather
            output_path = output_path.replace('.', '_clean.feather')
            df_clean.reset_index().to_feather(output_path)
            
        print(f"   ‚úÖ Zapisano: {output_path}")
        
    except Exception as e:
        raise RuntimeError(f"B≈ÇƒÖd zapisu danych: {e}")
    
    # 8. Przygotuj rozszerzony raport
    extended_report = {
        **report,
        'preprocessing_info': {
            'timestamp': datetime.now().isoformat(),
            'input_path': input_path,
            'output_path': output_path,
            'min_quality_threshold': min_quality,
            'quality_passed': final_score >= min_quality,
            'file_size_mb': round(Path(output_path).stat().st_size / 1024 / 1024, 2)
        }
    }
    
    # 9. Zapisz raport JSON
    print("üìã Zapisywanie raportu...")
    try:
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(extended_report, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
        print(f"   ‚úÖ Zapisano: {report_path}")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  B≈ÇƒÖd zapisu raportu: {e}")
    
    # 10. Podsumowanie
    print(f"\n‚úÖ PREPROCESSING ZAKO≈ÉCZONY")
    print(f"   Status: {'‚úÖ PASSED' if final_score >= min_quality else '‚ö†Ô∏è BELOW THRESHOLD'}")
    print(f"   Jako≈õƒá: {final_score:.1f}%")
    print(f"   Pliki zapisane:")
    print(f"     Dane: {output_path}")
    print(f"     Raport: {report_path}")
    
    # Dodatkowe informacje o competitive labeling
    if 'competitive_labeling' in report and report['competitive_labeling'].get('enabled'):
        labeling_info = report['competitive_labeling']
        if labeling_info.get('labels_generated', 0) > 0:
            print(f"   Competitive labeling:")
            print(f"     Etykiety: {labeling_info['labels_generated']:,}")
            for label, count in labeling_info['label_distribution'].items():
                percentage = labeling_info['label_percentages'][label]
                print(f"     {label}: {count:,} ({percentage:.1f}%)")
    
    # Zwr√≥ƒá rozszerzone statystyki
    stats = {
        'quality_score': final_score,
        'quality_passed': final_score >= min_quality,
        'input_candles': report['original_candles'],
        'final_candles': len(df_clean),
        'added_candles': report['candles_added'],
        'gaps_detected': report['gaps_detected'],
        'processing_time': datetime.now().isoformat(),
        'enable_quality_validation': enable_quality_validation,
        'enable_competitive_labeling': enable_competitive_labeling
    }
    
    # Dodaj statystyki competitive labeling je≈õli dostƒôpne
    if 'competitive_labeling' in report and report['competitive_labeling'].get('enabled'):
        labeling_info = report['competitive_labeling']
        stats['competitive_labeling'] = {
            'labels_generated': labeling_info.get('labels_generated', 0),
            'label_distribution': labeling_info.get('label_distribution', {}),
            'parameters': labeling_info.get('labeling_parameters', {})
        }
    
    return stats


def main():
    """G≈Ç√≥wna funkcja skryptu"""
    parser = argparse.ArgumentParser(
        description="Preprocessing danych historycznych - uzupe≈Çnianie luk",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PRZYK≈ÅADY U≈ªYCIA:

  # Podstawowe u≈ºycie - automatyczna organizacja folder√≥w
  python scripts/preprocess_data.py --pair BTCUSDT
  # Utworzy: data/validated/BTC_USDT_1m/BTC_USDT_1m_validated.feather
  #          data/validated/BTC_USDT_1m/BTC_USDT_1m_quality_report.json
  
  # Z okre≈õlonym timeframe
  python scripts/preprocess_data.py --pair BTCUSDT --timeframe 5m
  # Utworzy: data/validated/BTC_USDT_5m/BTC_USDT_5m_validated.feather
  
  # Tylko ciƒÖg≈Ço≈õƒá danych (bez walidacji jako≈õci)
  python scripts/preprocess_data.py --pair BTCUSDT --disable-quality-validation
  
  # Automatyczna organizacja z pliku wej≈õciowego
  python scripts/preprocess_data.py --input "ft_bot_docker_compose/user_data/data/binanceusdm/futures/BTC_USDT-1m-futures.feather"
  # Wykryje: para=BTC_USDT, timeframe=1m
  # Utworzy: data/validated/BTC_USDT_1m/BTC_USDT_1m_validated.feather
  
  # Z niestandardowymi progami (pe≈Çna walidacja)
  python scripts/preprocess_data.py --pair BTCUSDT \\
    --price-jump-threshold 3.0 \\
    --outlier-sigma 2.5 \\
    --min-quality 85
    
  # Rƒôczne ≈õcie≈ºki (stary spos√≥b)
  python scripts/preprocess_data.py \\
    --input data/raw/ETHUSDT_1m.feather \\
    --output data/custom/ETHUSDT_clean.feather \\
    --report data/custom/ETHUSDT_report.json
    
  # Tylko wybrane sprawdzenia jako≈õci
  python scripts/preprocess_data.py --pair ADAUSDT \\
    --quality-checks price_anomalies \\
    --price-jump-threshold 2.0
    
  # Szybkie przetwarzanie bez walidacji jako≈õci
  python scripts/preprocess_data.py --pair BTCUSDT \\
    --disable-quality-validation \\
    --min-quality 70

STRUKTURA FOLDER√ìW:
  data/validated/
  ‚îú‚îÄ‚îÄ BTC_USDT_1m/
  ‚îÇ   ‚îú‚îÄ‚îÄ BTC_USDT_1m_validated.feather
  ‚îÇ   ‚îî‚îÄ‚îÄ BTC_USDT_1m_quality_report.json
  ‚îú‚îÄ‚îÄ BTC_USDT_5m/
  ‚îÇ   ‚îú‚îÄ‚îÄ BTC_USDT_5m_validated.feather
  ‚îÇ   ‚îî‚îÄ‚îÄ BTC_USDT_5m_quality_report.json
  ‚îî‚îÄ‚îÄ ETH_USDT_1h/
      ‚îú‚îÄ‚îÄ ETH_USDT_1h_validated.feather
      ‚îî‚îÄ‚îÄ ETH_USDT_1h_quality_report.json
        """
    )
    
    # Grupa argument√≥w - albo --pair albo rƒôczne ≈õcie≈ºki
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        '--pair',
        type=str,
        help='Para walutowa (np. BTCUSDT) - automatyczne ≈õcie≈ºki'
    )
    group.add_argument(
        '--input',
        type=str,
        help='≈öcie≈ºka do surowych danych'
    )
    
    # Opcjonalne argumenty
    parser.add_argument(
        '--timeframe',
        type=str,
        help='Timeframe (np. 1m, 5m, 1h, 1d) - wykryje automatycznie je≈õli nie podano'
    )
    parser.add_argument(
        '--output',
        type=str,
        help='≈öcie≈ºka zapisu czystych danych (opcjonalne - automatyczne je≈õli nie podano)'
    )
    parser.add_argument(
        '--report',
        type=str,
        help='≈öcie≈ºka zapisu raportu JSON (opcjonalne - automatyczne je≈õli nie podano)'
    )
    parser.add_argument(
        '--min-quality',
        type=float,
        default=80.0,
        help='Minimalny pr√≥g jako≈õci danych w %% (domy≈õlnie: 80.0)'
    )
    
    # NOWE ARGUMENTY WALIDACJI JAKO≈öCI
    parser.add_argument(
        '--disable-quality-validation',
        action='store_true',
        help='Wy≈ÇƒÖcz walidacjƒô jako≈õci danych (domy≈õlnie: w≈ÇƒÖczona)'
    )
    parser.add_argument(
        '--quality-checks',
        type=str,
        help='Lista sprawdze≈Ñ jako≈õci oddzielona przecinkami (ohlcv_logic,price_anomalies,statistical_patterns)'
    )
    parser.add_argument(
        '--price-jump-threshold',
        type=float,
        help='Pr√≥g dla skok√≥w cenowych w %% (domy≈õlnie: 5.0)'
    )
    parser.add_argument(
        '--outlier-sigma',
        type=float,
        help='Pr√≥g dla outliers w sigma (domy≈õlnie: 3.0)'
    )
    parser.add_argument(
        '--extreme-spread-threshold',
        type=float,
        help='Pr√≥g dla ekstremalnych spread√≥w w %% (domy≈õlnie: 20.0)'
    )
    parser.add_argument(
        '--flash-crash-threshold',
        type=float,
        help='Pr√≥g dla flash crashes w %% (domy≈õlnie: -10.0)'
    )
    parser.add_argument(
        '--uniqueness-min',
        type=float,
        default=0.1,
        help='Minimalny pr√≥g unikalno≈õci (domy≈õlnie: 0.1)'
    )
    parser.add_argument(
        '--volatility-max',
        type=float,
        default=0.1,
        help='Maksymalny pr√≥g volatility (domy≈õlnie: 0.1)'
    )
    
    # PARAMETRY COMPETITIVE LABELING
    parser.add_argument('--enable-competitive-labeling', action='store_true',
                       help='W≈ÇƒÖcz competitive labeling (etykietowanie danych)')
    parser.add_argument('--long-tp', type=float, default=1.0,
                       help='LONG Take Profit w procentach (domy≈õlnie: 1.0)')
    parser.add_argument('--long-sl', type=float, default=0.5,
                       help='LONG Stop Loss w procentach (domy≈õlnie: 0.5)')
    parser.add_argument('--short-tp', type=float, default=1.0,
                       help='SHORT Take Profit w procentach (domy≈õlnie: 1.0)')
    parser.add_argument('--short-sl', type=float, default=0.5,
                       help='SHORT Stop Loss w procentach (domy≈õlnie: 0.5)')
    parser.add_argument('--future-window', type=int, default=120,
                       help='Okno przysz≈Ço≈õci w minutach (domy≈õlnie: 120)')
    
    args = parser.parse_args()
    
    # Walidacja argument√≥w - teraz --output nie jest wymagane
    # Automatycznie wygenerujemy ≈õcie≈ºki je≈õli nie podano
    
    # Okre≈õl ≈õcie≈ºki
    if args.pair:
        # Automatyczne ≈õcie≈ºki na podstawie pary
        pair = args.pair.upper()
        timeframe = args.timeframe or "1m"  # Domy≈õlny timeframe
        
        # Znajd≈∫ plik wej≈õciowy - sprawd≈∫ r√≥≈ºne lokalizacje
        possible_inputs = [
            f"data/raw/{pair}_{timeframe}.feather",
            f"data/raw/{pair}-{timeframe}.feather", 
            f"data/processed/{pair}_{timeframe}.feather",
            f"data/processed/{pair}-{timeframe}.feather",
            f"ft_bot_docker_compose/user_data/data/binanceusdm/futures/{pair}-{timeframe}-futures.feather",
            f"ft_bot_docker_compose/user_data/data/binanceusdm/futures/{pair}_{timeframe}_futures.feather"
        ]
        
        input_path = None
        for possible_path in possible_inputs:
            if Path(possible_path).exists():
                input_path = possible_path
                break
        
        if not input_path:
            print(f"‚ùå B≈ÅƒÑD: Nie znaleziono pliku dla pary {pair} i timeframe {timeframe}")
            print("   Sprawdzone lokalizacje:")
            for path in possible_inputs:
                print(f"     - {path}")
            sys.exit(1)
        
        # Wygeneruj zorganizowane ≈õcie≈ºki
        output_path, report_path, folder_name = generate_organized_paths(input_path, pair, timeframe)
        
    else:
        # Rƒôczne ≈õcie≈ºki
        input_path = args.input
        
        if not Path(input_path).exists():
            print(f"‚ùå B≈ÅƒÑD: Plik wej≈õciowy nie istnieje: {input_path}")
            sys.exit(1)
        
        # Je≈õli nie podano output/report, wygeneruj automatycznie
        if args.output or args.report:
            # U≈ºytkownik poda≈Ç w≈Çasne ≈õcie≈ºki
            output_path = args.output
            report_path = args.report
            folder_name = "custom"
            
            if not output_path:
                # Wygeneruj output na podstawie input
                output_path, report_path, folder_name = generate_organized_paths(
                    input_path, timeframe=args.timeframe
                )
            elif not report_path:
                # Wygeneruj tylko report
                _, report_path, _ = generate_organized_paths(
                    input_path, timeframe=args.timeframe
                )
        else:
            # Automatyczne ≈õcie≈ºki
            output_path, report_path, folder_name = generate_organized_paths(
                input_path, timeframe=args.timeframe
            )
    
    # Wy≈õwietl informacje o organizacji
    print(f"üìÅ ORGANIZACJA PLIK√ìW:")
    print(f"   Folder: {folder_name}")
    print(f"   Wej≈õcie: {input_path}")
    print(f"   Wyj≈õcie: {output_path}")
    print(f"   Raport: {report_path}")
    print()
    
    try:
        # NOWE: Przygotuj parametry walidacji jako≈õci
        quality_checks = None
        if args.quality_checks:
            quality_checks = [check.strip() for check in args.quality_checks.split(',')]
            # Waliduj nazwy sprawdze≈Ñ
            valid_checks = ['ohlcv_logic', 'price_anomalies', 'statistical_patterns']
            invalid_checks = [check for check in quality_checks if check not in valid_checks]
            if invalid_checks:
                parser.error(f"Nieprawid≈Çowe sprawdzenia jako≈õci: {invalid_checks}. Dostƒôpne: {valid_checks}")
        
        # Przygotuj progi anomalii
        anomaly_thresholds = {}
        if args.price_jump_threshold is not None:
            anomaly_thresholds['price_jump'] = args.price_jump_threshold / 100.0  # Konwersja % na u≈Çamek
        if args.outlier_sigma is not None:
            anomaly_thresholds['outlier_sigma'] = args.outlier_sigma
        if args.extreme_spread_threshold is not None:
            anomaly_thresholds['extreme_spread'] = args.extreme_spread_threshold / 100.0
        if args.flash_crash_threshold is not None:
            anomaly_thresholds['flash_crash'] = args.flash_crash_threshold / 100.0
        
        # Konfiguracja prog√≥w statystycznych
        statistical_thresholds = {
            'uniqueness_min': args.uniqueness_min,
            'volatility_max': args.volatility_max
        }
        
        # NOWA: Konfiguracja competitive labeling
        competitive_config = None
        if args.enable_competitive_labeling:
            competitive_config = {
                'LONG_TP_PCT': args.long_tp / 100.0,   # Konwersja % na decimal
                'LONG_SL_PCT': args.long_sl / 100.0,   # Konwersja % na decimal
                'SHORT_TP_PCT': args.short_tp / 100.0, # Konwersja % na decimal
                'SHORT_SL_PCT': args.short_sl / 100.0, # Konwersja % na decimal
                'FUTURE_WINDOW': args.future_window
            }
        
        print(f"üöÄ Uruchamianie preprocessing...")
        
        # Wykonaj preprocessing
        stats = preprocess_and_save_data(
            input_path=input_path,
            output_path=output_path,
            report_path=report_path,
            min_quality=args.min_quality,
            enable_quality_validation=not args.disable_quality_validation,
            quality_checks=quality_checks,
            anomaly_thresholds=anomaly_thresholds,
            statistical_thresholds=statistical_thresholds,
            enable_competitive_labeling=args.enable_competitive_labeling,
            competitive_config=competitive_config
        )
        
        # Podsumowanie
        print(f"\nüìà STATYSTYKI KO≈ÉCOWE:")
        print(f"   Wej≈õcie: {stats['input_candles']:,} ≈õwiec")
        print(f"   Wyj≈õcie: {stats['final_candles']:,} ≈õwiec")
        print(f"   Dodane: {stats['added_candles']:,} ≈õwiec")
        print(f"   Luki: {stats['gaps_detected']}")
        print(f"   Jako≈õƒá: {stats['quality_score']:.1f}%")
        print(f"   Status: {'‚úÖ PASSED' if stats['quality_passed'] else '‚ö†Ô∏è BELOW THRESHOLD'}")
        
        if not stats['quality_passed']:
            print(f"\n‚ö†Ô∏è  UWAGA: Jako≈õƒá danych poni≈ºej progu {args.min_quality}%")
            print("   Sprawd≈∫ raport i rozwa≈º u≈ºycie danych z ostro≈ºno≈õciƒÖ")
            sys.exit(2)  # Exit code 2 = warning
        
    except Exception as e:
        print(f"\n‚ùå B≈ÅƒÑD PREPROCESSING: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 