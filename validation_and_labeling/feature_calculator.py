"""
ModuÅ‚ obliczania features technicznych z danych OHLCV
Implementuje algorytm obliczania 8 features: zmiany procentowe, Å›rednie kroczÄ…ce, stosunki do MA, volume features
"""
import logging
import pandas as pd
import pandas_ta as ta
import numpy as np
import sys
import os
from typing import Dict, Any, Tuple, List

# ObsÅ‚uga importÃ³w
try:
    from . import config
    from .utils import setup_logging, ProgressReporter
except ImportError:
    # Standalone script
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    import config
    from utils import setup_logging, ProgressReporter

class FeatureCalculator:
    """Klasa odpowiedzialna za obliczanie features technicznych"""
    
    def __init__(self):
        self.logger = setup_logging(f"{__name__}.FeatureCalculator")
    
    def calculate_features(self, df: pd.DataFrame, pair_name: str = "") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        Oblicza 8 features technicznych zgodnie z algorytmem z planu
        
        Args:
            df: Dane OHLCV po walidacji i wypeÅ‚nieniu luk
            pair_name: Nazwa pary (do logowania)
            
        Returns:
            Tuple[pd.DataFrame, Dict]: (dane_z_features, raport_obliczen)
        """
        self.logger.info(f"Rozpoczynam obliczanie features dla {pair_name}")
        
        features_report = {
            "input_rows": len(df),
            "features_calculated": [],
            "ma_calculation_method": "expanding_window",
            "features_anomalies": {}
        }
        
        if len(df) == 0:
            self.logger.warning("Brak danych do obliczenia features")
            return df, features_report
        
        # Kopia DataFrame Å¼eby nie modyfikowaÄ‡ oryginaÅ‚u
        df_features = df.copy()
        
        try:
            # Progress reporter dla dÅ‚ugich operacji
            progress = ProgressReporter(len(df), self.logger)
            
            # KROK 1: OBLICZ ZMIANY PROCENTOWE (3 features)
            df_features = self._calculate_percentage_changes(df_features, features_report)
            progress.update(len(df) // 4, pair_name)
            
            # KROK 2: OBLICZ ÅšREDNIE KROCZÄ„CE (na dostÄ™pnych danych)
            df_features = self._calculate_moving_averages(df_features, features_report, pair_name)
            progress.update(len(df) // 2, pair_name)
            
            # KROK 3: OBLICZ STOSUNKI DO MA (2 features)
            df_features = self._calculate_ma_ratios(df_features, features_report)
            progress.update(3 * len(df) // 4, pair_name)
            
            # KROK 4: OBLICZ VOLUME FEATURES (3 features)
            df_features = self._calculate_volume_features(df_features, features_report)
            progress.update(len(df), pair_name)
            
            # KROK 4: ZBIERZ WSZYSTKIE OBLICZONE FEATURES
            self.logger.debug("FinalizujÄ™ DataFrame z features")

            feature_columns = [
                'high_change', 'low_change', 'close_change', 'volume_change',
                'price_to_ma1440', 'price_to_ma43200',
                'volume_to_ma1440', 'volume_to_ma43200'
            ]

            # âœ… ZACHOWAJ DATETIME INDEX - nie usuwaj informacji czasowej!
            df_final = df_features[feature_columns].copy()
            # Datetime index zostaje zachowany automatycznie

            features_report["output_rows"] = len(df_final)
            features_report["features_calculated"] = feature_columns

            progress.finish(pair_name)

            self.logger.info(
                f"Features dla {pair_name} obliczone: {len(feature_columns)} kolumn, "
                f"{len(df_final):,} wierszy"
            )

            # ğŸ”¥ KLUCZOWA POPRAWKA: OdrzuÄ‡ pierwsze 30 dni (43200 Å›wiec), aby zapewniÄ‡
            # Å¼e wszystkie wartoÅ›ci MA sÄ… obliczone na peÅ‚nym oknie historycznym.
            # To gwarantuje 100% zgodnoÅ›Ä‡ z logikÄ… bufora strategii.
            warmup_period = config.MA_LONG_WINDOW
            if len(df_final) > warmup_period:
                self.logger.info(f"Odrzucam okres rozgrzewkowy {warmup_period} Å›wiec dla zapewnienia poprawnoÅ›ci MA...")
                df_final = df_final.iloc[warmup_period:].copy()
                self.logger.info(f"âœ… Finalna liczba wierszy po odrzuceniu okresu rozgrzewkowego: {len(df_final):,}")
            else:
                self.logger.warning(
                    f"Za maÅ‚o danych ({len(df_final)}) do odrzucenia peÅ‚nego okresu rozgrzewkowego ({warmup_period}). "
                    f"Zwracam pusty DataFrame, aby uniknÄ…Ä‡ bÅ‚Ä™dÃ³w."
                )
                # ZwrÃ³Ä‡ pusty dataframe z tymi samymi kolumnami
                return pd.DataFrame(columns=df_final.columns), features_report
            
            return df_final, features_report
            
        except Exception as e:
            self.logger.error(f"BÅ‚Ä…d podczas obliczania features {pair_name}: {str(e)}")
            raise
    
    def _calculate_percentage_changes(self, df: pd.DataFrame, report: Dict[str, Any]) -> pd.DataFrame:
        """
        ALGORYTM OBLICZANIA FEATURES - KROK 1: OBLICZ ZMIANY PROCENTOWE (3 features)
        """
        self.logger.debug("Obliczam zmiany procentowe")
        
        # high_change = (high[t] - close[t-1]) / close[t-1] * 100
        df['close_prev'] = df['close'].shift(1)
        df['high_change'] = ((df['high'] - df['close_prev']) / df['close_prev'] * 100)
        
        # low_change = (low[t] - close[t-1]) / close[t-1] * 100  
        df['low_change'] = ((df['low'] - df['close_prev']) / df['close_prev'] * 100)
        
        # close_change = (close[t] - close[t-1]) / close[t-1] * 100
        df['close_change'] = ((df['close'] - df['close_prev']) / df['close_prev'] * 100)
        
        # UsuÅ„ pomocniczÄ… kolumnÄ™
        df.drop(['close_prev'], axis=1, inplace=True)
        
        # Pierwsza Å›wieca bÄ™dzie miaÅ‚a NaN. WypeÅ‚nij metodÄ… back-fill,
        # aby zreplikowaÄ‡ zachowanie Freqtrade i zapewniÄ‡ spÃ³jnoÅ›Ä‡ danych.
        for col in ['high_change', 'low_change', 'close_change']:
            df[col] = df[col].bfill()
        
        # Po bfill() pierwszy wiersz moÅ¼e nadal byÄ‡ NaN, jeÅ›li caÅ‚y zbiÃ³r jest krÃ³tki.
        # WypeÅ‚nij zerem jako ostateczny fallback.
        df.fillna(0, inplace=True)
        
        self.logger.debug("Zmiany procentowe obliczone")
        
        return df
    
    def _calculate_moving_averages(self, df: pd.DataFrame, report: Dict[str, Any], 
                                 pair_name: str = "") -> pd.DataFrame:
        """
        ALGORYTM OBLICZANIA FEATURES - KROK 2: OBLICZ ÅšREDNIE KROCZÄ„CE (na dostÄ™pnych danych)
        """
        self.logger.debug("Obliczam Å›rednie kroczÄ…ce na dostÄ™pnych danych")
        
        # MA_1440 (1 dzieÅ„ = 1440 minut) - Å›rednia na dostÄ™pnych danych
        df['ma_close_1440'] = self._calculate_expanding_ma(df['close'], config.MA_SHORT_WINDOW)
        
        # MA_43200 (30 dni = 43200 minut) - Å›rednia na dostÄ™pnych danych  
        df['ma_close_43200'] = self._calculate_expanding_ma(df['close'], config.MA_LONG_WINDOW)
        
        # Åšrednie kroczÄ…ce dla volume (potrzebne do volume features)
        df['ma_volume_1440'] = self._calculate_expanding_ma(df['volume'], config.MA_SHORT_WINDOW)
        df['ma_volume_43200'] = self._calculate_expanding_ma(df['volume'], config.MA_LONG_WINDOW)
        
        self.logger.debug(
            f"Åšrednie kroczÄ…ce obliczone: okna {config.MA_SHORT_WINDOW} i {config.MA_LONG_WINDOW}"
        )
        
        return df
    
    def _calculate_expanding_ma(self, series: pd.Series, max_window: int) -> pd.Series:
        """
        Oblicza Å›redniÄ… kroczÄ…cÄ… na dostÄ™pnych danych zgodnie ze specyfikacjÄ…:
        - Åšwieca 1: MA = current_value
        - Åšwieca 2: MA = (value1 + value2) / 2
        - ...
        - Åšwieca max_window+: MA = mean(value[t-max_window+1:t+1])
        
        OPTIMIZED VERSION: O(n) complexity using pandas built-in methods
        """
        # FAZA 1: Expanding window (rosnÄ…ce okno do max_window)
        expanding_ma = series.expanding().mean()
        
        # FAZA 2: Rolling window (staÅ‚e okno max_window) 
        rolling_ma = series.rolling(window=max_window, min_periods=1).mean()
        
        # POÅÄ„CZ: expanding do max_window, potem rolling dla reszty
        result = expanding_ma.copy()
        
        # JeÅ›li mamy wiÄ™cej danych niÅ¼ max_window, uÅ¼yj rolling dla dalszych Å›wiec
        if len(series) > max_window:
            result.iloc[max_window-1:] = rolling_ma.iloc[max_window-1:]
        
        return result
    
    def _calculate_ma_ratios(self, df: pd.DataFrame, report: Dict[str, Any]) -> pd.DataFrame:
        """
        ALGORYTM OBLICZANIA FEATURES - KROK 3: OBLICZ STOSUNKI DO MA (2 features)
        """
        self.logger.debug("Obliczam stosunki ceny do Å›rednich kroczÄ…cych")
        
        # price_to_ma1440 = close[t] / MA_1440[t]
        df['price_to_ma1440'] = df['close'] / df['ma_close_1440']
        
        # price_to_ma43200 = close[t] / MA_43200[t]
        df['price_to_ma43200'] = df['close'] / df['ma_close_43200']
        
        # Zabezpieczenie przed dzieleniem przez zero (nie powinno siÄ™ zdarzyÄ‡, ale...)
        df.loc[:, 'price_to_ma1440'] = df['price_to_ma1440'].replace([np.inf, -np.inf], 1.0)
        df.loc[:, 'price_to_ma43200'] = df['price_to_ma43200'].replace([np.inf, -np.inf], 1.0)
        
        self.logger.debug("Stosunki do MA obliczone")
        
        return df
    
    def _calculate_volume_features(self, df: pd.DataFrame, report: Dict[str, Any]) -> pd.DataFrame:
        """
        ALGORYTM OBLICZANIA FEATURES - KROK 4: OBLICZ VOLUME FEATURES (3 features)
        """
        self.logger.debug("Obliczam volume features")
        
        # ğŸ”¥ UsuniÄ™to epsilon, aby zapewniÄ‡ 100% zgodnoÅ›Ä‡ z logikÄ… Freqtrade.
        # Dodano obsÅ‚ugÄ™ dzielenia przez zero przez zastÄ…pienie `inf` wartoÅ›ciami.
        
        # volume_to_ma1440 = volume[t] / MA_volume_1440[t]
        df['volume_to_ma1440'] = df['volume'] / df['ma_volume_1440']
        
        # volume_to_ma43200 = volume[t] / MA_volume_43200[t]
        df['volume_to_ma43200'] = df['volume'] / df['ma_volume_43200']
        
        # volume_change = (volume[t] - volume[t-1]) / volume[t-1] * 100
        df['volume_prev'] = df['volume'].shift(1)
        df['volume_change'] = ((df['volume'] - df['volume_prev']) / df['volume_prev'] * 100)
        
        # UsuÅ„ pomocniczÄ… kolumnÄ™
        df.drop(['volume_prev'], axis=1, inplace=True)
        
        # ZastÄ…p potencjalne NaN/Inf, ktÃ³re mogÅ‚y powstaÄ‡, bezpiecznymi wartoÅ›ciami
        # UÅ¼yj bfill() dla volume_change, aby zachowaÄ‡ spÃ³jnoÅ›Ä‡ z Freqtrade
        df['volume_change'] = df['volume_change'].bfill()
        
        # ğŸ”¥ Zabezpieczenie przed dzieleniem przez zero: zastÄ…p nieskoÅ„czonoÅ›ci zerami/jedynkami
        df['volume_change'] = df['volume_change'].replace([np.inf, -np.inf], 0)
        df['volume_to_ma1440'] = df['volume_to_ma1440'].replace([np.inf, -np.inf], 1)
        df['volume_to_ma43200'] = df['volume_to_ma43200'].replace([np.inf, -np.inf], 1)
        
        # Fallback na zero/jeden, jeÅ›li pierwszy wiersz nadal jest NaN
        df.loc[:, 'volume_change'] = df['volume_change'].fillna(0)
        df.loc[:, 'volume_to_ma1440'] = df['volume_to_ma1440'].fillna(1.0)
        df.loc[:, 'volume_to_ma43200'] = df['volume_to_ma43200'].fillna(1.0)
        
        # UsuÅ„ pomocnicze kolumny MA (nie sÄ… potrzebne w finalnych danych)
        df.drop(['ma_close_1440', 'ma_close_43200', 'ma_volume_1440', 'ma_volume_43200'], 
                axis=1, inplace=True)
        
        self.logger.debug("Volume features obliczone")
        
        return df

class FeatureQualityValidator:
    """Klasa do walidacji jakoÅ›ci wygenerowanych features"""
    
    def __init__(self):
        self.logger = setup_logging(f"{__name__}.FeatureQualityValidator")
    
    def validate_features_quality(self, df: pd.DataFrame, pair_name: str = "") -> Dict[str, Any]:
        """
        ALGORYTM WALIDACJI JAKOÅšCI FEATURES
        
        Args:
            df: DataFrame z obliczonymi features
            pair_name: Nazwa pary (do logowania)
            
        Returns:
            Dict: Raport anomalii w features
        """
        self.logger.debug(f"Waliduje jakoÅ›Ä‡ features dla {pair_name}")
        
        anomalies_report = {
            "total_anomalies": 0,
            "nan_values": {},
            "inf_values": {},
            "extreme_values": {},
            "warnings": []
        }
        
        # SPRAWDÅ¹ WARTOÅšCI NaN/Inf
        self._check_nan_inf_values(df, anomalies_report)
        
        # WYKRYJ EKSTREMALNE WARTOÅšCI
        self._detect_extreme_values(df, anomalies_report)
        
        # WYGENERUJ KOMUNIKATY OSTRZEGAWCZE
        self._generate_warning_messages(anomalies_report, pair_name)
        
        return anomalies_report
    
    def _check_nan_inf_values(self, df: pd.DataFrame, report: Dict[str, Any]) -> None:
        """Sprawdza wartoÅ›ci NaN/Inf w kaÅ¼dej kolumnie features"""
        
        feature_columns = ['high_change', 'low_change', 'close_change', 'volume_change',
                          'price_to_ma1440', 'price_to_ma43200', 'volume_to_ma1440', 'volume_to_ma43200']
        
        for col in feature_columns:
            if col in df.columns:
                # Policz wartoÅ›ci NaN
                nan_count = df[col].isna().sum()
                if nan_count > 0:
                    report["nan_values"][col] = nan_count
                    report["total_anomalies"] += nan_count
                    self.logger.warning(f"Feature validation: {nan_count} wartoÅ›ci NaN w {col}")
                
                # Policz wartoÅ›ci Inf/-Inf
                inf_count = np.isinf(df[col]).sum()
                if inf_count > 0:
                    report["inf_values"][col] = inf_count
                    report["total_anomalies"] += inf_count
                    self.logger.warning(f"Feature validation: {inf_count} wartoÅ›ci Inf w {col}")
    
    def _detect_extreme_values(self, df: pd.DataFrame, report: Dict[str, Any]) -> None:
        """Wykrywa ekstremalne wartoÅ›ci w features"""
        
        # ZMIANY PROCENTOWE (high_change, low_change, close_change)
        change_columns = ['high_change', 'low_change', 'close_change']
        for col in change_columns:
            if col in df.columns:
                extreme_changes = (df[col].abs() > config.MAX_CHANGE_THRESHOLD)
                if extreme_changes.any():
                    extreme_count = extreme_changes.sum()
                    report["extreme_values"][f"{col}_extreme"] = extreme_count
                    report["total_anomalies"] += extreme_count
                    self.logger.warning(
                        f"Feature validation: {extreme_count} ekstremalnych zmian w {col} "
                        f"(>{config.MAX_CHANGE_THRESHOLD}%)"
                    )
        
        # STOSUNKI DO MA (price_to_ma1440, price_to_ma43200)
        ma_ratio_columns = ['price_to_ma1440', 'price_to_ma43200']
        for col in ma_ratio_columns:
            if col in df.columns:
                # SprawdÅº czy stosunek <= 0
                zero_or_negative = (df[col] <= 0)
                if zero_or_negative.any():
                    negative_count = zero_or_negative.sum()
                    report["extreme_values"][f"{col}_negative"] = negative_count
                    report["total_anomalies"] += negative_count
                    self.logger.warning(f"Feature validation: {negative_count} wartoÅ›ci <= 0 w {col}")
                
                # SprawdÅº czy stosunek > MAX_MA_RATIO (300% od MA)
                extreme_ratios = (df[col] > config.MAX_MA_RATIO)
                if extreme_ratios.any():
                    extreme_count = extreme_ratios.sum()
                    report["extreme_values"][f"{col}_extreme"] = extreme_count
                    report["total_anomalies"] += extreme_count
                    self.logger.warning(
                        f"Feature validation: {extreme_count} ekstremalnych stosunkÃ³w w {col} "
                        f"(>{config.MAX_MA_RATIO})"
                    )
        
        # VOLUME FEATURES
        # volume_change
        if 'volume_change' in df.columns:
            extreme_volume_changes = (df['volume_change'].abs() > config.MAX_VOLUME_CHANGE)
            if extreme_volume_changes.any():
                extreme_count = extreme_volume_changes.sum()
                report["extreme_values"]["volume_change_extreme"] = extreme_count
                report["total_anomalies"] += extreme_count
                self.logger.warning(
                    f"Feature validation: {extreme_count} ekstremalnych zmian volume "
                    f"(>{config.MAX_VOLUME_CHANGE}%)"
                )
        
        # volume_to_ma ratio
        volume_ratio_columns = ['volume_to_ma1440', 'volume_to_ma43200']
        for col in volume_ratio_columns:
            if col in df.columns:
                zero_or_negative = (df[col] <= 0)
                if zero_or_negative.any():
                    negative_count = zero_or_negative.sum()
                    report["extreme_values"][f"{col}_negative"] = negative_count
                    report["total_anomalies"] += negative_count
                    self.logger.warning(f"Feature validation: {negative_count} wartoÅ›ci <= 0 w {col}")
    
    def _generate_warning_messages(self, report: Dict[str, Any], pair_name: str) -> None:
        """Generuje komunikaty ostrzegawcze"""
        
        if report["total_anomalies"] > 0:
            warning_msg = f"Feature validation: {report['total_anomalies']} anomalii wykrytych w {pair_name}"
            report["warnings"].append(warning_msg)
            self.logger.warning(warning_msg)
            
            # SzczegÃ³Å‚owe komunikaty
            if report["nan_values"]:
                for col, count in report["nan_values"].items():
                    msg = f"NaN values: {count} w {col}"
                    report["warnings"].append(msg)
            
            if report["inf_values"]:
                for col, count in report["inf_values"].items():
                    msg = f"Inf values: {count} w {col}"
                    report["warnings"].append(msg)
            
            if report["extreme_values"]:
                for anomaly_type, count in report["extreme_values"].items():
                    msg = f"Extreme values: {count} przypadkÃ³w {anomaly_type}"
                    report["warnings"].append(msg)
        else:
            self.logger.info(f"Feature validation: Brak anomalii w {pair_name}")
            report["warnings"].append(f"Brak anomalii w features dla {pair_name}") 

class FeatureDistributionAnalyzer:
    """Klasa do analizy rozkÅ‚adu wartoÅ›ci features"""
    
    def __init__(self):
        self.logger = setup_logging(f"{__name__}.FeatureDistributionAnalyzer")
    
    def analyze_feature_distributions(self, df: pd.DataFrame, pair_name: str = "") -> Dict[str, Any]:
        """
        Analizuje rozkÅ‚ad wartoÅ›ci dla wszystkich features
        
        Args:
            df: DataFrame z obliczonymi features
            pair_name: Nazwa pary (do logowania)
            
        Returns:
            Dict: SzczegÃ³Å‚owy raport rozkÅ‚adu wartoÅ›ci
        """
        self.logger.info(f"Rozpoczynam analizÄ™ rozkÅ‚adu wartoÅ›ci features dla {pair_name}")
        
        distribution_report = {
            "pair": pair_name,
            "total_rows": len(df),
            "features_analyzed": [],
            "distributions": {}
        }
        
        if len(df) == 0:
            self.logger.warning("Brak danych do analizy rozkÅ‚adu")
            return distribution_report
        
        # Lista wszystkich features do analizy
        feature_columns = [
            'high_change', 'low_change', 'close_change', 'volume_change',
            'price_to_ma1440', 'price_to_ma43200', 
            'volume_to_ma1440', 'volume_to_ma43200'
        ]
        
        self.logger.info("=" * 80)
        self.logger.info(f"ğŸ“Š ANALIZA ROZKÅADU WARTOÅšCI FEATURES - {pair_name}")
        self.logger.info("=" * 80)
        
        for feature_name in feature_columns:
            if feature_name in df.columns:
                feature_distribution = self._analyze_single_feature_distribution(
                    df[feature_name], feature_name, len(df)
                )
                distribution_report["features_analyzed"].append(feature_name)
                distribution_report["distributions"][feature_name] = feature_distribution
                
                # Loguj szczegÃ³Å‚y dla tej feature
                self._log_feature_distribution(feature_distribution, feature_name)
        
        self.logger.info("=" * 80)
        self.logger.info(f"âœ… Analiza rozkÅ‚adu zakoÅ„czona: {len(distribution_report['features_analyzed'])} features przeanalizowanych")
        self.logger.info("=" * 80)
        
        return distribution_report
    
    def _analyze_single_feature_distribution(self, series: pd.Series, feature_name: str, 
                                           total_rows: int) -> Dict[str, Any]:
        """
        Analizuje rozkÅ‚ad wartoÅ›ci dla pojedynczej feature
        
        Args:
            series: Seria z wartoÅ›ciami feature
            feature_name: Nazwa feature
            total_rows: ÅÄ…czna liczba wierszy
            
        Returns:
            Dict: SzczegÃ³Å‚owy raport rozkÅ‚adu dla tej feature
        """
        # Podstawowe statystyki
        min_val = float(series.min())
        max_val = float(series.max())
        mean_val = float(series.mean())
        std_val = float(series.std())
        median_val = float(series.median())
        
        # Podziel zakres na 10 rÃ³wnych przedziaÅ‚Ã³w
        bins = np.linspace(min_val, max_val, 11)  # 11 punktÃ³w = 10 przedziaÅ‚Ã³w
        
        # Oblicz histogram
        counts, bin_edges = np.histogram(series, bins=bins)
        
        # Przygotuj szczegÃ³Å‚y przedziaÅ‚Ã³w
        bin_details = []
        for i in range(len(counts)):
            bin_start = float(bin_edges[i])
            bin_end = float(bin_edges[i + 1])
            count = int(counts[i])
            percentage = (count / total_rows) * 100 if total_rows > 0 else 0
            
            bin_details.append({
                "bin_number": i + 1,
                "range_start": bin_start,
                "range_end": bin_end,
                "count": count,
                "percentage": percentage
            })
        
        return {
            "feature_name": feature_name,
            "basic_stats": {
                "min": min_val,
                "max": max_val,
                "mean": mean_val,
                "std": std_val,
                "median": median_val,
                "range": max_val - min_val
            },
            "distribution_bins": bin_details,
            "total_values": total_rows
        }
    
    def _log_feature_distribution(self, distribution: Dict[str, Any], feature_name: str) -> None:
        """Loguje szczegÃ³Å‚y rozkÅ‚adu dla pojedynczej feature"""
        
        stats = distribution["basic_stats"]
        bins = distribution["distribution_bins"]
        
        self.logger.info(f"\nğŸ“ˆ ROZKÅAD WARTOÅšCI - {feature_name}:")
        self.logger.info(f"   Zakres: [{stats['min']:.3f}, {stats['max']:.3f}] (rozpiÄ™toÅ›Ä‡: {stats['range']:.3f})")
        self.logger.info(f"   Åšrednia: {stats['mean']:.3f}, Mediana: {stats['median']:.3f}, Odch.std: {stats['std']:.3f}")
        
        # Loguj przedziaÅ‚y z najwiÄ™kszÄ… liczbÄ… wartoÅ›ci
        sorted_bins = sorted(bins, key=lambda x: x['count'], reverse=True)
        
        self.logger.info(f"   ğŸ“Š RozkÅ‚ad w 10 przedziaÅ‚ach:")
        for bin_info in bins:
            bin_num = bin_info['bin_number']
            start = bin_info['range_start']
            end = bin_info['range_end']
            count = bin_info['count']
            pct = bin_info['percentage']
            
            # Wizualizacja sÅ‚upka
            bar_length = int(pct / 2)  # Maksymalnie 50 znakÃ³w dla 100%
            bar = "â–ˆ" * bar_length
            
            self.logger.info(f"      PrzedziaÅ‚ {bin_num:2d}: [{start:8.3f}, {end:8.3f}] â†’ {count:8,} wartoÅ›ci ({pct:5.1f}%) {bar}")
        
        # PokaÅ¼ top 3 przedziaÅ‚y
        self.logger.info(f"   ğŸ† Top 3 przedziaÅ‚y:")
        for i, bin_info in enumerate(sorted_bins[:3]):
            self.logger.info(f"      {i+1}. PrzedziaÅ‚ {bin_info['bin_number']}: {bin_info['count']:,} wartoÅ›ci ({bin_info['percentage']:.1f}%)") 