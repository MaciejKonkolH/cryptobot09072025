"""
Data Interpolator - Algorytm interpolacji zepsutych danych
Eliminuje wartoÅ›ci 0, inf, NaN ktÃ³re powodujÄ… bÅ‚Ä™dy treningowe
Bazuje na: memory-bank/Algorytmy/Algorytm_uzupelniania_danaych_historycznych.md
"""
import logging
import pandas as pd
import numpy as np
import random
import time
from typing import Dict, Any, List, Tuple, Optional

# ObsÅ‚uga importÃ³w
try:
    from . import config
    from .utils import setup_logging
except ImportError:
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    import config
    from utils import setup_logging


class DataInterpolator:
    """Algorytm interpolacji zepsutych danych"""
    
    def __init__(self):
        self.logger = setup_logging(f"{__name__}.DataInterpolator")
        self.noise_pct = getattr(config, 'NOISE_PERCENTAGE', 2.0)
        self.max_iterations = getattr(config, 'MAX_INTERPOLATION_ITERATIONS', 3)
        self.min_valid_volume = getattr(config, 'MIN_VALID_VOLUME', 0.0001)
        
        self.logger.info("DataInterpolator initialized")
        
    def interpolate_corrupted_data(self, df: pd.DataFrame, pair_name: str = "") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """GÅÃ“WNA METODA - Interpolacja zepsutych danych"""
        start_time = time.time()  # START TIMER
        timeout = getattr(config, 'INTERPOLATION_MAX_PROCESSING_TIME', 300)  # 5 minut default
        
        self.logger.info(f"ðŸ”§ Rozpoczynam interpolacjÄ™ dla {pair_name} ({len(df):,} Å›wiec)")
        
        # Przygotuj raport
        report = {
            "pair": pair_name,
            "input_rows": len(df),
            "corrupted_candles_detected": 0,
            "total_interpolated": 0,
            "iterations_performed": 0,
            "success": False,
            "warnings": []
        }
        
        # SprawdÅº czy dataset nie jest za duÅ¼y
        corrupted_percentage_limit = getattr(config, 'INTERPOLATION_MAX_CORRUPTED_PERCENTAGE', 50)
        
        # Kopia DataFrame do modyfikacji
        df_fixed = df.copy()
        
        # Iteracyjna naprawa (maksimum 3 iteracje)
        for iteration in range(1, self.max_iterations + 1):
            iteration_start = time.time()
            self.logger.info(f"ðŸ”„ Iteracja {iteration}/{self.max_iterations}")
            
            # SprawdÅº timeout
            elapsed = time.time() - start_time
            if elapsed > timeout:
                warning_msg = f"â° Timeout ({timeout}s) - przerywam interpolacjÄ™"
                self.logger.warning(warning_msg)
                report["warnings"].append(warning_msg)
                break
            
            # IDENTYFIKUJ zepsute Å›wiece
            self.logger.info(f"ðŸ” Skanowanie Å›wiec - iteracja {iteration}")
            corrupted_indices = self._identify_corrupted_candles(df_fixed)
            
            if not corrupted_indices:
                self.logger.info(f"âœ… Brak zepsutych Å›wiec w iteracji {iteration}")
                break
                
            # SprawdÅº czy nie za duÅ¼o zepsutych danych
            corrupted_percentage = (len(corrupted_indices) / len(df_fixed)) * 100
            if corrupted_percentage > corrupted_percentage_limit:
                warning_msg = f"âš ï¸ Zbyt duÅ¼o zepsutych danych: {corrupted_percentage:.1f}% > {corrupted_percentage_limit}%"
                self.logger.warning(warning_msg)
                report["warnings"].append(warning_msg)
                break
                
            self.logger.info(f"ðŸš¨ Iteracja {iteration}: Znaleziono {len(corrupted_indices)} zepsutych Å›wiec ({corrupted_percentage:.1f}%)")
            
            if iteration == 1:
                report["corrupted_candles_detected"] = len(corrupted_indices)
            
            # GRUPUJ w bloki ciÄ…gÅ‚e
            corrupted_blocks = self._group_corrupted_into_blocks(corrupted_indices)
            self.logger.info(f"ðŸ“¦ Pogrupowano w {len(corrupted_blocks)} blokÃ³w")
            
            # NAPRAW kaÅ¼dy blok
            fixes_in_iteration = 0
            for block_idx, block in enumerate(corrupted_blocks):
                if block_idx % 100 == 0 and block_idx > 0:
                    self.logger.info(f"ðŸ”§ Naprawiam blok {block_idx}/{len(corrupted_blocks)}")
                
                fixed_count = self._fix_corrupted_block(df_fixed, block)
                fixes_in_iteration += fixed_count
            
            report["total_interpolated"] += fixes_in_iteration
            report["iterations_performed"] = iteration
            
            iteration_time = time.time() - iteration_start
            self.logger.info(f"âœ… Iteracja {iteration}: Naprawiono {fixes_in_iteration} Å›wiec w {iteration_time:.2f}s")
        
        # Finalne sprawdzenie - TYLKO jeÅ›li wykonano wszystkie iteracje
        if report["iterations_performed"] >= self.max_iterations:
            final_corrupted = self._identify_corrupted_candles(df_fixed)
            if final_corrupted:
                warning_msg = f"âš ï¸ Po {self.max_iterations} iteracjach nadal {len(final_corrupted)} zepsutych Å›wiec"
                self.logger.warning(warning_msg)
                report["warnings"].append(warning_msg)
            else:
                self.logger.info(f"âœ… Interpolacja zakoÅ„czona pomyÅ›lnie")
                report["success"] = True
        else:
            # Iteracje zakoÅ„czone wczeÅ›niej z powodu braku problemÃ³w
            self.logger.info(f"âœ… Interpolacja zakoÅ„czona pomyÅ›lnie - brak problemÃ³w po {report['iterations_performed']} iteracjach")
            report["success"] = True
        
        self.logger.info(f"ðŸ“Š {pair_name}: {report['total_interpolated']} Å›wiec interpolowanych w {report['iterations_performed']} iteracjach")
        
        # WALIDACJA KOÅƒCOWA (NOWE)
        validation_report = self._validate_interpolation_success(df_fixed, pair_name)
        report["final_validation"] = validation_report
        
        if not validation_report["success"]:
            # JeÅ›li nadal sÄ… problemy, oznacz jako partial success
            report["success"] = False
            report["warnings"].append("Interpolacja nie usunÄ™Å‚a wszystkich problemÃ³w!")
        
        end_time = time.time()
        processing_time = end_time - start_time
        report["processing_time_seconds"] = processing_time
        
        # Log performance
        if processing_time > 10.0:  # Warning jeÅ›li > 10 sekund
            self.logger.warning(f"â±ï¸ Interpolacja {pair_name}: {processing_time:.2f}s (SLOW!)")
        else:
            self.logger.info(f"â±ï¸ Interpolacja {pair_name}: {processing_time:.2f}s")
        
        # Throughput
        rows_per_second = len(df) / processing_time if processing_time > 0 else 0
        self.logger.info(f"ðŸ“ˆ Throughput: {rows_per_second:.0f} Å›wiec/sekunda")
        
        return df_fixed, report
    
    def interpolate_specific_indices(self, df: pd.DataFrame, indices_to_fix: List[int], reason: str = "External request") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        Interpoluje Å›wiece na podstawie jawnie podanej listy indeksÃ³w.
        UÅ¼ywane do naprawy anomalii wykrytych przez zewnÄ™trzne moduÅ‚y (np. DataValidator).
        """
        start_time = time.time()
        self.logger.info(f"ðŸ”§ Rozpoczynam interpolacjÄ™ {len(indices_to_fix)} Å›wiec na Å¼Ä…danie (powÃ³d: {reason})")
        
        df_fixed = df.copy()
        report = {
            "reason": reason,
            "indices_provided": len(indices_to_fix),
            "total_interpolated": 0,
            "success": False
        }

        if not indices_to_fix:
            self.logger.info("Brak indeksÃ³w do interpolacji. Zwracam oryginalne dane.")
            report["success"] = True
            return df_fixed, report

        # GRUPUJ w bloki ciÄ…gÅ‚e
        corrupted_blocks = self._group_corrupted_into_blocks(indices_to_fix)
        self.logger.info(f"ðŸ“¦ Pogrupowano w {len(corrupted_blocks)} blokÃ³w do interpolacji.")

        # NAPRAW kaÅ¼dy blok
        fixes_in_run = 0
        for block_idx, block in enumerate(corrupted_blocks):
            if block_idx % 100 == 0 and block_idx > 0:
                self.logger.info(f"ðŸ”§ InterpolujÄ™ blok {block_idx}/{len(corrupted_blocks)}")
            
            fixed_count = self._fix_corrupted_block(df_fixed, block)
            fixes_in_run += fixed_count
        
        report["total_interpolated"] = fixes_in_run
        report["success"] = True  # ZakÅ‚adamy sukces, jeÅ›li proces przeszedÅ‚
        
        end_time = time.time()
        processing_time = end_time - start_time
        report["processing_time_seconds"] = processing_time

        self.logger.info(f"âœ… Interpolacja na Å¼Ä…danie zakoÅ„czona w {processing_time:.2f}s. Zmieniono {fixes_in_run} Å›wiec.")

        return df_fixed, report

    def _is_ohlc_valid(self, candle: pd.Series) -> bool:
        """Sprawdza, czy ceny OHLC w Å›wiecy sÄ… poprawne i logiczne."""
        try:
            # SprawdÅº, czy ceny sÄ… dodatnie i skoÅ„czone
            for col in ['open', 'high', 'low', 'close']:
                price = candle[col]
                if price <= 0 or np.isinf(price) or np.isnan(price):
                    return False
            
            # SprawdÅº logikÄ™ OHLC
            if candle['high'] < max(candle['open'], candle['close']):
                return False
            if candle['low'] > min(candle['open'], candle['close']):
                return False
                
            return True
        except (KeyError, ValueError, TypeError):
            return False

    def _identify_corrupted_candles(self, df: pd.DataFrame) -> List[int]:
        """IDENTYFIKACJA ZEPSUTYCH ÅšWIEC - OPTIMIZED VERSION"""
        total_rows = len(df)
        self.logger.info(f"Skanowanie {total_rows:,} Å›wiec w poszukiwaniu problemÃ³w...")
        
        # --- Diagnoza wektorowa ---
        volume_invalid = (df['volume'] <= self.min_valid_volume) | np.isinf(df['volume']) | np.isnan(df['volume'])
        
        price_invalid_flags = pd.DataFrame(index=df.index)
        for col in ['open', 'high', 'low', 'close']:
            price_invalid_flags[col] = (df[col] <= 0) | np.isinf(df[col]) | np.isnan(df[col])
        any_price_invalid = price_invalid_flags.any(axis=1)

        ohlc_logic_invalid = (df['high'] < np.maximum(df['open'], df['close'])) | \
                             (df['low'] > np.minimum(df['open'], df['close']))
        
        # PoÅ‚Ä…cz wszystkie warunki
        all_invalid = volume_invalid | any_price_invalid | ohlc_logic_invalid
        
        corrupted_indices = df.index[all_invalid].tolist()
        
        # --- Logowanie i raportowanie postÄ™pu ---
        if total_rows > 100000:
            progress_step = max(1, total_rows // 20)  # Raportuj co 5%
            for i in range(0, total_rows, progress_step):
                if i > 0:
                    progress_pct = (i / total_rows) * 100
                    self.logger.info(f"ðŸ“Š PostÄ™p skanowania: {progress_pct:.1f}% ({i:,}/{total_rows:,} Å›wiec)")
        
        if corrupted_indices:
            self.logger.info(f"ðŸš¨ Znaleziono {len(corrupted_indices)} zepsutych Å›wiec z {total_rows:,} total ({len(corrupted_indices)/total_rows*100:.2f}%)")
        else:
            self.logger.info("âœ… Wszystkie Å›wiece sÄ… prawidÅ‚owe")
            
        return corrupted_indices

    def _group_corrupted_into_blocks(self, corrupted_indices: List[int]) -> List[List[int]]:
        """Grupuje ciÄ…gÅ‚e indeksy zepsutych Å›wiec w bloki"""
        if not corrupted_indices:
            return []
        
        blocks = []
        current_block = [corrupted_indices[0]]
        
        for i in range(1, len(corrupted_indices)):
            if corrupted_indices[i] == corrupted_indices[i-1] + 1:
                current_block.append(corrupted_indices[i])
            else:
                blocks.append(current_block)
                current_block = [corrupted_indices[i]]
        
        blocks.append(current_block)
        return blocks

    def _fix_corrupted_block(self, df: pd.DataFrame, block: List[int]) -> int:
        """
        "CHIRURGICZNA" NAPRAWA BLOKU: Iteruje przez kaÅ¼dÄ… Å›wiecÄ™ w bloku
        i naprawia tylko te wartoÅ›ci, ktÃ³re sÄ… uszkodzone.
        """
        left_index, right_index = self._find_nearest_valid_candles(df, block)
        fixed_count = 0

        for candle_index in block:
            candle = df.iloc[candle_index]
            
            volume_is_invalid = candle['volume'] <= self.min_valid_volume
            ohlc_is_valid = self._is_ohlc_valid(candle)

            if not ohlc_is_valid:
                # Scenariusz A: OHLC jest zepsute. Napraw caÅ‚Ä… Å›wiecÄ™.
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    self._interpolate_value(df, candle_index, col, left_index, right_index)
                fixed_count += 1
                
            elif volume_is_invalid:
                # Scenariusz B: OHLC jest OK, ale wolumen jest zÅ‚y. Napraw tylko wolumen.
                self._interpolate_value(df, candle_index, 'volume', left_index, right_index)
                fixed_count += 1
        
        # Po naprawie wartoÅ›ci, upewnij siÄ™, Å¼e logika OHLC jest spÃ³jna
        for candle_index in block:
            self._fix_ohlc_logic(df, candle_index)
            
        return fixed_count

    def _find_nearest_valid_candles(self, df: pd.DataFrame, block: List[int]) -> Tuple[Optional[int], Optional[int]]:
        """Znajduje indeksy najbliÅ¼szych prawidÅ‚owych Å›wiec otaczajÄ…cych blok"""
        start_block_index = block[0]
        end_block_index = block[-1]
        
        # Szukaj na lewo
        left_index = None
        for i in range(start_block_index - 1, -1, -1):
            if i not in block and self._is_ohlc_valid(df.iloc[i]) and df.iloc[i]['volume'] > self.min_valid_volume:
                left_index = i
                break
        
        # Szukaj na prawo
        right_index = None
        for i in range(end_block_index + 1, len(df)):
             if i not in block and self._is_ohlc_valid(df.iloc[i]) and df.iloc[i]['volume'] > self.min_valid_volume:
                right_index = i
                break
                
        return left_index, right_index

    def _interpolate_value(self, df: pd.DataFrame, idx: int, col: str, left_idx: Optional[int], right_idx: Optional[int]):
        """
        Interpoluje, forward-filluje lub backward-filluje pojedynczÄ… wartoÅ›Ä‡
        w danej kolumnie i indeksie.
        """
        # Scenariusz 1: PeÅ‚na interpolacja liniowa
        if left_idx is not None and right_idx is not None:
            left_val = df.at[df.index[left_idx], col]
            right_val = df.at[df.index[right_idx], col]
            
            total_distance = right_idx - left_idx
            current_distance = idx - left_idx
            
            if total_distance > 0:
                step = (right_val - left_val) / total_distance
                interpolated_val = left_val + (step * current_distance)
                
                if col != 'volume':
                    interpolated_val = self._add_realistic_noise(interpolated_val)
                df.at[df.index[idx], col] = interpolated_val
            else:
                 df.at[df.index[idx], col] = left_val

        # Scenariusz 2: Backward fill (tylko prawa granica)
        elif right_idx is not None:
            val = df.at[df.index[right_idx], col]
            df.at[df.index[idx], col] = val

        # Scenariusz 3: Forward fill (tylko lewa granica)
        elif left_idx is not None:
            val = df.at[df.index[left_idx], col]
            df.at[df.index[idx], col] = val
        
        else:
            self.logger.warning(f"Brak granic do interpolacji wartoÅ›ci dla {col} w indeksie {idx}. WartoÅ›Ä‡ pozostaje bez zmian.")

    def _add_realistic_noise(self, value: float) -> float:
        """Dodaje niewielki, realistyczny szum do interpolowanych cen"""
        if value > 0:
            noise = value * (self.noise_pct / 100) * (random.uniform(-0.5, 0.5))
            return max(0, value + noise)
        return value

    def _fix_ohlc_logic(self, df: pd.DataFrame, candle_index: int) -> None:
        """
        Naprawia logikÄ™ OHLC dla pojedynczej Å›wiecy po interpolacji,
        upewniajÄ…c siÄ™, Å¼e high jest max, a low jest min.
        """
        candle = df.iloc[candle_index]
        open_val, high_val, low_val, close_val = candle['open'], candle['high'], candle['low'], candle['close']
        
        # Upewnij siÄ™, Å¼e high jest najwyÅ¼szÄ…, a low najniÅ¼szÄ… wartoÅ›ciÄ…
        correct_high = max(open_val, high_val, low_val, close_val)
        correct_low = min(open_val, high_val, low_val, close_val)
        
        df.at[df.index[candle_index], 'high'] = correct_high
        df.at[df.index[candle_index], 'low'] = correct_low
        
        # Upewnij siÄ™, Å¼e wolumen nie jest ujemny
        if df.at[df.index[candle_index], 'volume'] < 0:
            df.at[df.index[candle_index], 'volume'] = 0
            
    def _validate_interpolation_success(self, df: pd.DataFrame, pair_name: str = "") -> Dict[str, Any]:
        """FINALNA WALIDACJA - sprawdza, czy po wszystkich operacjach nie ma juÅ¼ zepsutych Å›wiec"""
        self.logger.info(f"âœ… Walidacja {pair_name}: Sprawdzam ostateczny wynik interpolacji...")
        
        remaining_corrupted = self._identify_corrupted_candles(df)
        
        report = {"success": not remaining_corrupted, "remaining_corrupted": len(remaining_corrupted)}
        
        if not report["success"]:
            self.logger.warning(f"ðŸš¨ Walidacja {pair_name}: Nadal istnieje {len(remaining_corrupted)} zepsutych Å›wiec!")
        else:
            self.logger.info(f"âœ… Walidacja {pair_name}: Wszystkie problemy usuniÄ™te!")
            
        return report 