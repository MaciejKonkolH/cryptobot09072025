import os
import requests
import zipfile
import pandas as pd
import json
from datetime import datetime, timedelta
import sys
from pathlib import Path
import io
import argparse
import logging

# Konfiguracja katalogÃ³w
ORDERBOOK_DIR = "orderbook_raw"
OHLC_DIR = "ohlc_raw"
METADATA_FILE = "download_metadata.json"

def daterange(start_date, end_date):
    """Generator dat od start_date do end_date (wÅ‚Ä…cznie)"""
    for n in range(int((end_date - start_date).days) + 1):
        yield start_date + timedelta(n)

def check_file_exists_on_server(url):
    """Sprawdza czy plik istnieje na serwerze"""
    try:
        response = requests.head(url, timeout=10)
        return response.status_code == 200
    except:
        return False

def download_and_extract_file(url, local_zip_path, local_csv_path):
    """Pobiera plik ZIP i rozpakowuje go do CSV"""
    try:
        # Pobierz ZIP
        resp = requests.get(url, stream=True, timeout=30)
        if resp.status_code == 200:
            # Zapisz ZIP
            with open(local_zip_path, "wb") as f:
                for chunk in resp.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # Rozpakuj ZIP
            with zipfile.ZipFile(local_zip_path) as zip_file:
                csv_filename = zip_file.namelist()[0]
                zip_file.extract(csv_filename, os.path.dirname(local_csv_path))
                # ZmieÅ„ nazwÄ™ na standardowÄ…
                old_path = os.path.join(os.path.dirname(local_csv_path), csv_filename)
                os.rename(old_path, local_csv_path)
            
            # UsuÅ„ ZIP
            os.remove(local_zip_path)
            
            file_size = os.path.getsize(local_csv_path)
            print(f"âœ… Pobrano i rozpakowano -> {local_csv_path} ({file_size:,} bajtÃ³w)")
            return True
        else:
            print(f"âŒ BÅ‚Ä…d pobierania ({resp.status_code})")
            return False
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d pobierania: {e}")
        return False

def download_orderbook_data(symbol, date_str, market="futures"):
    """Pobiera dane order book dla podanej daty"""
    url = f"https://data.binance.vision/data/{market}/um/daily/bookDepth/{symbol}/{symbol}-bookDepth-{date_str}.zip"
    zip_path = os.path.join(ORDERBOOK_DIR, f"{symbol}-bookDepth-{date_str}.zip")
    csv_path = os.path.join(ORDERBOOK_DIR, f"{symbol}-bookDepth-{date_str}.csv")
    
    # SprawdÅº czy CSV juÅ¼ istnieje i jest kompletny
    if os.path.exists(csv_path):
        file_size = os.path.getsize(csv_path)
        if file_size > 1000:  # SprawdÅº czy plik ma sensowny rozmiar
            print(f"âœ… {date_str}: Order book CSV juÅ¼ istnieje ({file_size:,} bajtÃ³w)")
            return True
        else:
            print(f"âš ï¸ {date_str}: Order book CSV istnieje ale jest za maÅ‚y ({file_size} bajtÃ³w) - usuwam")
            os.remove(csv_path)
    
    # SprawdÅº czy plik istnieje na serwerze
    print(f"ğŸ” {date_str}: Sprawdzam order book na serwerze...")
    if not check_file_exists_on_server(url):
        print(f"âŒ {date_str}: Order book niedostÄ™pny na serwerze")
        return False
    
    # Pobierz plik
    return download_and_extract_file(url, zip_path, csv_path)

def download_ohlc_data(symbol, date_str, interval="1m", market="futures"):
    """Pobiera dane OHLC dla podanej daty"""
    url = f"https://data.binance.vision/data/{market}/um/daily/klines/{symbol}/{interval}/{symbol}-{interval}-{date_str}.zip"
    zip_path = os.path.join(OHLC_DIR, f"{symbol}-{interval}-{date_str}.zip")
    csv_path = os.path.join(OHLC_DIR, f"{symbol}-{interval}-{date_str}.csv")
    
    # SprawdÅº czy CSV juÅ¼ istnieje i jest kompletny
    if os.path.exists(csv_path):
        file_size = os.path.getsize(csv_path)
        if file_size > 1000:  # SprawdÅº czy plik ma sensowny rozmiar
            print(f"âœ… {date_str}: OHLC CSV juÅ¼ istnieje ({file_size:,} bajtÃ³w)")
            return True
        else:
            print(f"âš ï¸ {date_str}: OHLC CSV istnieje ale jest za maÅ‚y ({file_size} bajtÃ³w) - usuwam")
            os.remove(csv_path)
    
    # SprawdÅº czy plik istnieje na serwerze
    print(f"ğŸ” {date_str}: Sprawdzam OHLC na serwerze...")
    if not check_file_exists_on_server(url):
        print(f"âŒ {date_str}: OHLC niedostÄ™pny na serwerze")
        return False
    
    # Pobierz plik
    return download_and_extract_file(url, zip_path, csv_path)

def copy_neighboring_file(source_date, target_date, file_type, symbol, interval="1m"):
    """Kopiuje plik z sÄ…siedniego dnia i dostosowuje timestampy"""
    if file_type == "orderbook":
        source_file = os.path.join(ORDERBOOK_DIR, f"{symbol}-bookDepth-{source_date}.csv")
        target_file = os.path.join(ORDERBOOK_DIR, f"{symbol}-bookDepth-{target_date}.csv")
    else:  # ohlc
        source_file = os.path.join(OHLC_DIR, f"{symbol}-{interval}-{source_date}.csv")
        target_file = os.path.join(OHLC_DIR, f"{symbol}-{interval}-{target_date}.csv")
    
    if not os.path.exists(source_file):
        print(f"âŒ Plik ÅºrÃ³dÅ‚owy nie istnieje: {source_file}")
        return False
    
    try:
        # Wczytaj dane ÅºrÃ³dÅ‚owe
        df = pd.read_csv(source_file)
        print(f"ğŸ“Š Wczytano {len(df):,} wierszy z {source_date}")
        
        # Skopiuj dane
        new_df = df.copy()
        
        # Dostosuj timestampy
        source_start = pd.to_datetime(source_date)
        target_start = pd.to_datetime(target_date)
        time_shift = target_start - source_start
        
        # Dostosuj timestampy (rÃ³Å¼ne formaty dla OHLC i Orderbook)
        if file_type == "orderbook":
            new_df['timestamp'] = pd.to_datetime(new_df['timestamp']) + time_shift
            new_df['timestamp'] = new_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
        else:  # ohlc
            # OHLC ma timestamp w pierwszej kolumnie (open_time)
            new_df.iloc[:, 0] = pd.to_numeric(new_df.iloc[:, 0]) + int(time_shift.total_seconds() * 1000)
        
        # Zapisz nowy plik
        new_df.to_csv(target_file, index=False)
        
        file_size = os.path.getsize(target_file)
        print(f"âœ… Utworzono: {target_file} ({len(new_df):,} wierszy, {file_size:,} bajtÃ³w)")
        return True
        
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas kopiowania: {e}")
        return False

def find_neighboring_dates(missing_date, date_range):
    """Znajduje sÄ…siednie daty dla uzupeÅ‚nienia brakujÄ…cego dnia"""
    missing_dt = datetime.strptime(missing_date, '%Y-%m-%d')
    
    # SprawdÅº dzieÅ„ przed
    day_before = (missing_dt - timedelta(days=1)).strftime('%Y-%m-%d')
    day_before_exists = day_before in date_range
    
    # SprawdÅº dzieÅ„ po
    day_after = (missing_dt + timedelta(days=1)).strftime('%Y-%m-%d')
    day_after_exists = day_after in date_range
    
    if day_before_exists and day_after_exists:
        # Preferuj dzieÅ„ przed
        return day_before
    elif day_before_exists:
        return day_before
    elif day_after_exists:
        return day_after
    else:
        return None

def fill_missing_files(missing_dates, date_range, symbol, interval="1m"):
    """UzupeÅ‚nia brakujÄ…ce pliki przez kopiowanie sÄ…siednich dni"""
    print(f"\nğŸ”§ UzupeÅ‚niam {len(missing_dates)} brakujÄ…cych plikÃ³w...")
    
    filled_dates = []  # Lista dat ktÃ³re zostaÅ‚y uzupeÅ‚nione
    
    for missing_date in missing_dates:
        print(f"\nğŸ“… Przetwarzam: {missing_date}")
        
        # ZnajdÅº sÄ…siedni dzieÅ„
        neighbor_date = find_neighboring_dates(missing_date, date_range)
        
        if neighbor_date is None:
            print(f"âŒ Brak sÄ…siednich dni dla {missing_date}")
            continue
        
        print(f"ğŸ“‹ UÅ¼ywam danych z: {neighbor_date}")
        
        # UzupeÅ‚nij order book
        if not copy_neighboring_file(neighbor_date, missing_date, "orderbook", symbol):
            print(f"âŒ Nie udaÅ‚o siÄ™ uzupeÅ‚niÄ‡ order book dla {missing_date}")
            continue
        
        # UzupeÅ‚nij OHLC
        if not copy_neighboring_file(neighbor_date, missing_date, "ohlc", symbol, interval):
            print(f"âŒ Nie udaÅ‚o siÄ™ uzupeÅ‚niÄ‡ OHLC dla {missing_date}")
            continue
        
        print(f"âœ… UzupeÅ‚niono dane dla {missing_date}")
        filled_dates.append(missing_date)
    
    return filled_dates

def check_for_long_gaps(missing_dates):
    """Sprawdza czy sÄ… przerwy dÅ‚uÅ¼sze niÅ¼ 2 dni"""
    if not missing_dates:
        return False
    
    # Sortuj daty
    sorted_dates = sorted(missing_dates)
    
    # SprawdÅº przerwy miÄ™dzy kolejnymi brakujÄ…cymi datami
    for i in range(len(sorted_dates) - 1):
        date1 = datetime.strptime(sorted_dates[i], '%Y-%m-%d')
        date2 = datetime.strptime(sorted_dates[i + 1], '%Y-%m-%d')
        gap_days = (date2 - date1).days
        
        if gap_days > 2:
            print(f"âŒ Znaleziono przerwÄ™ dÅ‚uÅ¼szÄ… niÅ¼ 2 dni: {sorted_dates[i]} - {sorted_dates[i+1]} ({gap_days} dni)")
            return True
    
    return False

def main():
    """GÅ‚Ã³wna funkcja pobierania danych"""
    parser = argparse.ArgumentParser(description='Pobierz dane OHLC i Orderbook z Binance')
    parser.add_argument('symbol', help='Symbol kryptowaluty (np. BTCUSDT)')
    parser.add_argument('start_date', help='Data poczÄ…tkowa (YYYY-MM-DD)')
    parser.add_argument('end_date', help='Data koÅ„cowa (YYYY-MM-DD)')
    parser.add_argument('--interval', default='1m', help='InterwaÅ‚ OHLC (domyÅ›lnie: 1m)')
    parser.add_argument('--market', default='futures', help='Typ rynku (domyÅ›lnie: futures)')
    
    args = parser.parse_args()
    
    # Konwertuj stringi dat na datetime
    try:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
        end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
    except ValueError as e:
        print(f"âŒ BÅ‚Ä…d formatu daty: {e}")
        print("UÅ¼yj formatu: YYYY-MM-DD (np. 2023-01-01)")
        return
    
    symbol = args.symbol
    interval = args.interval
    market = args.market
    
    print(f"ğŸš€ Rozpoczynanie pobierania danych dla {symbol}")
    print(f"ğŸ“… Zakres: {start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}")
    print(f"ğŸ“Š InterwaÅ‚: {interval}")
    print(f"ğŸª Rynek: {market}")
    
    # UtwÃ³rz katalogi jeÅ›li nie istniejÄ…
    os.makedirs(ORDERBOOK_DIR, exist_ok=True)
    os.makedirs(OHLC_DIR, exist_ok=True)
    
    # KROK 1: Pobierz wszystkie daty z zakresu
    all_dates = [date.strftime('%Y-%m-%d') for date in daterange(start_date, end_date)]
    print(f"\nğŸ“‹ Zakres zawiera {len(all_dates)} dni")
    
    # KROK 2: Pobierz dane
    print(f"\nğŸ“¥ Pobieram dane...")
    successful_orderbook = []
    successful_ohlc = []
    missing_orderbook = []
    missing_ohlc = []
    
    for date_str in all_dates:
        print(f"\nğŸ“… Przetwarzam: {date_str}")
        
        # Pobierz order book
        if download_orderbook_data(symbol, date_str, market):
            successful_orderbook.append(date_str)
        else:
            missing_orderbook.append(date_str)
        
        # Pobierz OHLC
        if download_ohlc_data(symbol, date_str, interval, market):
            successful_ohlc.append(date_str)
        else:
            missing_ohlc.append(date_str)
    
    # KROK 3: SprawdÅº przerwy
    print(f"\nğŸ” Analiza brakujÄ…cych plikÃ³w:")
    print(f"   Order book: {len(successful_orderbook)} pobranych, {len(missing_orderbook)} brakujÄ…cych")
    print(f"   OHLC: {len(successful_ohlc)} pobranych, {len(missing_ohlc)} brakujÄ…cych")
    
    if missing_orderbook:
        print(f"   BrakujÄ…ce order book: {missing_orderbook}")
    if missing_ohlc:
        print(f"   BrakujÄ…ce OHLC: {missing_ohlc}")
    
    # KROK 4: SprawdÅº czy sÄ… przerwy dÅ‚uÅ¼sze niÅ¼ 2 dni
    if check_for_long_gaps(missing_orderbook) or check_for_long_gaps(missing_ohlc):
        print(f"\nâŒ Znaleziono przerwy dÅ‚uÅ¼sze niÅ¼ 2 dni. KoÅ„czÄ™ dziaÅ‚anie.")
        return
    
    # KROK 5: UzupeÅ‚nij brakujÄ…ce pliki
    filled_orderbook = fill_missing_files(missing_orderbook, all_dates, symbol, interval)
    filled_ohlc = fill_missing_files(missing_ohlc, all_dates, symbol, interval)
    
    # KROK 6: Podsumowanie
    print(f"\nğŸ‰ Proces zakoÅ„czony!")
    print(f"ğŸ“Š Pobrano order book: {len(successful_orderbook)}")
    print(f"ğŸ“Š Pobrano OHLC: {len(successful_ohlc)}")
    print(f"ğŸ”§ UzupeÅ‚niono order book: {len(filled_orderbook)}")
    print(f"ğŸ”§ UzupeÅ‚niono OHLC: {len(filled_ohlc)}")
    
    # WyÅ›wietl szczegÃ³Å‚owe informacje o uzupeÅ‚nionych datach
    if filled_orderbook:
        print(f"\nğŸ“‹ UzupeÅ‚nione daty order book: {', '.join(filled_orderbook)}")
    if filled_ohlc:
        print(f"ğŸ“‹ UzupeÅ‚nione daty OHLC: {', '.join(filled_ohlc)}")
    
    # SprawdÅº czy wszystkie daty zostaÅ‚y uzupeÅ‚nione
    if len(filled_orderbook) < len(missing_orderbook):
        print(f"âš ï¸ Nie udaÅ‚o siÄ™ uzupeÅ‚niÄ‡ wszystkich order book: {len(missing_orderbook) - len(filled_orderbook)} pozostaÅ‚o")
    if len(filled_ohlc) < len(missing_ohlc):
        print(f"âš ï¸ Nie udaÅ‚o siÄ™ uzupeÅ‚niÄ‡ wszystkich OHLC: {len(missing_ohlc) - len(filled_ohlc)} pozostaÅ‚o")
    
    if len(filled_orderbook) == len(missing_orderbook) and len(filled_ohlc) == len(missing_ohlc):
        print(f"âœ… Wszystkie brakujÄ…ce pliki zostaÅ‚y pomyÅ›lnie uzupeÅ‚nione!")
    
    # Zapisz metadata
    metadata = {
        'symbol': symbol,
        'start_date': start_date.isoformat(),
        'end_date': end_date.isoformat(),
        'interval': interval,
        'market': market,
        'created_at': datetime.now().isoformat(),
        'successful_orderbook': successful_orderbook,
        'successful_ohlc': successful_ohlc,
        'missing_orderbook': missing_orderbook,
        'missing_ohlc': missing_ohlc
    }
    
    with open(METADATA_FILE, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"ğŸ’¾ Metadata zapisana: {METADATA_FILE}")

if __name__ == "__main__":
    main() 