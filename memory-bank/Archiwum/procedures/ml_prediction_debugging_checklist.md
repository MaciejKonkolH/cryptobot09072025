# ğŸš¨ PLAN DEBUGOWANIA: Problem z predykcjami ML w strategii FreqTrade

## ğŸ“‹ **PROBLEM:**
Model ML osiÄ…ga 65% accuracy w walidacji i przewiduje 26,752 sygnaÅ‚Ã³w transakcyjnych na danych ze stycznia 2025, ale strategia FreqTrade na tych samych danych generuje 0 sygnaÅ‚Ã³w transakcyjnych. **To jest logiczna sprzecznoÅ›Ä‡!**

## ğŸ¯ **CHECKLIST DEBUGOWANIA:**

### **FAZA 1: WERYFIKACJA DANYCH** âœ…âŒ
- [ ] **1.1** PorÃ³wnaÄ‡ dane ÅºrÃ³dÅ‚owe (trening vs backtest)
  - [ ] SprawdziÄ‡ ÅºrÃ³dÅ‚o danych (Binance API vs pliki)
  - [ ] PorÃ³wnaÄ‡ timeframe (1m vs 1m)
  - [ ] PorÃ³wnaÄ‡ zakres dat (styczeÅ„ 2025)
  - [ ] PorÃ³wnaÄ‡ liczbÄ™ Å›wiec i timestamp
- [ ] **1.2** SprawdziÄ‡ preprocessing danych
  - [ ] PorÃ³wnaÄ‡ obliczanie OHLCV changes
  - [ ] PorÃ³wnaÄ‡ obliczanie MA1440 i MA43200
  - [ ] SprawdziÄ‡ buffer system (czy dziaÅ‚a poprawnie)
  - [ ] PorÃ³wnaÄ‡ kolejnoÅ›Ä‡ i nazwy kolumn

### **FAZA 2: WERYFIKACJA FEATURES** âœ…âŒ
- [x] **2.1** SprawdziÄ‡ obliczanie features
  - [x] PorÃ³wnaÄ‡ wzory features (trening vs strategia) âœ… NAPRAWIONE!
  - [x] SprawdziÄ‡ kolejnoÅ›Ä‡ features (juÅ¼ naprawione, ale zweryfikowaÄ‡) âœ…
  - [ ] PorÃ³wnaÄ‡ wartoÅ›ci features dla tych samych dat
  - [x] SprawdziÄ‡ czy brak NaN/inf w features âœ… NAPRAWIONE!
- [ ] **2.2** SprawdziÄ‡ features scaling
  - [ ] PorÃ³wnaÄ‡ parametry scalera (mean, scale, center)
  - [ ] SprawdziÄ‡ czy scaler jest poprawnie zaÅ‚adowany
  - [ ] PorÃ³wnaÄ‡ scaled features (trening vs strategia)
  - [ ] SprawdziÄ‡ czy scaler.transform() dziaÅ‚a poprawnie

### **FAZA 3: WERYFIKACJA MODELU** âœ…âŒ
- [ ] **3.1** SprawdziÄ‡ Å‚adowanie modelu
  - [ ] PorÃ³wnaÄ‡ Å›cieÅ¼ki do modelu
  - [ ] SprawdziÄ‡ czy model.h5 jest poprawnie zaÅ‚adowany
  - [ ] PorÃ³wnaÄ‡ architekturÄ™ modelu (warstwy, parametry)
  - [ ] SprawdziÄ‡ czy wagi modelu sÄ… identyczne
- [ ] **3.2** SprawdziÄ‡ predykcje modelu
  - [ ] PorÃ³wnaÄ‡ raw predictions (probabilities)
  - [ ] SprawdziÄ‡ ksztaÅ‚t predykcji (shape)
  - [ ] PorÃ³wnaÄ‡ confidence scores
  - [ ] SprawdziÄ‡ czy model.predict() dziaÅ‚a identycznie

### **FAZA 4: WERYFIKACJA PIPELINE** âœ…âŒ
- [ ] **4.1** SprawdziÄ‡ window_size i sequences
  - [ ] PorÃ³wnaÄ‡ window_size (120 vs 120)
  - [ ] SprawdziÄ‡ tworzenie sequences
  - [ ] PorÃ³wnaÄ‡ padding (pierwsze 120 wierszy)
  - [ ] SprawdziÄ‡ indeksowanie sequences
- [ ] **4.2** SprawdziÄ‡ konwersjÄ™ predykcji
  - [ ] PorÃ³wnaÄ‡ progi confidence (43% vs 42%)
  - [ ] SprawdziÄ‡ logikÄ™ konwersji probabilities â†’ signals
  - [ ] PorÃ³wnaÄ‡ klasyfikacjÄ™ (argmax)
  - [ ] SprawdziÄ‡ mapowanie klas (0=SHORT, 1=HOLD, 2=LONG)

### **FAZA 5: WERYFIKACJA KONFIGURACJI** âœ…âŒ
- [x] **5.1** SprawdziÄ‡ parametry treningu vs strategii
  - [x] PorÃ³wnaÄ‡ SEQUENCE_LENGTH (120 vs 120) âœ…
  - [x] PorÃ³wnaÄ‡ FUTURE_WINDOW (120 vs 120) âœ…
  - [x] PorÃ³wnaÄ‡ TP/SL parametry (1.0/0.5 vs 1.0/0.5) âœ…
  - [ ] PorÃ³wnaÄ‡ batch_size i inne parametry
- [ ] **5.2** SprawdziÄ‡ metadata modelu
  - [ ] PorÃ³wnaÄ‡ metadata.json
  - [ ] SprawdziÄ‡ kompatybilnoÅ›Ä‡ parametrÃ³w
  - [ ] PorÃ³wnaÄ‡ feature_columns
  - [ ] SprawdziÄ‡ confidence thresholds

### **FAZA 6: TESTY DIAGNOSTYCZNE** âœ…âŒ
- [ ] **6.1** Test na identycznych danych
  - [ ] WziÄ…Ä‡ dokÅ‚adnie te same dane (10 Å›wiec)
  - [ ] PrzepuÅ›ciÄ‡ przez trening pipeline
  - [ ] PrzepuÅ›ciÄ‡ przez strategiÄ™ pipeline
  - [ ] PorÃ³wnaÄ‡ wyniki krok po kroku
- [ ] **6.2** Test confidence scores
  - [ ] WylogowaÄ‡ wszystkie confidence scores
  - [ ] SprawdziÄ‡ rozkÅ‚ad confidence
  - [ ] PorÃ³wnaÄ‡ z progami (42% vs 43%)
  - [ ] SprawdziÄ‡ czy sÄ… sygnaÅ‚y powyÅ¼ej progu

### **FAZA 7: ROZWIÄ„ZANIE** âœ…âŒ
- [ ] **7.1** Identyfikacja root cause
  - [ ] OkreÅ›liÄ‡ dokÅ‚adnÄ… przyczynÄ™ problemu
  - [ ] UdokumentowaÄ‡ rÃ³Å¼nice
  - [ ] ZaplanowaÄ‡ naprawÄ™
- [ ] **7.2** Implementacja fix
  - [ ] NaprawiÄ‡ zidentyfikowany problem
  - [ ] PrzetestowaÄ‡ naprawÄ™
  - [ ] ZweryfikowaÄ‡ Å¼e sygnaÅ‚y sÄ… generowane

## ğŸš¨ **CZERWONE FLAGI DO SPRAWDZENIA:**

1. ~~**SEQUENCE_LENGTH: 300 (trening) vs 120 (strategia)**~~ âœ… ROZWIÄ„ZANE
2. **RÃ³Å¼ne ÅºrÃ³dÅ‚a danych** (Kaggle vs Binance API) âš ï¸
3. **Buffer system** - czy poprawnie Å‚aduje dane historyczne âš ï¸
4. **Scaler parameters** - czy identyczne miÄ™dzy treningiem a strategiÄ… âš ï¸
5. **Model architecture** - czy model zostaÅ‚ poprawnie zaÅ‚adowany âš ï¸

## ğŸ“Š **EXPECTED OUTCOME:**
Po przejÅ›ciu przez checklist powinniÅ›my znaleÅºÄ‡ przyczynÄ™ dlaczego:
- **Walidacja:** 26,752 sygnaÅ‚Ã³w na styczniu 2025
- **Backtest:** 0 sygnaÅ‚Ã³w na styczniu 2025

## ğŸ¯ **NOWY PRIORITET:**
1. **FAZA 2.2** - SprawdziÄ‡ scaler parameters (mean, scale, center)
2. **FAZA 3.2** - PorÃ³wnaÄ‡ raw predictions i confidence scores  
3. **FAZA 1.2** - SprawdziÄ‡ czy dane ÅºrÃ³dÅ‚owe sÄ… identyczne 

## âœ… POTWIERDZONY PROBLEM PRZESUNIÄ˜CIA (2024-12-20)

### ğŸš¨ DOWÃ“D PRZESUNIÄ˜CIA O 119 MINUT:
```
WALIDACJA:  2024-12-20 00:00:00 â†’ predykcja: 0.47290429,0.16065080,0.36644489
FREQTRADE:  2024-12-20 01:59:00 â†’ predykcja: 0.47291863,0.16063705,0.36644438
```

**WNIOSEK**: Identyczne modele, scalery i features, ale FreqTrade mapuje predykcje o 119 minut pÃ³Åºniej!

### ğŸ” POTWIERDZONE FAKTY:
- âœ… System bufora dostarcza peÅ‚ne 120x8 features dla kaÅ¼dej Å›wiecy
- âœ… Pierwsza Å›wieca NIE JEST problemem (buffer rozwiÄ…zuje to)
- âœ… startup_candle_count = 0 vs 120 nie ma wpÅ‚ywu na backtesting
- âœ… startup_candle_count to parametr tylko live tradingu
- âŒ Problem JEST w mapowaniu predykcji do timestampÃ³w

### ğŸ¯ LOKALIZACJA PROBLEMU:
Prawdopodobnie w `signal_generator.py` w funkcji `_add_predictions_to_dataframe()`:
```python
start_idx = window_size - 1  # = 119 - moÅ¼e to byÄ‡ przyczyna?
```

---

## General ML Debugging Checklist

### 1. Data Consistency
- [ ] Raw features identical between training and prediction
- [ ] Scaled features identical between training and prediction  
- [ ] Same scaler object used (check scaler parameters)
- [ ] Same model architecture and weights

### 2. Sequence Generation
- [ ] Window size matches training (120)
- [ ] Feature order matches training
- [ ] Sequence indexing correct ([t-120:t] not [t:t+120])
- [ ] No off-by-one errors in sequence creation

### 3. Timestamp Alignment
- [ ] **CRITICAL**: Check prediction timestamp mapping
- [ ] Verify first prediction timestamp matches validation
- [ ] Compare prediction outputs for same timestamp
- [ ] Check for timezone issues

### 4. Model Loading
- [ ] Model loads without errors
- [ ] Scaler loads without errors
- [ ] Model metadata matches training config
- [ ] Feature names and order preserved

### 5. Buffer System
- [ ] MA calculations identical to training
- [ ] Feature calculations match validation module
- [ ] No data leakage from future
- [ ] Proper handling of NaN/inf values

### 6. Signal Generation
- [ ] Threshold application correct
- [ ] Signal mapping (0=SHORT, 1=HOLD, 2=LONG) consistent
- [ ] Confidence calculation matches training
- [ ] CSV logging captures all predictions

### 7. Common Issues
- [ ] Off-by-one errors in indexing
- [ ] Timezone mismatches
- [ ] Different feature calculation methods
- [ ] Scaler state differences
- [ ] Model version mismatches
- [ ] **TIMESTAMP MAPPING ERRORS** âš ï¸

### 8. Debugging Tools
- [ ] Save debug features to compare with training
- [ ] Log prediction timestamps and values
- [ ] Compare raw vs scaled features
- [ ] Verify sequence shapes and contents
- [ ] Cross-reference with validation module outputs 