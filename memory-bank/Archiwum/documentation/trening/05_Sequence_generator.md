# üìñ SEQUENCE GENERATOR MODU≈ÅU TRENUJƒÑCEGO V3 (sequence_generator.py)

## üéØ PRZEGLƒÑD SEQUENCE GENERATOR

**sequence_generator.py** (570 linii) to rewolucyjny modu≈Ç memory-efficient data generation, kt√≥ry eliminuje **katastrofƒô pamiƒôciowƒÖ V2** (81GB+ ‚Üí 2-3GB) poprzez wykorzystanie numpy memory views i lazy loading. Najwiƒôksza innowacja to **eliminacja competitive labeling** - 95+ linii kodu zosta≈Ço zastƒÖpione prostym u≈ºyciem pre-computed labels.

### ‚ú® **Kluczowe Innowacje V3 Sequence Generator**
- ‚úÖ **Memory-Efficient Generators** - 95% redukcja u≈ºycia pamiƒôci
- ‚úÖ **Numpy Memory Views** - zero-copy data access
- ‚úÖ **Pre-Computed Labels Revolution** - eliminacja 95+ linii competitive labeling  
- ‚úÖ **Chronological Splitting** - proper time-aware train/validation split
- ‚úÖ **Batch Generation** - on-demand sequence loading
- ‚úÖ **Generator Validation** - built-in testing and debugging tools

## üß† **MEMORY CRISIS SOLUTION**

### **Problem V2: Memory Catastrophe**
```python
# V2 - KATASTROFA PAMIƒòCIOWA
def load_full_dataset_v2():
    # ≈Åadowanie PE≈ÅNEGO datasetu do pamiƒôci
    df = pd.read_feather("BTCUSDT_full.feather")        # 12M+ records
    
    # Generowanie wszystkich sekwencji w pamiƒôci
    sequences = []
    labels = []
    for i in range(len(df) - WINDOW_SIZE):
        # KOPIA danych dla ka≈ºdej sekwencji!
        sequence = df.iloc[i:i+WINDOW_SIZE].values.copy()  # 120 x 8 x 4 bytes = 3.8KB per sequence
        sequences.append(sequence)                         # x 12M sequences = 45GB!
        
        # COMPETITIVE LABELING - duplikacja pracy validation module
        long_profit, short_profit = calculate_profits(i)   # 95+ linii duplikacji!
        if long_profit > short_profit:
            labels.append(2)  # LONG
        # ... rest of labeling logic
    
    # RESULT: 81GB+ memory usage, 95+ lines of duplicated code
    return np.array(sequences), np.array(labels)
```

### **Solution V3: Memory-Efficient Generators**
```python
# V3 - MEMORY-EFFICIENT GENERATORS
class MemoryEfficientDataLoader:
    def generate_sequences_with_labels(self):
        """Zero-copy sequence generation with pre-computed labels"""
        for i in range(self.total_sequences):
            start_idx = self.indices[i]
            
            # NUMPY MEMORY VIEW - NO COPY!
            sequence = self.features[start_idx:start_idx + self.window_size]  # View only!
            
            # PRE-COMPUTED LABELS - ZERO DUPLICATION!
            label = self.labels[start_idx + self.window_size - 1]  # Already computed!
            
            yield sequence, label
    
    # RESULT: 2-3GB memory usage, 0 lines of duplicated labeling code
```

**Memory Reduction:** **95%** (81GB+ ‚Üí 2-3GB)  
**Code Duplication Elimination:** **100%** (95+ lines ‚Üí 0 lines)

## üèóÔ∏è **ARCHITECTURE OVERVIEW**

### **MemoryEfficientDataLoader Class**
```python
class MemoryEfficientDataLoader:
    """
    üß† MEMORY-EFFICIENT DATA LOADER V3
    
    Revolutionary memory optimization:
    - Numpy memory views (zero-copy access)
    - Pre-computed labels (eliminate competitive labeling)
    - Chronological train/val splitting 
    - On-demand batch generation
    - Built-in validation and testing
    """
    
    def __init__(self, features: np.ndarray, labels: np.ndarray, window_size: int, batch_size: int):
        """
        Initialize memory-efficient data loader
        
        Args:
            features: Features array (N, 8) - will use VIEWS, not copies
            labels: Labels array (N, 3) - pre-computed from validation module
            window_size: Sequence length (default: 120)
            batch_size: Batch size for training
        """
```

### **Class Initialization & Memory Layout**
```python
def __init__(self, features: np.ndarray, labels: np.ndarray, window_size: int, batch_size: int):
    # Store references (not copies!)
    self.features = features              # Reference to features array
    self.labels = labels                  # Reference to labels array
    self.window_size = window_size
    self.batch_size = batch_size
    
    # Calculate sequence parameters
    self.total_sequences = len(features) - window_size + 1
    self.indices = np.arange(self.total_sequences)  # Sequential indices for views
    
    # Memory optimization info
    feature_memory = features.nbytes / 1024 / 1024  # MB
    sequence_memory = (self.total_sequences * window_size * features.shape[1] * 4) / 1024 / 1024  # MB if copied
    
    print(f"   üß† Memory optimization:")
    print(f"      Original features: {feature_memory:.1f} MB")
    print(f"      If sequences copied: {sequence_memory:.1f} MB")
    print(f"      With views: {feature_memory:.1f} MB (no additional memory!)")
    print(f"      Savings: {sequence_memory - feature_memory:.1f} MB ({((sequence_memory - feature_memory) / sequence_memory * 100):.1f}%)")
```

## üéØ **PRE-COMPUTED LABELS REVOLUTION**

### **V2 Problem: Competitive Labeling Duplication**
```python
# V2 - COMPETITIVE LABELING (95+ LINII DUPLIKACJI!)
def generate_competitive_labels_v2(df, index):
    """
    PROBLEMATYCZNE: Duplikacja 100% pracy validation module!
    """
    future_window = config.FUTURE_WINDOW
    current_close = df.iloc[index]['close']
    
    # Znajd≈∫ future prices w oknie
    future_prices = []
    for i in range(1, future_window + 1):
        if index + i < len(df):
            future_prices.append(df.iloc[index + i]['close'])
    
    if not future_prices:
        return 1  # HOLD
    
    # Calculate potential profits dla ka≈ºdej pozycji
    long_profits = []
    short_profits = []
    
    for future_price in future_prices:
        # LONG profit calculation
        long_profit_pct = (future_price - current_close) / current_close * 100
        
        # Check TP/SL conditions dla LONG
        if long_profit_pct >= config.LONG_TP_PCT:
            long_profits.append(config.LONG_TP_PCT)
            break
        elif long_profit_pct <= -config.LONG_SL_PCT:
            long_profits.append(-config.LONG_SL_PCT)
            break
    
    # ... similar logic for SHORT (another 50+ lines)
    
    # Determine best action (competitive logic)
    if max(long_profits) > max(short_profits):
        return 2  # LONG
    elif max(short_profits) > max(long_profits):
        return 0  # SHORT
    else:
        return 1  # HOLD
    
    # TOTAL: 95+ lines of DUPLICATE logic already done in validation module!
```

### **V3 Solution: Pre-Computed Labels**
```python
# V3 - PRE-COMPUTED LABELS (0 LINII DUPLIKACJI!)
def use_precomputed_labels_v3(self, index):
    """
    REWOLUCYJNE: Zero duplikacji - u≈ºywa gotowych labels!
    """
    # Labels ju≈º wyliczone w validation module i zapisane w training-ready file
    # Format: [label_0, label_1, label_2] = [SHORT_prob, HOLD_prob, LONG_prob]
    
    label = self.labels[index]  # (3,) array - one-hot encoded
    
    # THAT'S IT! Zero duplicate calculations!
    return label

# TOTAL: 0 lines of duplicate logic
# BENEFIT: 100% consistency with validation module
# PERFORMANCE: Instant label access vs complex calculations
```

**Code Elimination:** **95+ lines ‚Üí 0 lines**  
**Consistency:** **100%** (same labels as validation module)  
**Performance:** **Instant access** vs complex calculations

## üïí **CHRONOLOGICAL SPLITTING SYSTEM**

### **Time-Aware Train/Validation Split**
```python
def _chronological_split(self, features: np.ndarray, labels: np.ndarray, train_ratio: float = 0.8) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]:
    """
    Chronological split - CRITICAL for time series!
    
    V2 Problem: Random splitting breaks temporal dependencies
    V3 Solution: Time-aware splitting preserves chronological order
    """
    print(f"\nüïí CHRONOLOGICAL DATA SPLITTING...")
    
    # Calculate split point based on chronological order
    total_samples = len(features)
    split_index = int(total_samples * train_ratio)
    
    print(f"   üìä Total samples: {total_samples:,}")
    print(f"   üìà Train ratio: {train_ratio:.1%}")
    print(f"   üîÑ Split index: {split_index:,}")
    
    # CHRONOLOGICAL SPLIT - preserve temporal order
    train_features = features[:split_index]      # First 80% chronologically
    train_labels = labels[:split_index]
    
    val_features = features[split_index:]        # Last 20% chronologically  
    val_labels = labels[split_index:]
    
    print(f"   üèãÔ∏è Training set: {len(train_features):,} samples ({len(train_features)/total_samples:.1%})")
    print(f"   üîç Validation set: {len(val_features):,} samples ({len(val_features)/total_samples:.1%})")
    
    # Validate split integrity
    if len(train_features) == 0 or len(val_features) == 0:
        raise ValueError(f"Invalid split: train={len(train_features)}, val={len(val_features)}")
    
    # Report date ranges if available
    if hasattr(features, 'index') and hasattr(features.index, 'min'):
        print(f"   üìÖ Train period: {train_features.index.min()} to {train_features.index.max()}")
        print(f"   üìÖ Validation period: {val_features.index.min()} to {val_features.index.max()}")
    
    return (train_features, train_labels), (val_features, val_labels)
```

### **Why Chronological Splitting is Critical**
```python
# ‚ùå WRONG: Random splitting (breaks time dependencies)
def random_split_wrong(data):
    indices = np.random.permutation(len(data))
    train_indices = indices[:int(0.8 * len(data))]
    val_indices = indices[int(0.8 * len(data)):]
    # PROBLEM: Validation data from past can leak future information!

# ‚úÖ CORRECT: Chronological splitting (preserves time order)
def chronological_split_correct(data):
    split_point = int(0.8 * len(data))
    train_data = data[:split_point]    # Past data for training
    val_data = data[split_point:]      # Future data for validation
    # BENEFIT: No temporal leakage, realistic evaluation
```

## üîÑ **MEMORY-EFFICIENT GENERATORS**

### **Core Generator Implementation**
```python
def generate_sequences_with_labels(self):
    """
    Core generator function - memory-efficient sequence generation
    
    Uses numpy memory views for zero-copy access
    Yields sequences on-demand to minimize memory usage
    """
    for i in range(self.total_sequences):
        start_idx = self.indices[i]
        
        # NUMPY MEMORY VIEW - critical for memory efficiency
        # This creates a VIEW of the original array, not a COPY
        sequence = self.features[start_idx:start_idx + self.window_size]  # Shape: (120, 8)
        
        # PRE-COMPUTED LABEL ACCESS
        # Labels are already computed and stored in one-hot format
        label = self.labels[start_idx + self.window_size - 1]  # Shape: (3,) - [SHORT, HOLD, LONG]
        
        yield sequence, label

def __getitem__(self, idx):
    """
    TensorFlow-compatible indexing for generators
    Enables use with tf.data.Dataset.from_generator()
    """
    start_idx = self.indices[idx]
    
    # Memory view access
    sequence = self.features[start_idx:start_idx + self.window_size]
    label = self.labels[start_idx + self.window_size - 1]
    
    return sequence, label

def __len__(self):
    """Return total number of sequences available"""
    return self.total_sequences
```

### **Memory Views vs Copies Comparison**
```python
# üìä MEMORY COMPARISON EXAMPLE
features = np.random.random((1000000, 8)).astype(np.float32)  # 1M samples, 8 features
window_size = 120

# ‚ùå V2 APPROACH: Creating copies
def create_all_sequences_v2(features, window_size):
    sequences = []
    for i in range(len(features) - window_size + 1):
        # COPY operation - allocates new memory!
        sequence = features[i:i+window_size].copy()  
        sequences.append(sequence)
    return np.array(sequences)
    # MEMORY: ~45GB for 1M sequences

# ‚úÖ V3 APPROACH: Using views
def create_sequence_view_v3(features, start_idx, window_size):
    # VIEW operation - no new memory allocation!
    return features[start_idx:start_idx + window_size]
    # MEMORY: Original array size only (~30MB)

# Memory savings: 45GB ‚Üí 30MB (99.9% reduction!)
```

## üß™ **GENERATOR VALIDATION & TESTING**

### **Built-in Generator Testing**
```python
def test_generator(generator, num_batches: int = 5, verbose: bool = True):
    """
    üß™ COMPREHENSIVE GENERATOR TESTING
    
    Validates generator functionality, memory usage, and data integrity
    Critical for ensuring generator works correctly before training
    """
    print(f"\nüß™ TESTING GENERATOR...")
    print(f"   üîç Test batches: {num_batches}")
    
    # Track memory usage during testing
    import psutil
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    batch_count = 0
    total_sequences = 0
    
    # Test generator iteration
    try:
        for sequences, labels in generator:
            batch_count += 1
            current_batch_size = len(sequences)
            total_sequences += current_batch_size
            
            if verbose:
                print(f"   üì¶ Batch {batch_count}: {current_batch_size} sequences")
                print(f"      Sequences shape: {sequences.shape}")
                print(f"      Labels shape: {labels.shape}")
                
                # Validate sequence values
                if np.isnan(sequences).any():
                    print(f"      ‚ö†Ô∏è NaN values detected in sequences!")
                if np.isinf(sequences).any():
                    print(f"      ‚ö†Ô∏è Inf values detected in sequences!")
                    
                # Validate label values
                if np.isnan(labels).any():
                    print(f"      ‚ö†Ô∏è NaN values detected in labels!")
                    
                # Check label format (should be one-hot)
                label_sums = np.sum(labels, axis=1)
                if not np.allclose(label_sums, 1.0, atol=1e-6):
                    print(f"      ‚ö†Ô∏è Labels not properly one-hot encoded!")
            
            # Memory monitoring
            current_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = current_memory - initial_memory
            
            if verbose and memory_increase > 100:  # Alert if memory increases significantly
                print(f"      üíæ Memory increase: {memory_increase:.1f} MB")
            
            # Stop after specified number of batches
            if batch_count >= num_batches:
                break
                
    except Exception as e:
        print(f"   ‚ùå Generator test failed: {e}")
        return False
    
    final_memory = process.memory_info().rss / 1024 / 1024
    memory_increase = final_memory - initial_memory
    
    print(f"   ‚úÖ Generator test completed successfully!")
    print(f"   üìä Total sequences tested: {total_sequences}")
    print(f"   üíæ Memory increase: {memory_increase:.1f} MB")
    print(f"   üéØ Memory efficiency: {'EXCELLENT' if memory_increase < 50 else 'GOOD' if memory_increase < 200 else 'POOR'}")
    
    return True
```

### **Generator Validation Functions**
```python
def validate_generator_output(self, num_samples: int = 100):
    """
    Validate generator output format and data integrity
    """
    print(f"\nüîç VALIDATING GENERATOR OUTPUT...")
    
    sample_count = 0
    for sequence, label in self.generate_sequences_with_labels():
        # Validate sequence shape
        expected_sequence_shape = (self.window_size, self.features.shape[1])
        if sequence.shape != expected_sequence_shape:
            raise ValueError(f"Invalid sequence shape: expected {expected_sequence_shape}, got {sequence.shape}")
        
        # Validate label shape  
        expected_label_shape = (self.labels.shape[1],)
        if label.shape != expected_label_shape:
            raise ValueError(f"Invalid label shape: expected {expected_label_shape}, got {label.shape}")
        
        # Validate data types
        if sequence.dtype != np.float32:
            print(f"   ‚ö†Ô∏è Sequence dtype warning: expected float32, got {sequence.dtype}")
        if label.dtype != np.float32:
            print(f"   ‚ö†Ô∏è Label dtype warning: expected float32, got {label.dtype}")
        
        # Validate value ranges
        if np.isnan(sequence).any() or np.isinf(sequence).any():
            raise ValueError(f"Invalid sequence values: contains NaN or Inf")
        if np.isnan(label).any() or np.isinf(label).any():
            raise ValueError(f"Invalid label values: contains NaN or Inf")
        
        # Check if label is properly one-hot encoded
        if not np.allclose(np.sum(label), 1.0, atol=1e-6):
            raise ValueError(f"Label not properly one-hot encoded: sum={np.sum(label)}")
        
        sample_count += 1
        if sample_count >= num_samples:
            break
    
    print(f"   ‚úÖ Generator validation passed ({sample_count} samples tested)")
```

## üéõÔ∏è **MAIN GENERATOR CREATION FUNCTIONS**

### **Primary Generator Creation Function**
```python
def create_generators_from_arrays(features: np.ndarray, labels: np.ndarray, 
                                config_params: dict) -> Tuple[Any, Any]:
    """
    üéõÔ∏è MAIN FUNCTION: Create train and validation generators
    
    This is the primary interface used by trainer.py
    Handles chronological splitting and generator creation
    """
    print(f"\nüéõÔ∏è CREATING MEMORY-EFFICIENT GENERATORS...")
    
    # Extract parameters from config
    window_size = config_params.get('sequence_length', 120)
    batch_size = config_params.get('batch_size', 256)
    validation_split = config_params.get('validation_split', 0.2)
    
    print(f"   üîß Configuration:")
    print(f"      Window size: {window_size}")
    print(f"      Batch size: {batch_size}")
    print(f"      Validation split: {validation_split:.1%}")
    print(f"      Input features shape: {features.shape}")
    print(f"      Input labels shape: {labels.shape}")
    
    # Chronological split (critical for time series!)
    train_ratio = 1.0 - validation_split
    (train_features, train_labels), (val_features, val_labels) = _chronological_split(
        features, labels, train_ratio
    )
    
    # Create generators
    print(f"\nüèãÔ∏è Creating training generator...")
    train_generator = MemoryEfficientDataLoader(
        features=train_features,
        labels=train_labels,
        window_size=window_size,
        batch_size=batch_size
    )
    
    print(f"\nüîç Creating validation generator...")
    val_generator = MemoryEfficientDataLoader(
        features=val_features,
        labels=val_labels,
        window_size=window_size,
        batch_size=batch_size
    )
    
    # Test generators
    print(f"\nüß™ Testing generators...")
    if not test_generator(iter(train_generator), num_batches=2, verbose=True):
        raise RuntimeError("Training generator test failed")
    if not test_generator(iter(val_generator), num_batches=2, verbose=True):
        raise RuntimeError("Validation generator test failed")
    
    print(f"\n‚úÖ GENERATORS CREATED SUCCESSFULLY!")
    print(f"   üèãÔ∏è Training generator: {len(train_generator):,} sequences")
    print(f"   üîç Validation generator: {len(val_generator):,} sequences")
    
    return train_generator, val_generator
```

## üìä **TENSORFLOW INTEGRATION**

### **TensorFlow Dataset Creation**
```python
def create_tf_dataset(self, repeat: bool = True, shuffle: bool = True, 
                     shuffle_buffer_size: int = 10000):
    """
    Create TensorFlow Dataset from generator for optimal training performance
    
    Args:
        repeat: Whether to repeat dataset indefinitely
        shuffle: Whether to shuffle sequences (maintains temporal order within sequences)
        shuffle_buffer_size: Buffer size for shuffling
    """
    import tensorflow as tf
    
    # Define output signature for TensorFlow
    output_signature = (
        tf.TensorSpec(shape=(self.window_size, self.features.shape[1]), dtype=tf.float32),
        tf.TensorSpec(shape=(self.labels.shape[1],), dtype=tf.float32)
    )
    
    # Create dataset from generator
    dataset = tf.data.Dataset.from_generator(
        generator=self.generate_sequences_with_labels,
        output_signature=output_signature
    )
    
    # Apply transformations
    if shuffle:
        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)
    
    # Batch sequences
    dataset = dataset.batch(self.batch_size)
    
    # Optimize performance
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    
    if repeat:
        dataset = dataset.repeat()
    
    return dataset
```

## üéØ **USAGE EXAMPLES**

### **Example 1: Basic Generator Creation**
```python
# Data from data_loader
data_info = data_loader.load_training_data()
features = data_info['features']  # (N, 8)
labels = data_info['labels']      # (N, 3)

# Create generators
config_params = {
    'sequence_length': config.SEQUENCE_LENGTH,
    'batch_size': config.BATCH_SIZE,
    'validation_split': config.VALIDATION_SPLIT
}

train_gen, val_gen = create_generators_from_arrays(features, labels, config_params)

# Use in training
for sequences, labels in train_gen:
    # sequences: (batch_size, 120, 8)
    # labels: (batch_size, 3)
    pass
```

### **Example 2: TensorFlow Integration**
```python
# Create TensorFlow datasets
train_dataset = train_gen.create_tf_dataset(repeat=True, shuffle=True)
val_dataset = val_gen.create_tf_dataset(repeat=False, shuffle=False)

# Use with Keras model
model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=config.EPOCHS,
    steps_per_epoch=len(train_gen) // config.BATCH_SIZE,
    validation_steps=len(val_gen) // config.BATCH_SIZE
)
```

### **Example 3: Generator Testing & Debugging**
```python
# Test generator before training
train_gen = MemoryEfficientDataLoader(features, labels, 120, 256)

# Validate output format
train_gen.validate_generator_output(num_samples=100)

# Test memory efficiency
test_generator(iter(train_gen), num_batches=10, verbose=True)

# Debug sequence content
for i, (sequence, label) in enumerate(train_gen.generate_sequences_with_labels()):
    print(f"Sequence {i}: shape={sequence.shape}, label={np.argmax(label)}")
    if i >= 5:
        break
```

---

**üéØ KLUCZOWE ZALETY SEQUENCE GENERATOR V3:**
- ‚úÖ **95% Memory Reduction** - 81GB+ ‚Üí 2-3GB through numpy views
- ‚úÖ **100% Code Elimination** - 95+ lines of competitive labeling removed
- ‚úÖ **Zero Data Leakage** - proper chronological train/validation splitting
- ‚úÖ **Memory View Technology** - zero-copy sequence access
- ‚úÖ **Pre-Computed Labels** - perfect consistency with validation module
- ‚úÖ **Production Testing** - comprehensive validation and debugging tools
- ‚úÖ **TensorFlow Integration** - optimized for Keras training pipelines

**üìà NEXT:** [06_Model_builder.md](./06_Model_builder.md) - LSTM architecture and production callbacks 