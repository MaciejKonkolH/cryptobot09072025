# Algorytm Trenowania Dwuokiennego Systemu ML

*Ostatnia aktualizacja: 25 maja 2025*  
*Status: Production-ready (v2.0.0)*  
*Lokalizacja kodu: `Freqtrade/ft_bot_docker_compose/user_data/training/`*
*Verified against code: âœ…*

## ğŸ¯ PrzeglÄ…d Algorytmu

System trenowania implementuje **dwuokienne podejÅ›cie** (Dual Window Approach) eliminujÄ…ce data leakage w modelach predykcyjnych dla handlu kryptowalutami. GÅ‚Ã³wnÄ… zasadÄ… jest **Å›cisÅ‚a separacja czasowa** miÄ™dzy danymi wejÅ›ciowymi modelu a weryfikacjÄ… etykiet.

### ğŸ”‘ Kluczowa Zasada: Temporal Separation
```
[Å›wiece i-60:i] â†â”€â”€ HISTORICAL WINDOW (dane dla modelu LSTM)
     â†“
[Å›wieca i] â†â”€â”€ PREDICTION POINT (moment decyzji handlowej)
     â†“  
[Å›wiece i+1:i+61] â†â”€â”€ FUTURE WINDOW (weryfikacja etykiet post-factum)
```

## ğŸ“‹ GÅ‚Ã³wne Komponenty Systemu

### 1. **DualWindowTrainingPipeline** (Orkiestrator)
- Koordynuje wszystkie etapy treningu
- ZarzÄ…dza przepÅ‚ywem danych miÄ™dzy komponentami
- Implementuje time-aware split dla walidacji

### 2. **EnhancedFeatherLoader** (Åadowanie Danych)
- Inteligentne Å‚adowanie plikÃ³w .feather z automatycznym bufferem
- Oblicza wymagane bufory historyczne (33 dni total)
- Konwertuje i waliduje dane czasowe z timezone handling

### 3. **DualWindowSequenceBuilder** (Tworzenie Sekwencji)
- Implementuje separacjÄ™ temporal windows
- Tworzy sekwencje treningowe z eliminacjÄ… data leakage
- Generuje etykiety hybrydowe na podstawie TP/SL
- Progress tracking co 5,000 sekwencji

### 4. **DualWindowLSTMModel** (Model ML)
- cuDNN-optimized LSTM model bez recurrent_dropout
- Input: (60 Å›wiec, 8 cech) â†’ Output: 3 klasy (SHORT/HOLD/LONG)
- Legacy RMSprop optimizer z decay

### 5. **ModelEvaluator** (Ewaluacja)
- Trading-focused metrics (F1 dla sygnaÅ‚Ã³w handlowych)
- Confusion matrix, classification report
- Analiza rozkÅ‚adu klas i balansowania

## ğŸ”„ SzczegÃ³Å‚owy PrzepÅ‚yw Algorytmu

### KROK 1: Inicjalizacja i Konfiguracja
```
ğŸ“‹ TrainingConfig
â”œâ”€â”€ WINDOW_SIZE = 60 Å›wiec (Historical Window)
â”œâ”€â”€ FUTURE_WINDOW = 60 Å›wiec (Future Window) 
â”œâ”€â”€ LONG_TP_PCT = 0.007 (0.7% Take Profit)
â”œâ”€â”€ LONG_SL_PCT = 0.007 (0.7% Stop Loss)
â”œâ”€â”€ MA_FAST_PERIODS = 1440 (24h)
â”œâ”€â”€ MA_SLOW_PERIODS = 43200 (30 dni)
â”œâ”€â”€ LEARNING_RATE = 0.0005
â”œâ”€â”€ EPOCHS = 100
â””â”€â”€ 8 FEATURE_COLUMNS (cechy wejÅ›ciowe)
```

**Walidacja:**
- Sprawdzenie sensownoÅ›ci okien czasowych (max 1440 = 24h)
- Walidacja parametrÃ³w TP/SL (0 < x < 1)
- Obliczenie wymaganego buforu historycznego

### KROK 2: Åadowanie Danych z Inteligentnym Bufferem
```
ğŸ“Š EnhancedFeatherLoader.load_training_data()
â”œâ”€â”€ Obliczenie extended_start = training_start - buffer_days
â”œâ”€â”€ Odnalezienie plikÃ³w .feather dla pary walutowej
â”œâ”€â”€ Konwersja timestamp â†’ datetime index (timezone-naive)
â”œâ”€â”€ Filtrowanie do zakresu dat
â””â”€â”€ Walidacja wystarczalnoÅ›ci danych
```

**Buffer Calculation (POPRAWIONE):**
```python
# MA Buffer
ma_buffer_days = max(
    MA_FAST_PERIODS // (24 * 60),   # 1440 // 1440 = 1 dzieÅ„
    MA_SLOW_PERIODS // (24 * 60)    # 43200 // 1440 = 30 dni
) = 30 dni

# Window Buffer  
window_buffer_days = (WINDOW_SIZE + FUTURE_WINDOW) // (24 * 60) + 1
                   = (60 + 60) // 1440 + 1 = 0 + 1 = 1 dzieÅ„

# Safety Buffer
safety_buffer_days = 2 dni

# TOTAL BUFFER = 30 + 1 + 2 = 33 dni
```

### KROK 3: Feature Engineering z Zero-Safe Operations
```
ğŸ”§ Obliczanie 8 Cech Technicznych (Parametryzowane):
â”œâ”€â”€ high_change = np.where(open == 0, 0, (high - open) / open)
â”œâ”€â”€ low_change = np.where(open == 0, 0, (low - open) / open) 
â”œâ”€â”€ close_change = np.where(open == 0, 0, (close - open) / open)
â”œâ”€â”€ volume_change = volume.pct_change().fillna(0)
â”œâ”€â”€ price_to_ma1440 = np.where(ma_fast == 0, 1.0, close / ma_fast)
â”œâ”€â”€ price_to_ma43200 = np.where(ma_slow == 0, 1.0, close / ma_slow)
â”œâ”€â”€ volume_to_ma1440 = np.where(vol_ma_fast == 0, 1.0, volume / vol_ma_fast)
â””â”€â”€ volume_to_ma43200 = np.where(vol_ma_slow == 0, 1.0, volume / vol_ma_slow)
```

**Implementacja z parametryzacjÄ…:**
- MA periods z `config.MA_FAST_PERIODS` i `config.MA_SLOW_PERIODS`
- Zero-safe divisions z fallback values
- `.replace([np.inf, -np.inf], fallback)` dla czyszczenia
- Forward/backward fill dla brakujÄ…cych wartoÅ›ci

### KROK 4: Tworzenie Sekwencji Dwuokiennych â­
```
ğŸ”„ DualWindowSequenceBuilder.create_training_sequences()

FOR kaÅ¼da Å›wieca i w zakresie [WINDOW_SIZE : len(df) - FUTURE_WINDOW]:
    
    # Progress tracking co 5,000 sekwencji
    if processed_count % 5000 == 0 and processed_count > 0:
        progress = (processed_count / total_sequences) * 100
        print(f"   Tworzenie sekwencji: {processed_count:,}/{total_sequences:,} ({progress:.1f}%)")
    
    1. HISTORICAL WINDOW (dane dla modelu):
       features[i-60:i] â†’ X_sequence (60 Å›wiec Ã— 8 cech)
    
    2. PREDICTION POINT (moment decyzji):
       base_price = close[i]
       timestamp = index[i]
    
    3. FUTURE WINDOW (weryfikacja etykiety):
       future_candles = df[i+1:i+61]
       
    4. LABEL CREATION (hybrydowa klasyfikacja):
       long_tp = base_price Ã— (1 + 0.007)
       long_sl = base_price Ã— (1 - 0.007)
       short_tp = base_price Ã— (1 - 0.007)
       short_sl = base_price Ã— (1 + 0.007)
       
       long_tp_hit = any(future_candles.high >= long_tp)
       long_sl_hit = any(future_candles.low <= long_sl)
       short_tp_hit = any(future_candles.low <= short_tp)
       short_sl_hit = any(future_candles.high >= short_sl)
       
       IF long_tp_hit AND NOT long_sl_hit AND NOT (short_tp_hit AND NOT short_sl_hit):
           label = 2  # LONG
       ELIF short_tp_hit AND NOT short_sl_hit AND NOT (long_tp_hit AND NOT long_sl_hit):
           label = 0  # SHORT
       ELSE:
           label = 1  # HOLD
    
    5. APPEND TO TRAINING SET:
       X.append(features[i-60:i])  # shape: (60, 8)
       y.append(label)             # scalar: 0, 1, or 2
       timestamps.append(timestamp)

# Data leakage validation z progress co 10,000 par
_validate_no_data_leakage(timestamps)

RETURN X, y, timestamps, metadata
```

**Kluczowe aspekty:**
- **Zero data leakage**: Model NIE widzi przyszÅ‚ych danych podczas treningu
- **Temporal consistency**: Wszystkie sekwencje w porzÄ…dku chronologicznym
- **Hybrydowa klasyfikacja**: UwzglÄ™dnia zarÃ³wno TP jak i SL w jednej etykiecie
- **Progress monitoring**: Real-time feedback dla dÅ‚ugich operacji

### KROK 5: Time-Aware Split
```
âœ‚ï¸ Chronologiczny podziaÅ‚ danych:
â”œâ”€â”€ split_idx = len(X) Ã— config.TRAIN_TEST_SPLIT  # 0.8
â”œâ”€â”€ X_train = X[:split_idx]    (80% wczeÅ›niejszych danych)
â”œâ”€â”€ X_val = X[split_idx:]      (20% pÃ³Åºniejszych danych)
â”œâ”€â”€ Walidacja: train_end < val_start (brak data leakage)
â””â”€â”€ Sprawdzenie chronologii timestamps
```

### KROK 6: Balansowanie Klas (opcjonalne)
```
âš–ï¸ Class Balancing:
IF config.BALANCE_CLASSES:
    class_weights = compute_class_weight(
        'balanced', 
        classes=[0, 1, 2], 
        y=y_train
    )
    # ZwiÄ™kszenie wag dla klas <10% (x2.0)
    # ObsÅ‚uga ekstremalnego niezbalansowania (>90% jedna klasa)
ELSE:
    class_weights = None
```

### KROK 7: Budowanie Modelu LSTM (cuDNN-Optimized)
```
ğŸ—ï¸ build_dual_window_lstm_model() - RZECZYWISTA ARCHITEKTURA:
Input: (None, 60, 8)

# LSTM Stack (BEZ dropout/recurrent_dropout dla cuDNN optimization)
FOR i, units in enumerate(config.LSTM_UNITS):  # [128, 64, 32]
    return_sequences = (i < len(config.LSTM_UNITS) - 1)
    x = LSTM(
        units,
        return_sequences=return_sequences,
        name=f'lstm_{i+1}',
        activation='tanh',              # explicit dla cuDNN
        recurrent_activation='sigmoid', # required dla cuDNN
        use_bias=True,                  # required dla cuDNN
        # USUNIÄ˜TE: dropout, recurrent_dropout, kernel_regularizer
    )(x)
    # USUNIÄ˜TE: BatchNormalization (problemy z gradientami)

# Dense Stack (z Dropout)
FOR i, units in enumerate(config.DENSE_UNITS):  # [32, 16]
    x = Dense(units, activation='relu', name=f'dense_{i+1}')(x)
    x = Dropout(config.DROPOUT_RATE + 0.1, name=f'dropout_{i+1}')(x)  # 0.2 + 0.1 = 0.3

# Output Layer
â””â”€â”€ Dense(3, activation='softmax', name='output')  # [prob_SHORT, prob_HOLD, prob_LONG]

Compilation:
â”œâ”€â”€ Optimizer: tf.keras.optimizers.legacy.RMSprop(lr=0.0005, decay=1e-6)
â”œâ”€â”€ Loss: sparse_categorical_crossentropy
â””â”€â”€ Metrics: accuracy
```

**ğŸš€ cuDNN Optimizations:**
- **REMOVED**: `dropout`, `recurrent_dropout`, `kernel_regularizer` z LSTM layers
- **REMOVED**: `BatchNormalization` layers (problemy z gradientami)
- **EXPLICIT**: `activation='tanh'`, `recurrent_activation='sigmoid'`
- **PRESERVED**: `Dropout` tylko w Dense layers
- **LEGACY**: `tf.keras.optimizers.legacy.RMSprop` dla kompatybilnoÅ›ci

### KROK 8: Konfiguracja Callbacks
```
ğŸ“‹ Training Callbacks:
â”œâ”€â”€ EarlyStopping(
â”‚     monitor='val_loss', 
â”‚     patience=15,
â”‚     restore_best_weights=True,
â”‚     verbose=1,
â”‚     mode='min'
â”‚   )
â”œâ”€â”€ ReduceLROnPlateau(
â”‚     monitor='val_loss', 
â”‚     factor=0.5, 
â”‚     patience=8,
â”‚     min_lr=1e-7,
â”‚     verbose=1,
â”‚     mode='min'
â”‚   )
â””â”€â”€ ModelCheckpoint(
      monitor='val_accuracy', 
      save_best_only=True,
      save_weights_only=False,
      verbose=1,
      mode='max'
    )
```

### KROK 9: Trening Modelu
```
ğŸ¯ Model Training:
model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=config.EPOCHS,           # 100
    batch_size=config.BATCH_SIZE,   # 32
    callbacks=callbacks,
    class_weight=class_weights,
    verbose=1
)
```

### KROK 10: Ewaluacja Modelu
```
ğŸ“Š ModelEvaluator.evaluate_model():
â”œâ”€â”€ Podstawowe metryki: test_loss, test_accuracy
â”œâ”€â”€ Predykcje: y_pred = argmax(model.predict(X_test))
â”œâ”€â”€ Classification Report (precision, recall, F1 per klasa)
â”œâ”€â”€ Confusion Matrix
â”œâ”€â”€ Trading-focused metrics:
â”‚   â”œâ”€â”€ SHORT Precision/Recall (sygnaÅ‚y sprzedaÅ¼y)
â”‚   â”œâ”€â”€ LONG Precision/Recall (sygnaÅ‚y kupna)
â”‚   â””â”€â”€ TRADING SIGNALS AVG F1 (Å›rednia F1 dla SHORT+LONG, bez HOLD)
â””â”€â”€ RozkÅ‚ad predykcji vs rzeczywistych etykiet
```

**Kluczowe metryki:**
- **TRADING SIGNALS AVG F1**: Å›rednia F1 dla klas SHORT i LONG (bez HOLD)
- **Obecny poziom**: ~0.17 (cel: >0.25)
- **SHORT/LONG Recall**: czy model znajduje moÅ¼liwoÅ›ci handlowe

### KROK 11: Zapis ArtefaktÃ³w
```
ğŸ’¾ save_model_artifacts():
â”œâ”€â”€ dual_window_lstm_model.keras        (finalny model)
â”œâ”€â”€ training_config.json                (uÅ¼yta konfiguracja)
â”œâ”€â”€ evaluation_results.json             (wyniki ewaluacji)
â””â”€â”€ model_metadata.json                 (metadane: timestamp, version, parameters)
```

## ğŸ” Kluczowe RÃ³Å¼nice vs Poprzednie Wersje

### Dwuokienny System (v2.0) vs Prosty System (v1.0)
| Aspekt | Prosty System | Dwuokienny System |
|--------|---------------|-------------------|
| **Data leakage** | MoÅ¼liwy (brak separacji) | Eliminowany (temporal separation) |
| **Etykietowanie** | Prosty price shift | Hybrydowe TP/SL classification |
| **Model type** | Regresja (1 output) | Klasyfikacja (3 klasy) |
| **Walidacja** | Random split | Time-aware split |
| **Sekwencje** | expand_dims hack | WÅ‚aÅ›ciwe okna czasowe |
| **Buffer management** | Brak | Inteligentny auto-buffer (33 dni) |
| **GPU optimization** | Brak | cuDNN-compatible LSTM |

### vs Oryginalny BinanceBot
| Aspekt | BinanceBot | Dwuokienny Freqtrade |
|--------|-------------|----------------------|
| **Data source** | SQLite | Pliki .feather |
| **Format danych** | WÅ‚asny | Natywny Freqtrade |
| **Deployment** | Standalone | Docker container |
| **Configuracja** | Python files | JSON + dataclass |
| **Timezone handling** | Manual | Automatic timezone-naive conversion |

## âš¡ Optymalizacje i Innowacje

### 1. **Temporal Separation**
- Model NIE MA dostÄ™pu do przyszÅ‚ych danych podczas predykcji
- Eliminuje optimistic bias typowy dla ML w finansach

### 2. **Inteligentny Buffer Management**
- Automatyczne obliczanie wymaganych buforÃ³w (33 dni total)
- UwzglÄ™dnia potrzeby MA, windows, safety margins

### 3. **Hybrydowa Klasyfikacja**
- Etykiety bazujÄ… na rzeczywistych warunkach TP/SL
- UwzglÄ™dnia zÅ‚oÅ¼onoÅ›Ä‡ rzeczywistych decyzji handlowych

### 4. **Trading-Focused Metrics**
- Metryki optymalizowane pod sygnaÅ‚y handlowe
- F1 dla SHORT/LONG waÅ¼niejsze niÅ¼ ogÃ³lna accuracy

### 5. **cuDNN GPU Optimization**
- LSTM layers bez dropout/recurrent_dropout
- Explicit activation functions dla cuDNN compatibility
- Legacy RMSprop dla stabilnoÅ›ci

### 6. **Zero-Safe Operations**
- `np.where(denominator == 0, fallback, division)` dla wszystkich obliczeÅ„
- Automatic handling inf/NaN values
- Robust feature engineering

### 7. **Progress Monitoring**
- Real-time tracking dla sequence creation (co 5,000)
- Data leakage validation progress (co 10,000)
- Comprehensive logging na kaÅ¼dym etapie

### 8. **Production-Ready Pipeline**
- PeÅ‚na walidacja danych na kaÅ¼dym etapie
- Error handling i informative logging
- Systematyczny zapis artefaktÃ³w

## ğŸ¯ Oczekiwane Wyniki

### Obecne Benchmarki (7-dniowy test)
```
âœ… Test Accuracy: 60.34%
âœ… Trading F1: 0.171
âœ… SHORT Recall: 29.7%
âœ… LONG Recall: 35.6%
âœ… Zero tensor shape errors
âœ… Zero timezone issues
âœ… cuDNN optimization working
âœ… Progress tracking functional
```

### Cele Rozwojowe
```
ğŸ¯ KrÃ³tkoterminowe (3-6 miesiÄ™cy danych):
â”œâ”€â”€ Trading F1: >0.25 (+46% improvement)
â”œâ”€â”€ Lepsze class balancing
â””â”€â”€ Dodatkowe features

ğŸ¯ DÅ‚ugoterminowe:
â”œâ”€â”€ Multi-timeframe ensemble
â”œâ”€â”€ Advanced feature engineering
â”œâ”€â”€ Real-time prediction API
â””â”€â”€ Portfolio-based signals
```

## ğŸš€ Uruchomienie Treningu

### Podstawowy trening (POPRAWIONE CLI):
```bash
cd "C:\Users\macie\OneDrive\Python\Binance\Freqtrade\ft_bot_docker_compose\user_data\training"

python scripts\train_dual_window_model.py \
  --pair BTC_USDT \
  --date-from 2024-01-01 \
  --date-to 2024-06-30 \
  --epochs 100 \
  --batch-size 32 \
  --learning-rate 0.0005
```

### Preset system:
```bash
# Szybki test
python scripts\train_dual_window_model.py --preset test

# Standardowy trening
python scripts\train_dual_window_model.py --preset standard

# Produkcyjny (peÅ‚ne dane)
python scripts\train_dual_window_model.py --preset production
```

### Test i walidacja:
```bash
# SprawdÅº dostÄ™pnoÅ›Ä‡ danych
python scripts\train_dual_window_model.py --pair BTC_USDT --date-from 2024-01-01 --date-to 2024-01-07 --validate-data

# Dry run (bez treningu)
python scripts\train_dual_window_model.py --pair BTC_USDT --date-from 2024-01-01 --date-to 2024-01-07 --dry-run

# Szybki test (2 epoki)
python scripts\train_dual_window_model.py --pair BTC_USDT --date-from 2024-01-01 --date-to 2024-01-07 --epochs 2
```

---

**Ten algorytm reprezentuje state-of-the-art w zastosowaniu uczenia maszynowego do automatycznego handlu, z naciskiem na eliminacjÄ™ data leakage, optymalizacjÄ™ GPU i praktyczne rezultaty handlowe.**

*Dokumentacja zweryfikowana wzglÄ™dem kodu - wersja 2.0.0 verified âœ…*
