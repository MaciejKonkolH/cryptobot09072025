# ğŸ¯ Kompletna Dokumentacja ModuÅ‚u Treningowego Freqtrade

*Data utworzenia: 27 stycznia 2025*  
*Wersja: 3.0*  
*Status: âœ… Implementacja zakoÅ„czona z Confidence Thresholding*  
*Scalono z dwÃ³ch dokumentÃ³w: Medul_treningowy_dokumentacja.md + Modul_trenowania_modeli.md*

## ğŸ“‹ Spis TreÅ›ci

1. [PrzeglÄ…d Systemu](#1-przeglÄ…d-systemu)
2. [Architektura Dwuokiennego PodejÅ›cia](#2-architektura-dwuokiennego-podejÅ›cia)
3. [ğŸ†• Confidence Thresholding](#3-confidence-thresholding)
4. [Komponenty Systemu](#4-komponenty-systemu)
5. [Konfiguracja](#5-konfiguracja)
6. [ğŸ³ Docker Wrapper - ZALECANY SPOSÃ“B](#6-docker-wrapper---zalecany-sposÃ³b)
7. [Instrukcje UÅ¼ycia](#7-instrukcje-uÅ¼ycia)
8. [System Presets](#8-system-presets)
9. [Analiza WynikÃ³w](#9-analiza-wynikÃ³w)
10. [RozwiÄ…zywanie ProblemÃ³w](#10-rozwiÄ…zywanie-problemÃ³w)
11. [Zalecenia](#11-zalecenia)

---

## 1. PrzeglÄ…d Systemu

### 1.1. Cel i Zastosowanie

Dwuokienny moduÅ‚ trenujÄ…cy to zaawansowany system uczenia maszynowego dla Freqtrade, ktÃ³ry:

- **Generuje sygnaÅ‚y handlowe** (SHORT/HOLD/LONG) na podstawie analizy technicznej
- **Eliminuje data leakage** poprzez Å›cisÅ‚Ä… separacjÄ™ czasowÄ…
- **ğŸ†• Implementuje confidence thresholding** dla selektywnych predykcji
- **Symuluje rzeczywiste warunki handlowe** gdzie trader ma dostÄ™p tylko do przeszÅ‚oÅ›ci
- **UÅ¼ywa hybrydowego etykietowania** bazujÄ…cego na Take Profit/Stop Loss

### 1.2. ğŸ†• Najnowsze FunkcjonalnoÅ›ci (v3.0)

âœ… **Confidence Thresholding System**
- Conservative/Aggressive/Balanced modes
- Osobne progi dla SHORT (60%), LONG (60%), HOLD (40%)
- Automatyczne przeÅ‚Ä…czanie na HOLD przy niskiej pewnoÅ›ci

âœ… **Zaawansowane ZarzÄ…dzanie PamiÄ™ciÄ…**
- Batch processing dla duÅ¼ych zbiorÃ³w danych
- Memory monitoring z automatycznym cleanup
- Vectorized labeling (300% szybsze)

âœ… **Deterministyczny Trening**
- Fixed seed dla reprodukowalnoÅ›ci
- Eliminacja randomowych wynikÃ³w miÄ™dzy treningami

### 1.3. Kluczowe Innowacje

1. **Temporal Separation**: Rozdzielenie danych wejÅ›ciowych od weryfikacji etykiet
2. **ğŸ†• Confidence-Based Predictions**: Model wymaga 60%+ pewnoÅ›ci dla sygnaÅ‚Ã³w
3. **Realistic Trading Simulation**: Model nie ma dostÄ™pu do przyszÅ‚oÅ›ci
4. **Advanced Class Balancing**: Inteligentne wagi dla niezbalansowanych danych
5. **Production-Ready Pipeline**: Kompletny system z callbacks i artefaktami
6. **ğŸ³ Docker Integration**: PeÅ‚na integracja z wrapper do GPU treningu

---

## 2. Architektura Dwuokiennego PodejÅ›cia

### 2.1. Fundamentalna Zasada

**ğŸ”‘ KLUCZOWE**: Model NIE moÅ¼e widzieÄ‡ przyszÅ‚oÅ›ci podczas predykcji

```
TIMELINE dla Å›wiecy i=1000:

[Å›wiece 940-999] â†â”€â”€ HISTORICAL WINDOW (60 Å›wiec)
     â†“              Dane wejÅ›ciowe dla modelu
[Å›wieca 1000] â†â”€â”€ PREDICTION POINT
     â†“              Punkt decyzji handlowej  
[Å›wiece 1001-1060] â†â”€â”€ FUTURE WINDOW (60 Å›wiec)
                      Weryfikacja skutecznoÅ›ci sygnaÅ‚u
```

### 2.2. Historical Window (Input)

```python
# Co model widzi:
WINDOW_SIZE = 90  # 90 ostatnich Å›wiec (zaktualizowane w v3.0)
INPUT_FEATURES = 8  # Cechy techniczne

# Shape: (batch_size, 90, 8)
historical_features = [
    'high_change', 'low_change', 'close_change', 'volume_change',
    'price_to_ma1440', 'price_to_ma43200', 
    'volume_to_ma1440', 'volume_to_ma43200'
]

# Cel: "Na podstawie ostatnich 90 minut - jaki sygnaÅ‚?"
```

### 2.3. Future Window (Verification)

```python
# Jak weryfikujemy skutecznoÅ›Ä‡:
FUTURE_WINDOW = 90  # 90 nastÄ™pnych Å›wiec (zaktualizowane w v3.0)
TP_THRESHOLD = 1.0%  # Take Profit (zaktualizowane)
SL_THRESHOLD = 0.5%  # Stop Loss (zaktualizowane)

# Hybrydowa klasyfikacja:
if long_tp_hit and not long_sl_hit:
    label = 2  # LONG
elif short_tp_hit and not short_sl_hit:
    label = 0  # SHORT  
else:
    label = 1  # HOLD
```

### 2.4. Eliminacja Data Leakage

```python
# âœ… PRAWIDÅOWE: Model nie widzi przyszÅ‚oÅ›ci
X[i] = historical_features[i-90:i]      # PrzeszÅ‚oÅ›Ä‡
y[i] = verify_signal[i+1:i+91]          # PrzyszÅ‚oÅ›Ä‡ (tylko weryfikacja)

# âŒ BÅÄ˜DNE: Model widziaÅ‚by przyszÅ‚oÅ›Ä‡  
X[i] = features[i-45:i+45]              # ZAWIERA PRZYSZÅOÅšÄ†!
```

---

## 3. ğŸ†• Confidence Thresholding

### 3.1. Zasada DziaÅ‚ania

Confidence Thresholding to nowa funkcjonalnoÅ›Ä‡ w v3.0, ktÃ³ra pozwala modelowi na:
- **Selektywne predykcje**: Model otwiera pozycjÄ™ tylko gdy jest wystarczajÄ…co pewny
- **Automatyczne HOLD**: Przy niskiej pewnoÅ›ci model wybiera bezpiecznÄ… opcjÄ™ HOLD
- **RÃ³Å¼ne tryby**: Conservative, Aggressive, Balanced dla rÃ³Å¼nych strategii

### 3.2. Tryby Confidence

#### ğŸ›¡ï¸ Conservative Mode (domyÅ›lny)
```python
CONFIDENCE_THRESHOLD_SHORT = 0.70  # 70% pewnoÅ›ci dla SHORT
CONFIDENCE_THRESHOLD_LONG = 0.70   # 70% pewnoÅ›ci dla LONG  
CONFIDENCE_THRESHOLD_HOLD = 0.30   # 30% wystarczy dla HOLD
```

#### âš¡ Aggressive Mode
```python
CONFIDENCE_THRESHOLD_SHORT = 0.45  # 45% pewnoÅ›ci dla SHORT
CONFIDENCE_THRESHOLD_LONG = 0.45   # 45% pewnoÅ›ci dla LONG
CONFIDENCE_THRESHOLD_HOLD = 0.60   # 60% potrzeba dla HOLD
```

#### âš–ï¸ Balanced Mode
```python
CONFIDENCE_THRESHOLD_SHORT = 0.55  # 55% pewnoÅ›ci dla SHORT
CONFIDENCE_THRESHOLD_LONG = 0.55   # 55% pewnoÅ›ci dla LONG
CONFIDENCE_THRESHOLD_HOLD = 0.45   # 45% wystarczy dla HOLD
```

### 3.3. Implementacja w Treningu

```python
# W dual_window_lstm_model.py - ModelEvaluator
def _apply_confidence_thresholding(self, y_pred_proba: np.ndarray) -> np.ndarray:
    """
    Aplikuje confidence thresholding zamiast standardowego argmax.
    
    Args:
        y_pred_proba: Macierz prawdopodobieÅ„stw shape (n_samples, 3)
        
    Returns:
        np.ndarray: Predykcje z confidence thresholding
    """
    predictions = []
    
    for proba in y_pred_proba:
        short_confidence = proba[0]  # SHORT
        hold_confidence = proba[1]   # HOLD  
        long_confidence = proba[2]   # LONG
        
        # SprawdÅº czy ktÃ³ryÅ› sygnaÅ‚ przekracza prÃ³g
        if short_confidence >= self.config.CONFIDENCE_THRESHOLD_SHORT:
            predictions.append(0)  # SHORT
        elif long_confidence >= self.config.CONFIDENCE_THRESHOLD_LONG:
            predictions.append(2)  # LONG
        elif hold_confidence >= self.config.CONFIDENCE_THRESHOLD_HOLD:
            predictions.append(1)  # HOLD
        else:
            # Fallback - wybierz najwyÅ¼szÄ… pewnoÅ›Ä‡
            predictions.append(np.argmax(proba))
    
    return np.array(predictions)
```

### 3.4. Implementacja w Strategii

```python
# W Enhanced_ML_MA43200_Buffer_Strategy.py
confidence_threshold = self.confidence_threshold_ml.value  # 0.60 domyÅ›lnie

# ZnajdÅº najwyÅ¼szÄ… pewnoÅ›Ä‡ i klasÄ™
max_confidence = np.max(pred)
predicted_class = np.argmax(pred)

# SprawdÅº czy pewnoÅ›Ä‡ przekracza prÃ³g
if max_confidence >= confidence_threshold:
    if predicted_class == 0:    # SHORT
        dataframe.loc[dataframe.index[-1], 'ml_signal'] = 'SHORT'
    elif predicted_class == 2:  # LONG
        dataframe.loc[dataframe.index[-1], 'ml_signal'] = 'LONG'
    else:  # HOLD lub niska pewnoÅ›Ä‡
        dataframe.loc[dataframe.index[-1], 'ml_signal'] = 'HOLD'
else:
    # Niska pewnoÅ›Ä‡ - zawsze HOLD
    dataframe.loc[dataframe.index[-1], 'ml_signal'] = 'HOLD'
```

### 3.5. Konfiguracja CLI

```bash
# Confidence thresholding parameters w train_dual_window_model.py
--confidence-short 0.70     # PrÃ³g pewnoÅ›ci SHORT
--confidence-long 0.70      # PrÃ³g pewnoÅ›ci LONG  
--confidence-hold 0.30      # PrÃ³g pewnoÅ›ci HOLD
--confidence-mode conservative  # Tryb: conservative/aggressive/balanced
--disable-confidence        # WyÅ‚Ä…cz confidence thresholding
```

### 3.6. PorÃ³wnanie WynikÃ³w

System automatycznie porÃ³wnuje wyniki argmax vs confidence thresholding:

```
ğŸ” PORÃ“WNANIE ARGMAX vs CONFIDENCE THRESHOLDING:

ğŸ“Š ARGMAX (standardowe):
   Accuracy: 60.34%
   SHORT Precision: 36.7%, Recall: 29.7%
   LONG Precision: 41.3%, Recall: 35.6%

ğŸ¯ CONFIDENCE THRESHOLDING (conservative):
   Accuracy: 58.12%
   SHORT Precision: 42.1%, Recall: 24.8% 
   LONG Precision: 45.7%, Recall: 28.9%
   
ğŸ’¡ RÃ“Å»NICA:
   +5.4pp precision SHORT, +4.4pp precision LONG
   -4.9pp recall SHORT, -6.7pp recall LONG
   Mniej bÅ‚Ä™dnych sygnaÅ‚Ã³w, wiÄ™cej konserwatywnych HOLD
```

---

## 4. Komponenty Systemu

### 4.1. Struktura KatalogÃ³w

```
user_data/training/
â”œâ”€â”€ ğŸ“ config/                     # Konfiguracje systemu
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ training_config.py         â† ğŸ†• TrainingConfig z Confidence Thresholding
â”œâ”€â”€ ğŸ“ core/                       # Komponenty gÅ‚Ã³wne
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ“ data_loaders/           # Åadowanie danych
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ enhanced_feather_loader.py  â† Inteligentne Å‚adowanie z bufferami
â”‚   â”œâ”€â”€ ğŸ“ models/                 # Modele ML
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ dual_window_lstm_model.py   â† ğŸ†• Model z Confidence Thresholding
â”‚   â”œâ”€â”€ ğŸ“ sequence_builders/      # Tworzenie sekwencji
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ dual_window_sequence_builder.py â† ğŸ†• Batch processing + vectorized labeling
â”‚   â””â”€â”€ ğŸ“ feature_engineering/    # Engineering cech (pusty)
â”œâ”€â”€ ğŸ“ scripts/                    # Skrypty uruchomieniowe
â”‚   â””â”€â”€ train_dual_window_model.py â† ğŸ†• CLI z confidence parameters
â”œâ”€â”€ ğŸ“ outputs/                    # Wyniki treningu
â”‚   â”œâ”€â”€ ğŸ“ models/                 # Wytrenowane modele
â”‚   â””â”€â”€ ğŸ“ scalers/                # Skalowanie danych
â”œâ”€â”€ ğŸ“ utilities/                  # NarzÄ™dzia pomocnicze
â”œâ”€â”€ ğŸ“ archives/                   # Archiwa starych wersji
â””â”€â”€ ğŸ“„ test_implementation.py      # Testy systemu
```

### 4.2. ğŸ”§ TrainingConfig - Centralna Konfiguracja

**Plik**: `config/training_config.py`

```python
@dataclass
class TrainingConfig:
    """Centralna konfiguracja dla dwuokiennego systemu"""
    
    # === TEMPORAL WINDOWS ===
    WINDOW_SIZE: int = 90            # Historical window (zaktualizowane w v3.0)
    FUTURE_WINDOW: int = 90          # Future window (zaktualizowane w v3.0)
    
    # === LABELING PARAMETERS ===  
    LONG_TP_PCT: float = 0.01        # 1.0% Take Profit LONG (zaktualizowane)
    LONG_SL_PCT: float = 0.005       # 0.5% Stop Loss LONG (zaktualizowane)
    SHORT_TP_PCT: float = 0.01       # 1.0% Take Profit SHORT
    SHORT_SL_PCT: float = 0.005      # 0.5% Stop Loss SHORT
    
    # === ğŸ†• CONFIDENCE THRESHOLDING ===
    USE_CONFIDENCE_THRESHOLDING: bool = True
    CONFIDENCE_THRESHOLD_SHORT: float = 0.60
    CONFIDENCE_THRESHOLD_LONG: float = 0.60  
    CONFIDENCE_THRESHOLD_HOLD: float = 0.40
    CONFIDENCE_MODE: str = "conservative"
    
    # === MODEL PARAMETERS ===
    LSTM_UNITS: List[int] = [128, 64, 32]
    DENSE_UNITS: List[int] = [32, 16]
    DROPOUT_RATE: float = 0.2
    RECURRENT_DROPOUT_RATE: float = 0.2  # ğŸ†• Dodany parametr
    
    # === TRAINING ===
    EPOCHS: int = 100                # Zaktualizowane z 10 do 100
    BATCH_SIZE: int = 256            # ZwiÄ™kszone z 32 do 256
    LEARNING_RATE: float = 0.002     # Zaktualizowane
```

**ğŸ†• Nowe metody w v3.0**:
- `apply_confidence_mode()` - aplikuje tryby confidence
- `validate_confidence_params()` - walidacja progÃ³w confidence
- `from_cli_args()` - tworzenie config z parametrÃ³w CLI

### 4.3. ğŸ“Š EnhancedFeatherLoader - Åadowanie Danych

**Plik**: `core/data_loaders/enhanced_feather_loader.py`

**FunkcjonalnoÅ›ci**:
- **ğŸ”„ Automatyczny buffer**: Oblicza wymagane 33 dni buffera
- **ğŸ“ Multi-format support**: ObsÅ‚uga rÃ³Å¼nych struktur katalogÃ³w
- **ğŸ• Timezone handling**: Konwersja na timezone-naive
- **ğŸ”— Multi-file loading**: ÅÄ…czenie wielu plikÃ³w .feather
- **âœ… Data validation**: Sprawdzanie kompletnoÅ›ci danych

**Kluczowe metody**:
- `load_training_data()` - gÅ‚Ã³wna metoda Å‚adowania z bufferem
- `_calculate_total_buffer_days()` - obliczanie buffera (33 dni)
- `_compute_all_features()` - obliczanie wszystkich cech technicznych

### 4.4. ğŸ”„ DualWindowSequenceBuilder - Tworzenie Sekwencji

**Plik**: `core/sequence_builders/dual_window_sequence_builder.py`

**ğŸ†• FunkcjonalnoÅ›ci v3.0**:
- **Batch Processing**: Eliminuje memory exhaustion na duÅ¼ych zbiorach
- **Vectorized Labeling**: 300% szybsze przetwarzanie
- **Memory Monitoring**: Real-time monitoring z automatycznym cleanup
- **Deterministyczny seed**: Reprodukowalne wyniki

**Kluczowe metody**:
- `create_training_sequences()` - ğŸ†• batch processing version
- `_create_label_vectorized()` - ğŸ†• vectorized labeling (300% szybsze)
- `_apply_confidence_thresholding()` - ğŸ†• confidence-based predictions

**Pipeline procesu**:
```python
# FAZA 1: Batch processing configuration
BATCH_SIZE = 100000  # Process 100k sequences at a time

# FAZA 2: Memory monitoring
memory_monitor = MemoryMonitor(max_memory_gb=10)

# FAZA 3: Vectorized labeling
if USE_VECTORIZED_LABELING:
    label, simulation_results = self._create_label_vectorized(...)
else:
    label, simulation_results = self._create_label_from_future_chronological(...)

# FAZA 4: Batch saving with metadata
batch_file, metadata_file = self._save_batch(...)
```

### 4.5. ğŸ§  DualWindowLSTM - Model Architecture

**Plik**: `core/models/dual_window_lstm_model.py`

**ğŸ†• FunkcjonalnoÅ›ci v3.0**:
- **Confidence Thresholding**: `_apply_confidence_thresholding()`
- **Deterministyczny setup**: `setup_deterministic_training()`
- **PorÃ³wnanie wynikÃ³w**: `_print_confidence_comparison()`

**Architektura modelu**:
```python
# Input: (None, 90, 8) - 90 Å›wiec x 8 cech (zaktualizowane)
# LSTM Stack: 128 â†’ 64 â†’ 32 units (3 warstwy)
# Dense Stack: 32 â†’ 16 units z Dropout
# Output: 3 klasy (softmax) - SHORT/HOLD/LONG

# ğŸ†• Confidence evaluation
def _apply_confidence_thresholding(self, y_pred_proba):
    for proba in y_pred_proba:
        if proba[0] >= self.config.CONFIDENCE_THRESHOLD_SHORT:
            predictions.append(0)  # SHORT
        elif proba[2] >= self.config.CONFIDENCE_THRESHOLD_LONG:
            predictions.append(2)  # LONG
        else:
            predictions.append(1)  # HOLD (default)
```

---

## 5. Konfiguracja

### 5.1. Podstawowa Konfiguracja

```python
# UtwÃ³rz domyÅ›lnÄ… konfiguracjÄ™
from config.training_config import TrainingConfig

config = TrainingConfig()
config.print_summary()
```

### 5.2. ğŸ†• Konfiguracja Confidence Thresholding

```python
# Aplikuj tryb confidence
config.apply_confidence_mode("conservative")  # conservative/aggressive/balanced

# Lub rÄ™czne ustawienie progÃ³w
config.USE_CONFIDENCE_THRESHOLDING = True
config.CONFIDENCE_THRESHOLD_SHORT = 0.70
config.CONFIDENCE_THRESHOLD_LONG = 0.70
config.CONFIDENCE_THRESHOLD_HOLD = 0.30

# Walidacja parametrÃ³w
config.validate_confidence_params()
```

### 5.3. Dostosowanie ParametrÃ³w

```python
# Modyfikacja okien czasowych
config.WINDOW_SIZE = 90       # Historical window (zaktualizowane w v3.0)
config.FUTURE_WINDOW = 90     # Future window (zaktualizowane w v3.0)

# Modyfikacja progÃ³w TP/SL
config.LONG_TP_PCT = 0.01     # 1.0% TP (zaktualizowane)
config.LONG_SL_PCT = 0.005    # 0.5% SL (zaktualizowane)

# Modyfikacja treningu
config.EPOCHS = 100           # WiÄ™cej epok (zaktualizowane)
config.BATCH_SIZE = 256       # WiÄ™kszy batch size (zaktualizowane)
config.LEARNING_RATE = 0.002  # Zaktualizowany learning rate
```

### 5.4. Zapis/Odczyt Konfiguracji

```python
# Zapis do pliku
config.save_to_file("my_config.json")

# Odczyt z pliku
config = TrainingConfig.from_config_file("my_config.json")

# ğŸ†• Tworzenie z parametrÃ³w CLI
config = TrainingConfig.from_cli_args(args)
```

### 5.5. Walidacja Konfiguracji

```python
# Automatyczna walidacja
config.validate_config()  # ğŸ†• Nowa metoda walidacji

# Indywidualne walidacje
config.validate_windows()           # Walidacja okien czasowych  
config.validate_trading_params()    # Walidacja parametrÃ³w handlowych
config.validate_confidence_params() # ğŸ†• Walidacja confidence thresholding

# Buffer calculation
buffer_days = config.calculate_required_buffer_days()
# ğŸ“Š Required data buffer: 33 days
```

### 5.6. ğŸ†• Parametry CLI z Confidence

```bash
# Podstawowe parametry
python train_dual_window_model.py \
    --pair BTC_USDT \
    --epochs 100 \
    --window-past 90 \
    --window-future 90 \
    --take-profit 1.0 \
    --stop-loss 0.5

# ğŸ†• Confidence thresholding parameters
python train_dual_window_model.py \
    --confidence-short 0.70 \
    --confidence-long 0.70 \
    --confidence-hold 0.30 \
    --confidence-mode conservative

# ğŸ†• WyÅ‚Ä…czenie confidence thresholding
python train_dual_window_model.py \
    --disable-confidence
```

---

## 6. ğŸ³ Docker Wrapper - ZALECANY SPOSÃ“B

### 6.1. â­ DLACZEGO DOCKER WRAPPER?

**ğŸ¯ NAJLEPSZY SPOSÃ“B uruchamiania treningu to uÅ¼ycie Docker Wrapper `train_gpu.py`**

**Zalety Docker Wrapper:**
- âœ… **Automatyczna konfiguracja Å›rodowiska** - nie musisz instalowaÄ‡ zaleÅ¼noÅ›ci
- âœ… **GPU Support** - automatyczne wykorzystanie GPU jeÅ›li dostÄ™pne
- âœ… **Izolacja Å›rodowiska** - brak konfliktÃ³w z innymi projektami
- âœ… **ğŸ†• PeÅ‚na kompatybilnoÅ›Ä‡ z confidence thresholding** - wszystkie nowe parametry
- âœ… **Wszystkie aliasy parametrÃ³w** - obsÅ‚uguje wszystkie warianty nazw
- âœ… **ÅatwoÅ›Ä‡ uÅ¼ycia** - jeden plik, wszystkie funkcje

### 6.2. Lokalizacja i Wymagania

```bash
# Wrapper znajduje siÄ™ w:
ft_bot_docker_compose/train_gpu.py

# Wymagania:
- Docker i Docker Compose
- Serwis 'freqtrade' w docker-compose.yml
- Uruchamianie z katalogu ft_bot_docker_compose/
```

### 6.3. ğŸš€ Podstawowe UÅ¼ycie

```bash
# PrzejdÅº do katalogu Docker Compose
cd ft_bot_docker_compose

# SZYBKI TEST (5 epok, ostatnie 30 dni)
python train_gpu.py --preset quick

# STANDARDOWY TRENING (50 epok, caÅ‚y 2024)
python train_gpu.py --preset standard

# PRODUKCYJNY TRENING (100 epok, wszystkie dane)
python train_gpu.py --preset production

# TEST ROZWOJOWY (2 epoki, ostatnie 7 dni)
python train_gpu.py --preset test
```

### 6.4. ğŸ†• PrzykÅ‚ady z Confidence Thresholding

```bash
# Trening z conservative confidence mode
python train_gpu.py --preset standard --confidence-mode conservative

# Aggressive confidence thresholding
python train_gpu.py --pair ETH_USDT --confidence-mode aggressive \
    --confidence-short 0.45 --confidence-long 0.45

# WyÅ‚Ä…czenie confidence thresholding
python train_gpu.py --preset production --disable-confidence

# Custom confidence thresholds
python train_gpu.py --pair BTC_USDT \
    --confidence-short 0.75 \
    --confidence-long 0.75 \
    --confidence-hold 0.25 \
    --confidence-mode custom
```

### 6.5. PeÅ‚na Lista ParametrÃ³w

| Parametr | Alias | DomyÅ›lna | Opis |
|----------|-------|----------|------|
| `--preset` | - | - | System presets (quick/standard/production/test) |
| `--pair` | - | `BTC_USDT` | Para krypto |
| `--date-from` | `--start-date` | `2024-01-01` | Data poczÄ…tkowa YYYY-MM-DD |
| `--date-to` | `--end-date` | `2024-01-07` | Data koÅ„cowa YYYY-MM-DD |
| `--window-past` | `--window-size` | `90` | Okno przeszÅ‚oÅ›ci (ğŸ†• zaktualizowane) |
| `--window-future` | - | `90` | Okno przyszÅ‚oÅ›ci (ğŸ†• zaktualizowane) |
| `--take-profit` | `--tp-pct` | `1.0` | Take Profit % (ğŸ†• zaktualizowane) |
| `--stop-loss` | `--sl-pct` | `0.5` | Stop Loss % (ğŸ†• zaktualizowane) |
| `--epochs` | - | `100` | Liczba epok (ğŸ†• zaktualizowane) |
| `--batch-size` | - | `256` | Rozmiar batcha (ğŸ†• zaktualizowane) |
| `--learning-rate` | - | `0.002` | SzybkoÅ›Ä‡ uczenia (ğŸ†• zaktualizowane) |
| **ğŸ†• CONFIDENCE PARAMETERS** | | | |
| `--confidence-short` | - | `0.60` | PrÃ³g pewnoÅ›ci SHORT |
| `--confidence-long` | - | `0.60` | PrÃ³g pewnoÅ›ci LONG |
| `--confidence-hold` | - | `0.40` | PrÃ³g pewnoÅ›ci HOLD |
| `--confidence-mode` | - | `conservative` | Tryb confidence |
| `--disable-confidence` | - | `False` | WyÅ‚Ä…cz confidence thresholding |

### 6.6. PrzykÅ‚adowe WyjÅ›cie

```bash
ğŸš€ GPU TRAINING DOCKER WRAPPER (DUAL-WINDOW v3.0)
ğŸ“‹ Zgodny z dokumentacjÄ… z Confidence Thresholding
============================================================
âœ… Docker Compose dostÄ™pny: Docker Compose version v2.24.1
ğŸ” Sprawdzanie serwisu Freqtrade...
âœ… Serwis freqtrade dostÄ™pny
ğŸ“‹ Konfiguracja wrapper:
   Preset: standard
   Para: BTC_USDT
   ğŸ†• Confidence mode: conservative
   ğŸ†• Confidence thresholds: SHORT=0.70, LONG=0.70, HOLD=0.30
============================================================
ğŸ”§ Budowanie komendy docker-compose...
ğŸ³ Uruchamianie Docker Compose:
   docker-compose run --rm freqtrade python3 /freqtrade/user_data/training/scripts/train_dual_window_model.py --preset standard --confidence-mode conservative
============================================================
[TRENING W DOCKER Z GPU...]
ğŸ” PORÃ“WNANIE ARGMAX vs CONFIDENCE THRESHOLDING:
ğŸ“Š ARGMAX: Accuracy: 60.34%, SHORT Precision: 36.7%
ğŸ¯ CONFIDENCE: Accuracy: 58.12%, SHORT Precision: 42.1%
ğŸ’¡ +5.4pp precision improvement!
============================================================
âœ… Trening zakoÅ„czony pomyÅ›lnie!
ğŸ“ Wyniki w katalogu: user_data/training/outputs/models/
ğŸ“ Artefakty w katalogu: ml_artifacts/
```

### 6.7. RozwiÄ…zywanie ProblemÃ³w

```bash
# Problem: Docker Compose nie znaleziony
âŒ Docker Compose nie znaleziony
ğŸ’¡ Zainstaluj Docker Desktop lub Docker Compose

# Problem: Serwis freqtrade nie dostÄ™pny
âŒ Serwis freqtrade nie znaleziony
ğŸ’¡ Upewnij siÄ™, Å¼e uruchamiasz z katalogu ft_bot_docker_compose
ğŸ’¡ i Å¼e docker-compose.yml zawiera serwis freqtrade

# Problem: BÅ‚Ä™dne confidence parameters
âŒ Invalid confidence threshold: 1.5
ğŸ’¡ Confidence thresholds muszÄ… byÄ‡ miÄ™dzy 0.0 a 1.0
```

---

## 7. Instrukcje UÅ¼ycia

### 7.1. â­ ZALECANE: Docker Wrapper

```bash
# NAJLEPSZY SPOSÃ“B - Docker Wrapper z confidence thresholding
cd ft_bot_docker_compose
python train_gpu.py --preset standard --confidence-mode conservative
```

### 7.2. Alternatywne: BezpoÅ›rednie Uruchomienie

**âš ï¸ UWAGA: BezpoÅ›rednie uruchomienie wymaga rÄ™cznej konfiguracji Å›rodowiska**

```bash
# BezpoÅ›rednie uruchomienie (nie zalecane)
cd user_data/training
python scripts/train_dual_window_model.py \
    --pair BTC_USDT \
    --epochs 100 \
    --confidence-mode conservative
```

---

## 8. System Presets

### 8.1. DostÄ™pne Presets

#### ğŸ”¬ **test** - Test Rozwojowy
```bash
python train_gpu.py --preset test
```
- **Epoki**: 2
- **Dane**: Ostatnie 7 dni
- **Batch size**: 16
- **Window**: 30-30
- **ğŸ†• Confidence**: balanced mode
- **Cel**: Szybkie testowanie zmian w kodzie

#### âš¡ **quick** - Szybki Test
```bash
python train_gpu.py --preset quick
```
- **Epoki**: 5
- **Dane**: Ostatnie 30 dni
- **Batch size**: 64
- **Window**: 90-90 (ğŸ†• zaktualizowane)
- **ğŸ†• Confidence**: balanced mode
- **Cel**: Weryfikacja dziaÅ‚ania systemu

#### ğŸ“Š **standard** - Standardowy Trening
```bash
python train_gpu.py --preset standard
```
- **Epoki**: 50
- **Dane**: CaÅ‚y 2024
- **Batch size**: 256 (ğŸ†• zaktualizowane)
- **Window**: 90-90 (ğŸ†• zaktualizowane)
- **ğŸ†• Confidence**: conservative mode
- **Cel**: Typowy trening dla developmentu

#### ğŸš€ **production** - Produkcyjny Trening
```bash
python train_gpu.py --preset production
```
- **Epoki**: 100 (ğŸ†• zaktualizowane)
- **Dane**: Od 2020 do teraz
- **Batch size**: 256 (ğŸ†• zaktualizowane)
- **Validation split**: 0.15
- **ğŸ†• Confidence**: conservative mode
- **Cel**: Finalne modele do rzeczywistego tradingu

### 8.2. ğŸ†• Dostosowanie Presets z Confidence

```bash
# Kombinacja preset + dodatkowe confidence parametry
python train_gpu.py --preset standard \
    --confidence-mode aggressive \
    --confidence-short 0.45

# Preset z wyÅ‚Ä…czonym confidence thresholding
python train_gpu.py --preset production \
    --disable-confidence
```

---

## 9. Analiza WynikÃ³w

### 9.1. ğŸ†• Metryki Confidence Thresholding

System automatycznie generuje porÃ³wnanie argmax vs confidence thresholding:

```
ğŸ“Š WYNIKI TRENINGU z Confidence Thresholding:

ğŸ” PORÃ“WNANIE ARGMAX vs CONFIDENCE THRESHOLDING:

ğŸ“Š ARGMAX (standardowe):
   Test Accuracy: 60.34%
   SHORT Precision: 36.7%, Recall: 29.7%, F1: 0.327
   LONG Precision: 41.3%, Recall: 35.6%, F1: 0.384
   Trading F1 Average: 0.356

ğŸ¯ CONFIDENCE THRESHOLDING (conservative):
   Test Accuracy: 58.12%
   SHORT Precision: 42.1%, Recall: 24.8%, F1: 0.312
   LONG Precision: 45.7%, Recall: 28.9%, F1: 0.359  
   Trading F1 Average: 0.336
   
ğŸ’¡ ANALIZA RÃ“Å»NIC:
   âœ… +5.4pp precision SHORT (36.7% â†’ 42.1%)
   âœ… +4.4pp precision LONG (41.3% â†’ 45.7%)
   â“ -4.9pp recall SHORT (29.7% â†’ 24.8%)
   â“ -6.7pp recall LONG (35.6% â†’ 28.9%)
   
ğŸ¯ INTERPRETACJA:
   - Mniej bÅ‚Ä™dnych sygnaÅ‚Ã³w (wyÅ¼sza precision)
   - WiÄ™cej konserwatywnych HOLD (niÅ¼szy recall)
   - Lepsze dla strategii risk-averse
```

### 9.2. Podstawowe Metryki

- **Model Accuracy**: OgÃ³lna dokÅ‚adnoÅ›Ä‡ modelu
- **Trading F1**: F1-score dla sygnaÅ‚Ã³w SHORT + LONG (bez HOLD)
- **Precision/Recall**: JakoÅ›Ä‡ sygnaÅ‚Ã³w handlowych
- **Confusion Matrix**: Macierz pomyÅ‚ek z interpretacjÄ… handlowÄ…
- **Class Distribution**: RozkÅ‚ad predykcji vs rzeczywistoÅ›Ä‡

### 9.3. ğŸ†• Metryki Confidence

- **Confidence Distribution**: RozkÅ‚ad pewnoÅ›ci predykcji
- **Threshold Impact**: WpÅ‚yw progÃ³w confidence na wyniki
- **Conservative vs Aggressive**: PorÃ³wnanie trybÃ³w confidence
- **HOLD Rate**: Procent predykcji przekierowanych na HOLD

---

## 10. RozwiÄ…zywanie ProblemÃ³w

### 10.1. ğŸ†• Problemy Confidence Thresholding

```bash
# Problem: Zbyt wysokie progi confidence
âŒ Model zawsze predykuje HOLD
ğŸ’¡ Zmniejsz progi confidence: --confidence-short 0.50 --confidence-long 0.50

# Problem: Zbyt niskie progi confidence  
âŒ Confidence thresholding nie ma efektu
ğŸ’¡ ZwiÄ™ksz progi confidence: --confidence-short 0.75 --confidence-long 0.75

# Problem: BÅ‚Ä™dna konfiguracja trybu
âŒ Unknown confidence mode: custom
ğŸ’¡ UÅ¼ywaj: conservative, aggressive, balanced
```

### 10.2. Problemy Docker

```bash
# Problem: Docker Compose nie znaleziony
âŒ Docker Compose nie znaleziony
ğŸ’¡ Zainstaluj Docker Desktop

# Problem: GPU nie wykorzystane
âŒ Training bardzo wolny mimo GPU
ğŸ’¡ SprawdÅº docker-compose.yml - sekcja GPU
ğŸ’¡ Uruchom: docker run --gpus all nvidia/cuda:11.8-base nvidia-smi
```

### 10.3. Problemy Modelu

```bash
# Problem: 100% jedna klasa w predykcjach
âŒ Confusion matrix pokazuje tylko SHORT/HOLD/LONG
ğŸ’¡ Ustaw seed dla reprodukowalnoÅ›ci: setup_deterministic_training(42)
ğŸ’¡ SprawdÅº balansowanie klas: BALANCE_CLASSES=True

# Problem: Bardzo niska accuracy
âŒ Test accuracy < 40%
ğŸ’¡ ZwiÄ™ksz iloÅ›Ä‡ danych treningowych (min 3 miesiÄ…ce)
ğŸ’¡ Dostosuj TP/SL (sprÃ³buj --take-profit 1.5 --stop-loss 0.8)
```

---

## 11. Zalecenia

### 11.1. ğŸ†• Najlepsze Praktyki v3.0

1. **ğŸ³ UÅ»YWAJ DOCKER WRAPPER**: `python train_gpu.py --preset standard`
2. **ğŸ¯ Wybierz odpowiedni confidence mode**:
   - **Conservative** dla stabilnych strategii (precision > recall)
   - **Aggressive** dla aktywnego tradingu (recall > precision)  
   - **Balanced** jako punkt startowy
3. **ğŸ“Š Monitoruj metryki confidence**: Sprawdzaj porÃ³wnanie argmax vs confidence
4. **ğŸ”„ Testuj rÃ³Å¼ne progi**: Eksperymentuj z confidence thresholds 0.4-0.8

### 11.2. Klasyczne Zalecenia

5. **WiÄ™cej Danych**: Minimum 3-6 miesiÄ™cy dla stabilnych wynikÃ³w
6. **Balansowanie TP/SL**: Eksperymentuj z 0.5%-1.5%
7. **Walidacja Danych**: Zawsze sprawdzaj `--validate-data` przed treningiem
8. **Regularne Testowanie**: Uruchamiaj `test_implementation.py` 
9. **Chronologia**: Nigdy nie mieszaj danych czasowo
10. **System Presets**: UÅ¼ywaj presets dla rÃ³Å¼nych scenariuszy

### 11.3. ğŸ¯ Kluczowe Zalety Systemu v3.0

âœ… **ğŸ†• Confidence Thresholding** - Selektywne predykcje zamiast wymuszonych  
âœ… **ğŸ†• Deterministyczny Trening** - Reprodukowalne wyniki miÄ™dzy treningami  
âœ… **ğŸ†• Zaawansowane ZarzÄ…dzanie PamiÄ™ciÄ…** - Batch processing dla duÅ¼ych zbiorÃ³w  
âœ… **Eliminacja Data Leakage** - Model nie widzi przyszÅ‚oÅ›ci  
âœ… **Realistyczne Symulacje** - Warunki jak w prawdziwym tradingu  
âœ… **Automatyczne Balansowanie** - Inteligentne wagi klas  
âœ… **Production-Ready** - Kompletny pipeline z monitoringiem  
âœ… **Modularna Architektura** - Åatwa do rozszerzania  
âœ… **ğŸ³ Docker Integration** - Zintegrowany wrapper dla Å‚atwego uruchamiania

### 11.4. ğŸ“ˆ Performance Improvements v3.0

- **300% szybsze przetwarzanie** dziÄ™ki vectorized labeling
- **Eliminating memory exhaustion** dziÄ™ki batch processing  
- **Reprodukowalne wyniki** dziÄ™ki deterministycznemu seedowi
- **Lepsza precision** dziÄ™ki confidence thresholding
- **Åatwiejsze uÅ¼ycie** dziÄ™ki Docker wrapper z nowymi parametrami

---

## ğŸ“„ Podsumowanie

**Dokumentacja ModuÅ‚u Treningowego v3.0** to kompletny przewodnik po zaawansowanym systemie uczenia maszynowego dla Freqtrade z najnowszymi funkcjonalnoÅ›ciami **Confidence Thresholding**. 

**Status**: âœ… **MODUÅ W PEÅNI FUNKCJONALNY z CONFIDENCE THRESHOLDING**

**Rekomendacja**: ğŸ³ **UÅ¼ywaj Docker Wrapper** `train_gpu.py` z parametrami confidence dla najlepszego doÅ›wiadczenia.

---

*ğŸ“ Support: Przy problemach sprawdÅº sekcjÄ™ "RozwiÄ…zywanie ProblemÃ³w"*  
*ğŸ“ˆ Monitoring: UÅ¼ywaj Trading F1 i confidence metrics jako gÅ‚Ã³wnych metryk*  
*ğŸ”„ Updates: Dokumentacja zaktualizowana 27.01.2025 o funkcjonalnoÅ›ci Confidence Thresholding*  
*ğŸ“Š Scalono z: Medul_treningowy_dokumentacja.md + Modul_trenowania_modeli.md*  
*ğŸ†• Wersja: 3.0 z peÅ‚nym Confidence Thresholding System*

--- 