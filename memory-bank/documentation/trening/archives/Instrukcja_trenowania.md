# ğŸ“‹ Instrukcja Trenowania Modeli ML (Dual-Window System)

## ğŸš€ Podstawowe Uruchomienie

### ğŸ’» BezpoÅ›rednio na Host (CPU/GPU)
```bash
# Trening z domyÅ›lnymi parametrami
python user_data/training/scripts/train_dual_window_model.py

# Trening z presetem
python user_data/training/scripts/train_dual_window_model.py --preset quick

# Trening z wÅ‚asnymi parametrami
python user_data/training/scripts/train_dual_window_model.py --pair ETH_USDT --epochs 100 --take-profit 2.0
```

### ğŸ³ Przez Docker Wrapper (GPU Priority)
```bash
# Identyczna skÅ‚adnia, ale w Docker z GPU
python train_gpu.py --preset quick

# Wszystkie parametry dziaÅ‚ajÄ… tak samo
python train_gpu.py --pair ETH_USDT --epochs 100 --take-profit 2.0

# Windows batch launcher
train_gpu.bat --preset production --pair BTC_USDT
```

## ğŸ”„ Docker vs Host - KtÃ³ry WybraÄ‡?

| Cecha | ğŸ³ Docker Wrapper | ğŸ’» Host Direct |
|-------|-------------------|-----------------|
| **GPU Performance** | âœ… Optymalne | âš ï¸ ZaleÅ¼y od systemu |
| **Izolacja** | âœ… Czyste Å›rodowisko | âŒ Host dependencies |
| **Setup** | âš ï¸ Wymaga Docker | âœ… Prostsze |
| **Parametry** | âœ… Identyczne | âœ… Identyczne |
| **Wyniki** | âœ… Automatycznie na host | âœ… Lokalne |
| **Data Leakage** | âœ… Eliminowany (Dual-Window) | âœ… Eliminowany (Dual-Window) |

**Zalecenie**: UÅ¼yj `train_gpu.py` dla produkcji i bezpoÅ›rednio skryptu dla rozwoju.

## ğŸ“Š Parametry Treningu

### ğŸ¯ Podstawowe Parametry

| Parametr | DomyÅ›lna | Opis |
|----------|----------|------|
| `--pair` | BTC_USDT | Para kryptowalut do treningu |
| `--epochs` | 50 | Liczba epok treningu |
| `--window-past` | 60 | Ile Å›wiec wstecz analizuje model |
| `--window-future` | 60 | Ile Å›wiec w przÃ³d przewiduje |

### ğŸ“… Parametry Czasowe

| Parametr | DomyÅ›lna | Opis |
|----------|----------|------|
| `--date-from` | 2024-01-01 | Data poczÄ…tkowa danych |
| `--date-to` | 2024-12-31 | Data koÅ„cowa danych |

### ğŸ’° Risk Management

| Parametr | DomyÅ›lna | Opis |
|----------|----------|------|
| `--take-profit` | 1.0 | Take Profit w procentach |
| `--stop-loss` | 0.5 | Stop Loss w procentach |

### âš™ï¸ Parametry Modelu

| Parametr | DomyÅ›lna | Opis |
|----------|----------|------|
| `--batch-size` | 32 | Rozmiar batcha |
| `--learning-rate` | 0.001 | WspÃ³Å‚czynnik uczenia |
| `--validation-split` | 0.2 | PodziaÅ‚ na walidacjÄ™ (20%) |
| `--early-stopping` | 3 | Po ilu epokach bez poprawy zatrzymaÄ‡ |

### ğŸ“ Parametry WyjÅ›cia

| Parametr | DomyÅ›lna | Opis |
|----------|----------|------|
| `--output-dir` | auto | Katalog wynikÃ³w (automatyczny) |
| `--config` | auto | Plik konfiguracyjny TrainingConfig |

### ğŸ” Parametry Walidacji

| Parametr | Opis |
|----------|------|
| `--validate-data` | Tylko sprawdÅº dostÄ™pnoÅ›Ä‡ danych (nie trenuj) |
| `--dry-run` | Dry run - sprawdÅº konfiguracjÄ™ (nie trenuj) |

## ğŸ¨ Gotowe Presety

### `quick` - Szybki Test
```bash
python train_gpu.py --preset quick
```
- **Czas**: ~2-5 min
- **Dane**: Ostatnie 30 dni
- **Epoki**: 5
- **Zastosowanie**: Szybkie testy, rozwÃ³j

### `standard` - Standardowy Trening
```bash
python train_gpu.py --preset standard
```
- **Czas**: ~20-30 min
- **Dane**: CaÅ‚y 2024 rok
- **Epoki**: 50
- **Zastosowanie**: Normalne trenowanie

### `production` - Produkcyjny Model
```bash
python train_gpu.py --preset production
```
- **Czas**: ~1-2 godziny
- **Dane**: Od 2020 do dziÅ›
- **Epoki**: 100
- **Zastosowanie**: Finalne modele

### `test` - Minimalny Test
```bash
python train_gpu.py --preset test
```
- **Czas**: ~30 sekund
- **Dane**: Ostatnie 7 dni
- **Epoki**: 2
- **Zastosowanie**: Debugging, testy kodu

## ğŸ’¡ PrzykÅ‚ady UÅ¼ycia

### Podstawowe Scenariusze

```bash
# Szybki test nowej pary
python train_gpu.py --preset quick --pair DOGE_USDT

# Trening z wiÄ™kszym TP/SL
python train_gpu.py --take-profit 2.5 --stop-loss 1.0

# DÅ‚ugie okna czasowe
python train_gpu.py --window-past 120 --window-future 30

# Konkretny okres
python train_gpu.py --date-from 2024-06-01 --date-to 2024-12-01

# Szybsze uczenie z wiÄ™kszym batch
python train_gpu.py --batch-size 64 --learning-rate 0.002
```

### Kombinacje PresetÃ³w

```bash
# Preset + nadpisanie parametrÃ³w
python train_gpu.py --preset production --pair ETH_USDT --epochs 150

# Szybki test z wÅ‚asnymi parametrami TP/SL
python train_gpu.py --preset quick --take-profit 3.0 --stop-loss 1.5

# Test z custom oknem
python train_gpu.py --preset test --window-past 30 --window-future 15
```

### Walidacja i Debugging

```bash
# SprawdÅº tylko dostÄ™pnoÅ›Ä‡ danych
python train_gpu.py --pair ETH_USDT --validate-data

# Dry run - sprawdÅº konfiguracjÄ™
python train_gpu.py --preset production --dry-run

# Z custom config file
python train_gpu.py --config custom_training_config.json
```

### Windows Batch Shortcuts

```cmd
REM Szybkie testy
train_gpu.bat --preset test
train_gpu.bat --preset quick --pair ETH_USDT

REM Produkcyjne treningi
train_gpu.bat --preset production
train_gpu.bat --preset standard --epochs 200 --take-profit 2.0
```

### Host Direct (bez Docker)

```bash
# Z gÅ‚Ã³wnego katalogu Freqtrade
python user_data/training/scripts/train_dual_window_model.py --preset quick

# Z katalogu scripts
cd user_data/training/scripts
python train_dual_window_model.py --pair BTC_USDT --epochs 100
```

## ğŸ“ Struktura WynikÃ³w

Po treningu system tworzy katalog w `ml_artifacts/` z nazwÄ…:
```
PARA_DATA-OD_DATA-DO_EPOKIepochs_wOKNO-PRZESZÅE-PRZYSZÅE_tpTP_slSL_TIMESTAMP/
```

### ZawartoÅ›Ä‡ Katalogu

- `best_model_PARA.keras` - Najlepszy model z treningu
- `config.json` - Konfiguracja TrainingConfig uÅ¼yta w treningu
- `training_history.json` - Historia treningu (loss, accuracy)
- `evaluation_report.json` - SzczegÃ³Å‚owe metryki ewaluacji
- `training_log.txt` - PeÅ‚ny log treningu
- `README.md` - Podsumowanie treningu

## ğŸ”§ RozwiÄ…zywanie ProblemÃ³w

### CzÄ™ste BÅ‚Ä™dy

**BÅ‚Ä…d daty**: SprawdÅº format YYYY-MM-DD
```bash
# Å¹le
--date-from 01-01-2024

# Dobrze  
--date-from 2024-01-01
```

**Za maÅ‚o danych**: System automatycznie sprawdza dostÄ™pnoÅ›Ä‡
```bash
# SprawdÅº przed treningiem
python train_gpu.py --pair NEW_PAIR --validate-data
```

**Brak danych dla pary**: Upewnij siÄ™ Å¼e dane sÄ… w user_data
```bash
âŒ Brakuje danych dla pary XXX_USDT
ğŸ’¡ SprawdÅº czy dane sÄ… w user_data/data/
```

**GPU Issues**: System automatycznie przeÅ‚Ä…czy na CPU

**Docker Issues**: 
```bash
# Brak Docker
âŒ Docker nie znaleziony
ğŸ’¡ Zainstaluj Docker Desktop

# Brak GPU w Docker  
âŒ GPU nie wykryte, bÄ™dzie uÅ¼ywane CPU
ğŸ’¡ Zainstaluj NVIDIA Container Toolkit

# Brak obrazu freqtrade:gpu
âŒ Unable to find image 'freqtrade:gpu'
ğŸ’¡ Dostosuj nazwÄ™ obrazu w train_gpu.py
```

### Optymalizacja WydajnoÅ›ci

- **GPU**: Automatyczna detekcja i uÅ¼ycie
- **Batch Size**: WiÄ™kszy = szybszy (ale wiÄ™cej RAM)
- **Early Stopping**: Zatrzyma gdy model przestanie siÄ™ poprawiaÄ‡
- **Validation Split**: 0.2 = optymalne dla wiÄ™kszoÅ›ci przypadkÃ³w
- **Dual-Window**: Eliminuje data leakage automatycznie

## ğŸ“ˆ Monitorowanie Treningu

System pokazuje w czasie rzeczywistym:
- PostÄ™p epok z progress bar
- Accuracy i loss (train/validation)  
- CzasochÅ‚onnoÅ›Ä‡ epok
- Informacje o GPU/CPU
- Metryki dual-window approach

## ğŸ¯ Najlepsze Praktyki

1. **Zawsze zacznij od presetu `quick`** dla nowych par/parametrÃ³w
2. **UÅ¼yj `standard`** dla normalnego rozwoju  
3. **`production`** tylko dla finalnych modeli
4. **Zapisuj konfiguracje** ktÃ³re dziaÅ‚ajÄ… dobrze w config files
5. **Monitoruj overfit** - validation loss vs training loss
6. **Docker dla produkcji** - `train_gpu.py` dla dÅ‚ugich treningÃ³w
7. **Host dla testÃ³w** - bezpoÅ›rednio skrypt dla szybkich eksperymentÃ³w
8. **Sprawdzaj dane** - uÅ¼ywaj `--validate-data` przed dÅ‚ugimi treningami

## ğŸ³ Docker Wrapper - SzczegÃ³Å‚y

### ğŸ› ï¸ Wymagania Docker
- Docker Desktop z GPU support
- NVIDIA Container Toolkit (dla GPU)
- Obraz `freqtrade:gpu` (lub dostosuj nazwÄ™ w train_gpu.py)

### ğŸš€ Uruchomienie Wrapper

```bash
# Podstawowe (automatyczne GPU jeÅ›li dostÄ™pne)
python train_gpu.py

# Wszystkie opcje dziaÅ‚ajÄ… identycznie
python train_gpu.py --preset quick --pair DOGE_USDT
python train_gpu.py --epochs 200 --take-profit 3.0 --window-past 120

# Windows
train_gpu.bat --preset production
```

### ğŸ“ Montowanie KatalogÃ³w

Wrapper automatycznie montuje:
- `./ml_artifacts` â†’ `/workspace/ml_artifacts` (wyniki)
- `./user_data` â†’ `/workspace/user_data` (dane)
- `./` â†’ `/workspace/host` (kod ÅºrÃ³dÅ‚owy)

### ğŸ”§ Automatyczne Funkcje

- **GPU Detection**: Automatyczne `--gpus all` jeÅ›li GPU dostÄ™pne
- **CPU Fallback**: PrzeÅ‚Ä…czenie na CPU gdy brak GPU
- **Directory Creation**: Tworzenie katalogÃ³w `ml_artifacts/`, `user_data/`
- **Parameter Pass-Through**: Wszystkie parametry przekazane 1:1
- **Error Handling**: Propagacja kodÃ³w bÅ‚Ä™dÃ³w z kontenera
- **Dual-Window Pipeline**: UÅ¼ywa zaawansowanego systemu eliminujÄ…cego data leakage

### ğŸ’¡ PrzykÅ‚ady Docker Wrapper

```bash
# Szybki test w Docker
train_gpu.bat --preset test

# Produkcyjny model z GPU
python train_gpu.py --preset production --pair ETH_USDT --epochs 150

# Eksperyment z parametrami
python train_gpu.py --window-past 120 --window-future 30 --learning-rate 0.0005

# DÅ‚ugi trening overnight
python train_gpu.py --preset production --epochs 500 --early-stopping 10

# Z walidacjÄ… danych
python train_gpu.py --pair NEW_PAIR --validate-data
```

## âš¡ RÃ³Å¼nice vs Poprzednia Wersja

| Aspekt | Poprzednia (Universal) | Obecna (Dual-Window) |
|--------|----------------------|---------------------|
| **Dane** | Mock/Symulowane | Prawdziwe z Freqtrade |
| **Data Leakage** | MoÅ¼liwy | Eliminowany |
| **Architektura** | Prosta LSTM | Zaawansowana Dual-Window |
| **Ewaluacja** | Podstawowa | Comprehensive |
| **Konfiguracja** | CLI only | CLI + TrainingConfig |
| **Presety** | Proste | Zaawansowane (TrainingConfig) |
