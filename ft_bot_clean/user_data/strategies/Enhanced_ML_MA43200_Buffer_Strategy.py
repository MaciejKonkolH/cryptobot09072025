"""
üöÄ ARCHITEKTURA V6 - Enhanced XGBoost Strategy üöÄ

Zgodnie z ostatecznym, precyzyjnym planem, ta strategia implementuje
XGBoost z 37 cechami i 5 poziomami TP/SL.

‚úÖ TRYB BACKTEST:
- Przetwarzanie "≈õwieca po ≈õwiecy".
- Dla ka≈ºdego punktu w czasie, Bufor buduje od zera pe≈Çny kontekst historyczny
  (43,200+ ≈õwiec), oblicza wska≈∫niki i 37 kluczowych cech.
- Zwracana jest gotowa do predykcji dataframe z 37 cechami.

üìù TRYB LIVE:
- Przetwarzanie na paczkach 60 ≈õwiec.
- Jednorazowa synchronizacja na starcie w celu wype≈Çnienia "luki" w danych.
- Inteligentne ≈ÇƒÖczenie danych i okresowy zapis na dysk w celu zapewnienia
  ciƒÖg≈Ço≈õci i wydajno≈õci.
"""

import logging
import numpy as np
import pandas as pd
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

from freqtrade.strategy import IStrategy, IntParameter
from freqtrade.strategy.interface import IStrategy
from freqtrade.enums import RunMode
from freqtrade.exceptions import DependencyException

# üöÄ SETUP PROJECT PATH üöÄ
# To zapewnia, ≈ºe importy dzia≈ÇajƒÖ poprawnie, niezale≈ºnie od sposobu uruchomienia.
# ft_bot_clean/user_data/strategies/ -> ft_bot_clean/user_data/ -> ft_bot_clean/
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

# Importy komponent√≥w
from user_data.strategies.components.signal_generator import SignalGenerator
from user_data.strategies.utils.model_loader import ModelLoader
from user_data.strategies.utils.pair_manager import PairManager

logger = logging.getLogger(__name__)

class Enhanced_ML_MA43200_Buffer_Strategy(IStrategy):
    strategy_name = "Enhanced_ML_MA43200_Buffer_Strategy_v6"
    timeframe = '1m'
    startup_candle_count: int = 0

    # ROI table i stoploss sƒÖ teraz w config.json
    stoploss = -0.004
    
    can_short = True
    position_adjustment_enable = False
    use_exit_signal = False
    exit_profit_only = False
    exit_profit_offset = 0.0
    ignore_roi_if_entry_signal = False

    order_types = {
        'entry': 'limit',
        'exit': 'limit',
        'stoploss': 'market',
        'stoploss_on_exchange': True,
        'stoploss_on_exchange_interval': 60,
    }

    order_time_in_force = {
        'entry': 'GTC',
        'exit': 'GTC',
    }

    # Parametry strategii
    stake_currency = 'USDT'
    stake_amount = 120
    unfilledtimeout = {
        'entry': 10,
        'unit': 'minutes',
        'exit_timeout_count': 0,
    }
    max_open_trades = 100

    def __init__(self, config: dict = None) -> None:
        super().__init__(config)
        
        # Konfiguracja ML
        self.ml_config = config.get('ml_config', {}) if config else {}
        self.enabled = self.ml_config.get('enabled', True)
        
        # Inicjalizacja komponent√≥w
        self.signal_generator = SignalGenerator(self.ml_config)
        self.model_loader = ModelLoader()
        self.pair_manager = PairManager()
        
        # Cache dla modeli i scaler√≥w
        self.models_cache = {}
        self.scalers_cache = {}
        
        # Dane z cechami (za≈Çadowane raz na poczƒÖtku)
        self.features_data = None
        self.features_loaded = False
        
        # Log predykcji
        self.predictions_log = []
        
        # Konfiguracja backtestingu
        self._load_backtest_config()

    def _load_backtest_config(self) -> None:
        """≈Åaduje konfiguracjƒô dla backtestingu."""
        self.ml_confidence_short = self.ml_config.get('confidence_threshold_short', 0.42)
        self.ml_confidence_long = self.ml_config.get('confidence_threshold_long', 0.42)
        self.ml_confidence_hold = self.ml_config.get('confidence_threshold_hold', 0.30)
        self.selected_model_index = self.ml_config.get('selected_model_index', 2)


    def bot_start(self, **kwargs) -> None:
        """Inicjalizacja na starcie bota."""
        if not self.enabled:
            logger.warning("‚ùå ML Strategy jest wy≈ÇƒÖczona w konfiguracji.")
            return
            
        logger.info("üöÄ Enhanced ML Strategy v5.0 (Precise Architecture) initialized!")
        
        # Logowanie konfiguracji ML
        logger.info(f"üîß Konfiguracja ML:")
        logger.info(f"   - Progi pewno≈õci: SHORT={self.ml_confidence_short}, LONG={self.ml_confidence_long}, HOLD={self.ml_confidence_hold}")
        
        # Mapowanie indeks√≥w na opisy poziom√≥w TP/SL
        tp_sl_levels = [
            "TP: 1.2%, SL: 0.4%",
            "TP: 0.6%, SL: 0.3%", 
            "TP: 0.8%, SL: 0.4%",
            "TP: 1.0%, SL: 0.5%",
            "TP: 1.5%, SL: 0.4%"
        ]
        selected_level = tp_sl_levels[self.selected_model_index] if 0 <= self.selected_model_index < len(tp_sl_levels) else "NIEZNANY"
        logger.info(f"   - Wybrany model: indeks {self.selected_model_index} ({selected_level})")
        
        # Inicjalizacja systemu wieloparowego
        self._initialize_multi_pair_system()
        
        # ≈Åadowanie danych z cechami
        self._load_features_data()

    def _initialize_multi_pair_system(self) -> None:
        """Inicjalizuje system wieloparowy."""
        logger.info("üîÑ Inicjalizacja systemu wieloparowego...")
        
        # Pobierz listƒô par z konfiguracji
        pairs = self.config.get('pair_whitelist', [])
        if not pairs:
            # Fallback - u≈ºyj par z pairlist
            pairs = ["BTC/USDT:USDT"]
            logger.info(f"üîÑ U≈ºywam domy≈õlnej pary: {pairs}")
            
        # Inicjalizuj pary
        self._initialize_models_for_pairs(pairs)

    def _initialize_models_for_pairs(self, pairs: list) -> None:
        """Inicjalizuje modele dla wszystkich par."""
        logger.info(f"üîÑ Inicjalizacja modeli dla {len(pairs)} par...")
        
        for pair in pairs:
            try:
                # Za≈Çaduj model, scaler i metadata
                model, scaler, metadata = self.model_loader.load_model_for_pair(pair)
                
                if model and scaler:
                    normalized_pair = self._normalize_pair_name(pair)
                    self.models_cache[normalized_pair] = model
                    self.scalers_cache[normalized_pair] = scaler
                    
                    logger.info(f"‚úÖ {pair}: Model i scaler za≈Çadowane pomy≈õlnie.")
                else:
                    logger.error(f"‚ùå {pair}: Nie uda≈Ço siƒô za≈Çadowaƒá modelu lub scalera.")
                    
            except Exception as e:
                logger.error(f"‚ùå {pair}: B≈ÇƒÖd podczas ≈Çadowania modelu: {e}")

    def _load_features_data(self) -> None:
        """≈Åaduje dane z cechami z pliku labeler3 (ten sam plik co u≈ºywany podczas treningu)."""
        try:
            # ≈öcie≈ºka do pliku z cechami z labeler3 (bezwzglƒôdna)
            features_path = Path("C:/Users/macie/OneDrive/Python/Binance/crypto/labeler3/output/ohlc_orderbook_labeled_3class_fw120m_5levels.feather")
            
            if not features_path.exists():
                logger.error(f"‚ùå Plik z cechami nie istnieje: {features_path}")
                return
                
            # Wczytaj dane
            self.features_data = pd.read_feather(features_path)
            
            # Konwertuj timestamp na datetime z UTC
            if 'timestamp' in self.features_data.columns:
                self.features_data['date'] = pd.to_datetime(self.features_data['timestamp'], utc=True)
                self.features_data.set_index('date', inplace=True)
            elif 'date' in self.features_data.columns:
                self.features_data['date'] = pd.to_datetime(self.features_data['date'], utc=True)
                self.features_data.set_index('date', inplace=True)
            else:
                logger.error("‚ùå Brak kolumny timestamp lub date w pliku z cechami")
                return
            
            # Sprawd≈∫ czy wszystkie wymagane cechy sƒÖ dostƒôpne
            required_features = self.signal_generator.feature_columns
            missing_features = [f for f in required_features if f not in self.features_data.columns]
            
            if missing_features:
                logger.error(f"‚ùå BrakujƒÖce cechy: {missing_features}")
                return
                
            self.features_loaded = True
            logger.info(f"‚úÖ Dane z cechami za≈Çadowane z pliku labeler3: {len(self.features_data)} wierszy, {len(required_features)} cech")
            
        except Exception as e:
            logger.error(f"‚ùå B≈ÇƒÖd podczas ≈Çadowania danych z cechami: {e}")

    def populate_indicators(self, dataframe: pd.DataFrame, metadata: dict) -> pd.DataFrame:
        """
        G≈Ç√≥wna metoda FreqTrade - wywo≈Çywana dla ka≈ºdej ≈õwiecy.
        """
        pair = metadata['pair']
        
        if not self.enabled:
            logger.warning(f"‚ùå {pair}: ML Strategy jest wy≈ÇƒÖczona.")
            return dataframe
            
        if not self.features_loaded:
            logger.error(f"‚ùå {pair}: Dane z cechami nie zosta≈Çy za≈Çadowane.")
            return dataframe
        
        # Wybierz tryb dzia≈Çania na podstawie runmode
        if self.dp.runmode == RunMode.BACKTEST:
            return self._populate_for_backtest(dataframe, pair)
        else:
            return self._populate_for_live(dataframe, pair)

    def _populate_for_backtest(self, dataframe: pd.DataFrame, pair: str) -> pd.DataFrame:
        """
        Logika dla trybu BACKTEST - przetwarzanie wszystkich ≈õwiec na raz.
        """
        logger.info(f"üöÄ {pair}: Wykryto tryb BACKTEST. Uruchamianie logiki '≈õwieca po ≈õwiecy'...")
        
        # Inicjalizuj kolumny sygna≈Çowe
        self._initialize_signal_columns(dataframe)
        
        # Pobierz wszystkie timestampy z dataframe
        timestamps = dataframe['date'].tolist()
        logger.info(f"üöÄ {pair}: Rozpoczynanie przetwarzania dla {len(timestamps)} ≈õwiec...")
        
        # SPRAWDZENIE DANYCH OHLC - por√≥wnanie z danymi z pliku z cechami
        logger.info(f"üîç {pair}: Sprawdzanie zgodno≈õci danych OHLC...")
        mismatches = 0
        total_checked = 0
        
        for i, timestamp in enumerate(timestamps[:100]):  # Sprawd≈∫ pierwsze 100 ≈õwiec
            if timestamp in self.features_data.index:
                # Pobierz dane OHLC z FreqTrade
                ft_open = dataframe.iloc[i]['open']
                ft_high = dataframe.iloc[i]['high']
                ft_low = dataframe.iloc[i]['low']
                ft_close = dataframe.iloc[i]['close']
                ft_volume = dataframe.iloc[i]['volume']
                
                # Pobierz dane OHLC z pliku z cechami
                feat_open = self.features_data.loc[timestamp, 'open']
                feat_high = self.features_data.loc[timestamp, 'high']
                feat_low = self.features_data.loc[timestamp, 'low']
                feat_close = self.features_data.loc[timestamp, 'close']
                feat_volume = self.features_data.loc[timestamp, 'volume']
                
                # Sprawd≈∫ czy sƒÖ identyczne
                if (abs(ft_open - feat_open) > 0.01 or 
                    abs(ft_high - feat_high) > 0.01 or 
                    abs(ft_low - feat_low) > 0.01 or 
                    abs(ft_close - feat_close) > 0.01 or 
                    abs(ft_volume - feat_volume) > 0.01):
                    mismatches += 1
                    if mismatches <= 5:  # Poka≈º tylko pierwsze 5 r√≥≈ºnic
                        logger.warning(f"‚ö†Ô∏è {pair}: R√≥≈ºnica OHLC dla {timestamp}:")
                        logger.warning(f"   FreqTrade: O={ft_open:.2f}, H={ft_high:.2f}, L={ft_low:.2f}, C={ft_close:.2f}, V={ft_volume:.2f}")
                        logger.warning(f"   Features:  O={feat_open:.2f}, H={feat_high:.2f}, L={feat_low:.2f}, C={feat_close:.2f}, V={feat_volume:.2f}")
                
                total_checked += 1
        
        logger.info(f"üîç {pair}: Sprawdzono {total_checked} ≈õwiec, znaleziono {mismatches} r√≥≈ºnic w danych OHLC")
        
        # SPRAWDZENIE TIMESTAMP√ìW - ile z FreqTrade nie ma w danych z cechami
        logger.info(f"üîç {pair}: Sprawdzanie dostƒôpno≈õci timestamp√≥w...")
        missing_timestamps = 0
        available_timestamps = 0
        
        for timestamp in timestamps:
            if timestamp in self.features_data.index:
                available_timestamps += 1
            else:
                missing_timestamps += 1
                if missing_timestamps <= 5:  # Poka≈º tylko pierwsze 5 brakujƒÖcych
                    logger.warning(f"‚ö†Ô∏è {pair}: Timestamp {timestamp} nie znaleziony w danych z cechami")
        
        logger.info(f"üîç {pair}: Dostƒôpne timestampy: {available_timestamps}, brakujƒÖce: {missing_timestamps}")
        logger.info(f"üîç {pair}: Zakres timestamp√≥w FreqTrade: {timestamps[0]} - {timestamps[-1]}")
        logger.info(f"üîç {pair}: Zakres timestamp√≥w Features: {self.features_data.index.min()} - {self.features_data.index.max()}")
        
        # Pobierz model i scaler
        model = self.models_cache.get(self._normalize_pair_name(pair))
        scaler = self.scalers_cache.get(self._normalize_pair_name(pair))
        
        if not model or not scaler:
            logger.error(f"‚ùå {pair}: Brak modelu lub scalera.")
            return dataframe
        
        # Przygotuj cechy dla wszystkich timestamp√≥w
        features_list = []
        valid_indices = []
        
        for i, timestamp in enumerate(timestamps):
            try:
                # Znajd≈∫ cechy dla tego timestampu
                if timestamp in self.features_data.index:
                    features = self.features_data.loc[timestamp, self.signal_generator.feature_columns].values
                    features = features.astype(np.float64)
                    
                    if np.isfinite(features).all():
                        features_list.append(features)
                        valid_indices.append(i)
                    else:
                        logger.warning(f"‚ö†Ô∏è {pair}: Nieprawid≈Çowe cechy dla {timestamp}")
                else:
                    logger.warning(f"‚ö†Ô∏è {pair}: Timestamp {timestamp} nie znaleziony w danych z cechami")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è {pair}: B≈ÇƒÖd dla timestamp {timestamp}: {e}")
        
        if not features_list:
            logger.error(f"‚ùå {pair}: Brak prawid≈Çowych cech do predykcji.")
            return dataframe
        
        # Utw√≥rz DataFrame z cechami
        features_df = pd.DataFrame(features_list, columns=self.signal_generator.feature_columns)
        logger.info(f"ü§ñ {pair}: Przygotowywanie batch prediction dla {len(features_list)} pr√≥bek...")
        
        # Generuj sygna≈Çy dla ca≈Çego batcha
        all_signal_dicts = self.signal_generator.generate_signals_for_batch(model, scaler, features_df, self.selected_model_index)
        
        # Przypisz sygna≈Çy do odpowiednich wierszy
        logger.info(f"‚úçÔ∏è {pair}: Przypisywanie {len(all_signal_dicts)} sygna≈Ç√≥w do ramki danych...")
        
        for i, signal_data in enumerate(all_signal_dicts):
            if i < len(valid_indices):
                # Pobierz oryginalny indeks z `dataframe` i timestamp
                original_idx = valid_indices[i]
                timestamp = dataframe.at[original_idx, 'date']
                
                # Przypisz sygna≈Çy
                signal = signal_data.get('signal')
                if signal == 'LONG':
                    dataframe.at[original_idx, 'enter_long'] = 1
                elif signal == 'SHORT':
                    dataframe.at[original_idx, 'enter_short'] = 1
                # NEUTRAL nie generuje sygna≈Ç√≥w wej≈õcia
                
                # Zapisz dane do logu, je≈õli istniejƒÖ
                if signal_data and 'probabilities' in signal_data:
                    self.predictions_log.append({
                        'timestamp': timestamp,
                        'pair': pair,
                        'signal': signal,
                        'confidence': signal_data.get('confidence'),
                        'prob_SHORT': signal_data['probabilities'][0],
                        'prob_LONG': signal_data['probabilities'][1],
                        'prob_NEUTRAL': signal_data['probabilities'][2]
                    })

        logger.info(f"‚úÖ {pair}: Zako≈Ñczono backtesting.")
        
        # Zapisz log predykcji
        if self.predictions_log:
            self._save_predictions_log(pair)
        
        return dataframe

    def _populate_for_live(self, dataframe: pd.DataFrame, pair: str) -> pd.DataFrame:
        """
        Logika dla trybu LIVE - przetwarzanie tylko ostatniej ≈õwiecy.
        """
        self._initialize_signal_columns(dataframe)
        
        # Pobierz ostatniƒÖ ≈õwiecƒô
        last_candle_timestamp = dataframe.iloc[-1]['date']
        
        # Znajd≈∫ cechy dla ostatniego timestampu
        if last_candle_timestamp in self.features_data.index:
            features = self.features_data.loc[last_candle_timestamp, self.signal_generator.feature_columns].values
            features = features.astype(np.float64)
            
            if np.isfinite(features).all():
                model = self.models_cache.get(self._normalize_pair_name(pair))
                scaler = self.scalers_cache.get(self._normalize_pair_name(pair))
                
                if model and scaler:
                    # Utw√≥rz dataframe z cechami dla ostatniego wiersza
                    features_df = pd.DataFrame([features], columns=self.signal_generator.feature_columns)
                    
                    signal_data = self.signal_generator.generate_signal(model, scaler, features_df, self.selected_model_index)
                    self._assign_signals_to_row(
                        dataframe,
                        dataframe.index[-1],
                        signal_data
                    )
        
        return dataframe
     
    def populate_entry_trend(self, dataframe: pd.DataFrame, metadata: dict) -> pd.DataFrame:
        # Sygna≈Çy 'enter_long' i 'enter_short' sƒÖ ju≈º obliczone w `populate_indicators`.
        # Ta metoda s≈Çu≈ºy teraz tylko do ewentualnego dodania tag√≥w lub innej logiki
        # bazujƒÖcej na istniejƒÖcych sygna≈Çach.
        pair = metadata['pair']
        
        # Inicjalizuj kolumny je≈õli nie istniejƒÖ
        self._initialize_signal_columns(dataframe)
        
        long_condition = dataframe['enter_long'] == 1
        short_condition = dataframe['enter_short'] == 1
        
        dataframe.loc[long_condition, 'enter_tag'] = f'{pair}_long'
        dataframe.loc[short_condition, 'enter_tag'] = f'{pair}_short'
        
        return dataframe
     
    def populate_exit_trend(self, dataframe: pd.DataFrame, metadata: dict) -> pd.DataFrame:
        """
        Wy≈ÇƒÖcza niestandardowe sygna≈Çy wyj≈õcia. Strategia opiera siƒô wy≈ÇƒÖcznie na
        wbudowanych mechanizmach ROI i stop-loss dla maksymalnej wydajno≈õci.
        """
        dataframe['exit_long'] = 0
        dataframe['exit_short'] = 0
        return dataframe

    def _normalize_pair_name(self, pair: str) -> str:
        return pair.split(':')[0]

    def _initialize_signal_columns(self, dataframe: pd.DataFrame):
        """Inicjalizuje kolumny sygna≈Çowe, je≈õli nie istniejƒÖ."""
        if 'enter_long' not in dataframe.columns:
            dataframe['enter_long'] = 0
        if 'enter_short' not in dataframe.columns:
            dataframe['enter_short'] = 0
        if 'exit_long' not in dataframe.columns:
            dataframe['exit_long'] = 0
        if 'exit_short' not in dataframe.columns:
            dataframe['exit_short'] = 0
        if 'enter_tag' not in dataframe.columns:
            dataframe['enter_tag'] = ''
            
    def _assign_signals_to_row(self, df: pd.DataFrame, index, signal_data: dict):
        """Helper do przypisywania sygna≈Ç√≥w do wiersza ramki danych."""
        signal = signal_data.get('signal')

        if signal == 'LONG':
            df.loc[index, 'enter_long'] = 1
        elif signal == 'SHORT':
            df.loc[index, 'enter_short'] = 1
        
    def _save_predictions_log(self, pair: str):
        """Zapisuje log predykcji do pliku CSV."""
        if not self.predictions_log:
            return
            
        try:
            # Utw√≥rz katalog je≈õli nie istnieje
            log_dir = Path("user_data/backtest_results")
            log_dir.mkdir(parents=True, exist_ok=True)
            
            # Nazwa pliku z timestampem
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"predictions_{pair.replace('/', '').replace(':', '')}_{timestamp}.csv"
            filepath = log_dir / filename
            
            # Zapisz do CSV
            df_log = pd.DataFrame(self.predictions_log)
            df_log.to_csv(filepath, index=False)
            
            logger.info(f"‚úÖ Zapisano log predykcji do pliku: {filepath}")
            
        except Exception as e:
            logger.error(f"‚ùå B≈ÇƒÖd podczas zapisywania logu predykcji: {e}")

    def bot_loop_start(self, current_time, **kwargs) -> None:
        """Wywo≈Çywane na poczƒÖtku ka≈ºdej pƒôtli bota."""
        pass